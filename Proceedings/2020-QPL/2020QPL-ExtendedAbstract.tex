\documentclass{article}
\usepackage{authblk}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}


% Remove line spaces between items of enumerate and itemize
\usepackage{enumitem}
\setlist{noitemsep}


% Adds double bracket symbols
\usepackage{stmaryrd}

% Latex symbol guide at http://mirrors.ibiblio.org/CTAN/info/symbols/comprehensive/symbols-letter.pdf

% LOGIC symbols
% -------------

% Allows to create negation symbols
\usepackage{MnSymbol}

% General math symbols
\DeclareMathOperator{\Id}{Id} % Identity function

% Boolean symbols and algebra
\def\Bool{\mathbb{B}}
\def\TRUE{\textsc{true}}
\def\FALSE{\textsc{false}}
\def\AND{\wedge}
\def\bigAND{\bigwedge}
\def\OR{\vee}
\def\bigOR{\bigvee}
\def\NOT{\neg}

% Logical context and related symbols
\def\logCtx{\mathcal{S}}
\def\vstmtSet{\mathcal{S}_\textsf{v}}
\def\dstmtSet{\mathcal{S}_\textsf{d}}
\newcommand{\pAss}[1][\mathcal{S}] {\mathcal{A}_{#1}}
\DeclareMathOperator{\truth}{truth}

% Experimental test symbols
\newcommand{\exptSet}{\mathcal{E}}
\newcommand{\expt}[1][e] {\mathsf{#1}}
\DeclareMathOperator{\result}{result}
\def\SUCCESS{\textsc{success}}
\def\FAILURE{\textsc{failure}}
\def\UNDEF{\textsc{undefined}}

% Statements
\def\tautology{\top} % Tautology
\def\contradiction{\bot} % Contradiction
\newcommand{\stmt}[1][s] {\mathsf{#1}} % Statement
\newcommand{\tstmt}[1][s] {\bar{\mathsf{#1}}} % Theoretical statement


% Relationships between statements
\def\comp{\doublefrown} % Compatibility
\def\ncomp{\ndoublefrown} 
\def\narrower{\preccurlyeq} % Narrowness
\def\nnarrower{\npreccurlyeq}
\def\snarrower{\prec}
\def\nsnarrower{\nprec}
\def\broader{\succcurlyeq} % Broadness
\def\nbroader{\nsucccurlyeq}
\def\sbroader{\succ}
\def\nsbroader{\nsucc}
\def\indep{\upmodels} % Independent
\def\nindep{\nupmodels}

% Experimental domains and related symbols
\newcommand{\edomain}[1][D] {\mathcal{#1}} % Experimental domain
\newcommand{\tdomain}[1][D] {\bar{\mathcal{#1}}} % Theoretical domain
\newcommand{\basis}[1][B] {\mathcal{#1}} % Basis
\newcommand{\resPoss}[1][x] {\mathring{#1}} % Residual possibility
\newcommand{\estPoss}[1][x] {\dot{#1}} % Established possibility


% Formatting for experimental relationships
\newcommand{\erel}[1][r] {#1}

% Formatting for sentence statements
\newcommand{\statement}[1] {\emph{``#1"}}

% Formatting for reference
\newcommand{\refStmt}[1][r]{\textbf{#1}}

\DeclareMathOperator{\ver}{ver}
\DeclareMathOperator{\fal}{fal}
\DeclareMathOperator{\und}{und}

\DeclareMathOperator{\interior}{int}
\DeclareMathOperator{\exterior}{ext}

\usepackage{xcolor} % Required for specifying colors by name
\definecolor{sectionNumbers}{RGB}{44, 103, 0}


\renewcommand\thesubsection{\thesection.\Alph{subsection}}
\renewcommand{\theequation}{\thesection.\arabic{equation}}

\newtheorem{assump}{Assumption}
\renewcommand*{\theassump}{\Roman{assump}}

\newtheorem{axiom}[equation]{Axiom}
\newtheorem{defn}[equation]{Definition}
\newtheorem{prop}[equation]{Proposition}
\newtheorem{coro}[equation]{Corollary}
\newtheorem{thrm}[equation]{Theorem}

%\theoremstyle{definition}

\newenvironment{remark}{\emph{Remark}.}{}
\newenvironment{rationale}{\emph{Rationale}.}{\qed}
\newenvironment{justification}{\emph{Justification}.}{\qed}
\renewenvironment{proof}{\emph{Proof}.}{\qed}


\title{A model for the experimental verification of the continuum  OR \\ The continuum from experimental verification OR \\ A model of the continuum from experimental verification OR \\ Experimental verification and the continuum}
\author[1]{Gabriele Carcassi}
\author[1]{Christine A. Aidala}
\affil[1]{
	Physics Department\\
	University of Michigan
	}

\date{\today}
\begin{document}

\maketitle


\begin{abstract}
We present a model for the continuum that starts from requirements of experimental verification. That is, instead of starting from abstract mathematical structures or constructions, we posit that we can use a physical object as a reference such that we are able to verify whether another object lies before or after. We then lay out a series of necessary and sufficient conditions such that the experimentally distinguishable cases defined by a set of references can be labeled with a real number. We find that most of the conditions are needed to recover a more general notion of ordering, while the additional conditions to recover the reals (or the integers) are minimal. We argue that, at Planck scale, the conditions for ordering are not tenable. How and why this is may give new insights to people interested in space-time structure.
\end{abstract}

\section{Introduction}

In our ongoing project, Assumptions of Physics, we aim to find a set of minimal assumptions from which the different physical theories can be derived. By doing this as formally as possible, we are forced to specify all our implicit starting points, which provides greater insight and new ideas for solving open problems. While other approaches have a similar goal, see for example Refs.~\cite{PhysRevA.84.012311,QLogicReview,Hardy:2001jk,ludwig_hein_2013}, there are a number of key differences in our approach.

The first difference is that we want the different theories (e.g. classical Hamiltoniam mechanics, quantum particle mechanics, thermodynamics, ...) to be derived from starting points that are immediately intuitive to the non-expert. The assumptions we work with describe, for example, whether the state of the whole system is equivalent to the state of its parts (i.e. reducibility), or whether knowledge of the future state is equivalent to knowledge of the past state and vice-versa (i.e. determinism and reversibility). Physically, the idea is that we have a system to study and, under a few simplifying assumptions, we find that the system is adequately described by one of the theory. The set of assumptions for each theory, then, work both as a starting point to rederive the theory and as a clear demarcation of its realm of applicability. For example, Hamiltonian mechanics is derived on the assumption of determinism and reversibility, therefore we know it will not work if our system is irreversible.

Another difference is that our approach aims to start with primitives that are necessary to do physics, and not with requiring abstract mathematical structures that, at the very end, will give us something that is interpretable as physics. For example, one of our basic building block is the notion of a verifiable statement: an assertion for which an experimental test is available that would confirm, in finite time, that the assertion is true. As one can imagine, without such a notion, we would have no experimental verification, which means no possibility of doing science. In general, the goal is to start with a tight connection between the physical concepts and their respective formal representations, so that it is always clear what the mathematical structure represents physically and no mathematical objects are unphysical. Ideally, this would tell us, for example, what a topology or a differentiable structure represents physically in current theories, and when those are valid approximations of our physical concepts. In this particular work, the goal is to provide that understanding for real valued quantities.

The last difference we want to highlight is that we typically start at a lower level. For example, we do not assume probability spaces, which are already constructions upon sigma-algebras and measures, and sigma-algebras are typically constructed from the topology of the space. We instead aim to recover those as well. This is particularly important if one is interested in the structure of space-time, since its topology and sigma-algebra are the most foundational aspects.

What we want to present here is a construction of continuous quantities from the basic notion of verifiable statements, assertion that can be verified experimentally in finite time. We believe this is of interest to those working on the fine structure of space-time as it gives us necessary and sufficient operational requirements such that a set of experimentally distinguishable cases can be labeled by real numbers. The basic building block to construct quantities is the notion of a reference: a physical object that allows to distinguish between a before and an after. These generalize the notion of ticks of a ruler, pulses within a timing system, reference weights for a balance scale. The notion of a quantity, then, is not something that exists a priori, but something that is constructed through a set of prepared references, with known logical relationships among them. The goal, then, is to understand what are the necessary and sufficient conditions that a set of references must satisfy so that they distinguish a set of cases that can be labeled by real numbers.

Note that the set of real numbers can be characterized in different ways since they are usually associated with multiple structures. It is important to stress that, in our case, we are interested in the most basic characterization, which is in terms of ordering. Any totally ordered set that is dense, complete and contains a countable dense subset is order isomorphic to the real numbers. One can, through a non-linear monotonic transformation, change the group/field structure while preserving the ordering, but it is not possible to do the opposite. In this sense, the ordering structure is more fundamental than the group/field structure. Also note that the ordering is exactly enough to define the topology and nothing more (i.e. no geometric information).

The first main result is that much of the requirements are needed simply to impose an ordering. Comparatively, the requirements to turn that ordering into the one of the continuum are not as involved. The second main result is that the requirements for ordering are such that they are most likely not realized at Planck scale, leading to a breakdown not just of real valued quantities, but essentially of any scalar numeric quantity and, consequently, the mathematical techniques that rely on them. While we do not have yet a clear idea how to proceed in those cases, the work forced us to develop techniques to construct the ordering from more fundamental notions. The essential difficulty was to find concepts that are still physically intuitive that do not implicitly lead to circular arguments (e.g. any pictorial representation is inherently ``ordered" and should be avoided). We believe these may be useful to other as they may give new ideas and insights.

On the technical level, the full details are available at \cite{Carc3} which effectively function as a large appendix. Here we provide a summary of the mathematical definitions and the results, skipping much of the details, in particular the proofs and the parts that are not strictly necessary for our purposes.

\section{Logical contexts and experimental domain}

Our starting point is that a physical theory consists, at the very least, of a set of statements with well defined logical relationships defined by the semantic of the theory. We leave open the question of how those are constructed or articulated, but a set of logically consistent statement must be given. Some, but not all, the statements are experimentally verifiable, that is we have at our disposal a test that, if the statement is true, the test terminates successfully in finite time. We again leave open the question of how that is done and what constitutes enough experimental evidence, but a set of experimental tests must be given. For example, \statement{the mass of the particle is less than 1 keV} can be considered verifiable while \statement{the mass of the particle is exactly 1 keV} cannot, since we cannot perform infinite precision measuremnets.

The semantic of a specific statement (e.g. \statement{the mass of the electron is 0.5 $\pm$ 0.05 MeV} ) may in general depend on the definitions of the different terms and the characterization of the experimental procedures. As such, our most fundamental object is a set $\logCtx$ called \textbf{logical context} and each element $\stmt \in \logCtx$ is a \textbf{statement}. Each logical context is equipped with a set $\pAss \subseteq \Bool^\logCtx$, where $\Bool = \{ \TRUE, \FALSE \}$. Each $a \in \pAss$ represents a \textbf{possible assignment}, a possible way to set the truth of each value that is consistent with the semantic of the statements. For example, there will be no possible assignment where \statement{the particle is an electron} and \statement{the particle is a photon} are true at the same time.

This basic structure allows us to define:
\begin{itemize}
	\item \textbf{tautologies} and \textbf{contradictions}, noted $\tautology$ and $\contradiction$, as statements that are respectively always true or always false in all possible assignments (i.e. for all $a \in \pAss$, $a(\tautology) = \TRUE$ and $a(\contradiction) = \FALSE$)
	\item a notion of \textbf{statement equivalence}, noted $\stmt_1 \equiv \stmt_2$, if two statements have the same value in all possible assignments (i.e. for all $a \in \pAss$, $a(\stmt_1) = a(\stmt_2)$)
	\item a notion of \textbf{narrowness}, noted $\stmt_1 \narrower \stmt_2$, if the second statement is true whenever the first one is (i.e. for all $a \in \pAss$ where $a(\stmt_1) = \TRUE$ we have $a(\stmt_2) = \TRUE$); the opposite notion is called \textbf{broadness} 
	\item a notion of \textbf{compatibility}, noted $\stmt_1 \comp \stmt_2$, if the statements can be true at the same time (i.e. there exists an $a \in \pAss$ such that where $a(\stmt_1) = a(\stmt_2) = \TRUE$)
\end{itemize}
We can also define a notion of \textbf{independence} on a set of statement $S$, noted $\stmt_1 \indep \stmt_2$ for a binary set, if fixing the truth value of any subset does not constrain the truth value of the others, though it will not be used here.

Furthermore, the set of equivalence classes $\logCtx_{/\equiv}$ will form a complete Boolean algebra with the standard negation/conjunction/disjunction operations and properties, which also means $(\logCtx_{/\equiv}, \narrower)$ is an ordered set. This structure captures the idea that a physical theory is a set of logical statements with well defined logical relationships. From now on, unless otherwise stated, statement will refer to its equivalence class.

To keep track of experimental verifiability, every logical content $\logCtx$ comes equipped with a subset $\vstmtSet \subseteq \logCtx$, and each element $\stmt \in \vstmtSet$ will be called a \textbf{verifiable statement}. The idea is that, for each verifiable statement, we have at our disposal an experimental test that, if the statement is true, the test terminates in finite time. The requirement of experimental verifiability over finite time imposes the following conditions:
\begin{itemize}
	\item all tautology and contradictions are verifiable, since the context assumes them to be always true or false
	\item a statement equivalent to a verifiable statement is verifiable, since we can use the test of the second to test the first
	\item the finite conjunction and the countable disjunction of verifiable statements is verifiable, since we can construct general algorithms for both cases that simply execute the original tests in succession appropriately
\end{itemize}
Note that $(\vstmtSet, \narrower)$ is also a lattice, and is embedded in $(\logCtx, \narrower)$. This double structures allows us to keep track of what is logically consistent and what is experimentally verifiable within a theory.

Finite time experimental verification also imposes a limit on how many statements one can verify. Given an arbitrarily long amount of time, a countable set of verifiable statement represents the maximum. Given a set $S \subseteq \vstmtSet$ of verifiable statements, we call a \textbf{basis} $\basis \subset S$ a subset from which all of $S$ can be generated through finite conjunction and countable disjunction. We define an \textbf{experimental domain} $\edomain_X \subseteq \vstmtSet$ a set of verifiable statements that includes the tautology and the contradiction, that is closed under finite conjunction and countable disjunction and that can be generated by a countable basis. An experimental domain represents the most that can be learned experimentally about a particular scientific problem. Note that an experimental domain is a Heyting algebra.

An experimental domain will contain the negation of a verifiable statement only if its relative test always terminates. Even if the test does not always terminate in the negative case, though, it still conceptually creates a possible case within the context. Given an experimental domain $\edomain_X$ we construct its \textbf{theoretical domain} $\tdomain_X$ by closing under negation, as well as the original finite conjunction and countable disjunction. This represents the set of statements for which an experimental test is well defined, regardless of whether it will terminate or not. By DeMorgan rules, the theoretical domain is closed under countable conjunction as well, so it is a $\sigma$-complete Boolean algebra.

Within the theoretical domain, we define the  \textbf{possibilities of the domain} $X = \{ x \in \edomain_X \, | \, \forall \tstmt \in \tdomain_X $ either $x \narrower \tstmt$ or $x \ncomp \tstmt\}$ as those statements that, if true, will define the truth value for all other statements in the theoretical domain. These correspond to the cases that are experimentally distinguishable through the verifiable statements in the experimental domain. Conceptually, each possibility corresponds to a unique possible assignment for the domain. Mathematically, each possibility is a minterm of the basis (i.e. a conjunction where each element of the basis appears exactly once, either negated or not) that is not a contradiction.

Since every statement of the experimental domain can be expressed as a disjunction of minterms of the basis, for each verifiable statement $\stmt \in \edomain_X$ we can find a set $U \subseteq X$ such that $\stmt = \bigOR_{x \in U} x$. Similarly, for each theoretical statement $\tstmt \in \tdomain_X$ we can find a set $A \subseteq X$ such that $\tstmt = \bigOR_{x \in A} x$. Logical operations on the statements become set operations on the sets, which means that an experimental domain induces a natural topology on its possibilities, while a theoretical domain induces a natural $\sigma$-algebra, which is the Borel algebra of the natural topology.

This basic structure gives a well defined map between the physical objects and their mathematical counterparts. For example, given a theoretical statements $\tstmt$ we can define its verifiable part $\ver(\tstmt)$ as the broadest statement that is narrower than $\tstmt$. This corresponds to the cases in which the statement is true and the test terminates. If a statement is verifiable, then $\ver(\tstmt) \equiv \tstmt$. Topologically, this corresponds to the interior of a Borel set and, indeed, an open set corresponds to its interior. Conversely, we can define a falsifiable part $\fal(\tstmt)$ which, topologically, corresponds to the exterior of a Borel set. A statement that has nor interior or exterior, like the set of all rationals over a real line, corresponds to a statement for which the test never terminates: an undecidable statement. One can proceed this way and re-understand all definitions and proofs.

The general result is that any set $X$ of experimentally distinguishable cases has to come with a $\mathsf{T}_0$ second countable topology that represents the verifiable statements and a Borel algebra that represents the theoretical statements. These structures are the foundation for most of the other mathematical structures used in science (e.g. differential topology, measure theory, probability theory, ...) and this framework provides a strong justification for them and a direct physical meaning. It also gives us an understanding of exactly why those requirements are needed. A topological space that is not second countable, for example, would correspond to a set of possibility that cannot be, even in the limit, experimentally distinguished. A set with cardinality greater then that of the continuum, for example, does not allows a second countable topology and cannot correspond to a set of experimentally distinguishable cases: each element, in fact, must be identified with the output of a countable binary tests, which roughly corresponds to a real number in base two. A non-Borel set is also non-physical as it does not correspond to a statement for which we can construct a test, regardless of whether it terminates. In our view, much confusion is there in physics because we do not have such precise and methodical mapping between physical ideas and mathematical ones.

To sum up, we start with an experimental domain $\edomain_X$ which can be thought as a topology/locale/Heyting algebra with a countable basis. We close under negation to obtain a theoretical domain $\tdomain_X$, which corresponds to the related Borel algebra, and there find the points of our space $X$, which represent the physically distinguishable cases. We again stress that the points are generated from the verifiable statements. This framework allows us to ask the question: when is a set of physically distinguishable cases identifiable with the real numbers? Under what conditions the points become isomorphic to those of a real line?

\section{References and experimental ordering}

In general, we can concentrate on a single property of an object and measure that independently. It is fairly typical to define a quantity as an ordered property, where different values can be compared to see which one is greater. We want to capture these notions in our framework.

If we concentrate on a single property of an object, we can select the verifiable statement that only pertain to that property. These will form an experimental domain $\edomain_X$ whose possibilities $X$ will correspond to all possible property values. Recall that, given a totally ordered set $(\mathcal{Q}, \leq)$, the \textbf{order topology} is the one generated by sets of the form $$(a, \infty) = \{q \in \mathcal{Q} \, | \, a < q\} \;,\; (-\infty, b) = \{q \in \mathcal{Q} \, | \, q < b\}.$$
The standard topologies for the integers and the reals are simply the order topologies with their respective ordering. We will say that an experimental domain is \textbf{naturally ordered} when the possibilities are totally ordered and the natural topology is the corresponding order topology. Our goal, then, is to understand when the logical relationships between verifiable statements for a particular property are such that the possibilities are naturally ordered like the real numbers.

First note that the basis of the order topology corresponds to verifiable statements of the form \statement{the property value is after $a$} and \statement{the property value is before $b$}. This parallels what happens in practice: in general we have a set of references (e.g. marks on a ruler or ticks of a clock) which ideally define known values of the quantity, and we are able to test whether the object is before or after that reference value. We say ideally because, in general, a reference does not span a single value. For example, a mark on a ruler will also have an extent in space. Also note that, in general, the object being measured can also have an extent. For example, an event may start before the tick of a clock and finish after. Before and after, then, are not necessarily mutually exclusive. Our most general definitions, then, need to account for these cases as well.

Let us define a \textbf{reference} $\refStmt = ( \stmt[b], \stmt[o], \stmt[a] )$ as a tuple of three statements (the before/on/after statements) such that:
\begin{enumerate}
	\item we can verify whether the object is before or after the reference: $\stmt[b]$ and $\stmt[a]$ are verifiable statements
	\item the reference itself must occupy some values : $\stmt[o] \nequiv \contradiction$
	\item if the object is not before or after, it is on the reference: $\NOT \stmt[b] \AND \NOT \stmt[a] \narrower \stmt[o]$
	\item if the object is before and after, it is also on the reference: $\stmt[b] \AND \stmt[a] \narrower \stmt[o]$
\end{enumerate}
A set of references generates an experimental domain in the following way. Let $R = \{( \stmt[b]_i, \stmt[o]_i, \stmt[a]_i )\}_{i \in I}$ be a set of references. Let $\basis_b = \{\stmt[b]_i\}_{i \in I}$ be the set of all before statements and $\basis_a = \{\stmt[a]_i\}_{i \in I}$ be the set of all after statements. The experimental domain $\edomain_X$ generated by $R$ is the one generated by all before and after statements $\basis_b \cup \basis_a$. The \textbf{before domain} $\edomain_b$ is the domain generated only by the before statements $\basis_b$ and the \textbf{after domain} $\edomain_a$ is the domain generated only by the after statements $\basis_a$. The possibilities $X$ of the domain generated by $R$ consists of all the cases that are experimentally distinguishable given the references.

We can see that if $(X, \leq)$ is a totally ordered set of mutually incompatible statements (i.e. no two can be true at the same time) whose union is a tautology (i.e. one of them must be true), we can create the collection of triples $R = \{ \bigOR\limits_{x_b < x} x_b , x , \bigOR\limits_{x_a > x} x_a \}_{x \in X}$. If the before and after statements are verifiable, then the triples are references and the natural topology of the experimental domain they generate is exactly the order topology. Therefore, every naturally ordered experimental domains can be generated by a set of references. What we are looking is for the opposite conditions: what are the minimum requirements on a set of references such that they generate a naturally ordered experimental domain?

\subsection*{Requirements for ordering}

One of the main guiding insights is that, in a total order, $(a, +\infty) ^C = (-\infty, a]$. If $a \geq b$ then we have $(-\infty, b) \subseteq (-\infty, a]$ and if $a < b$ then $(-\infty, a) \subset (-\infty, b]$. This means that if $X$ is totally ordered, then all the sets of them form $(-\infty, x)$ and the complements of $(x, \infty)$ will be ordered by set inclusion. In terms of statement, this means that all the before statements $\basis_b$ and the negation of the after statements $\NOT(\basis_a)$ are ordered by narrowness. This, turns out, is a necessary condition.

We say a reference is \textbf{strict} if the before/on/after cases are mutually exclusive. That is, $\refStmt = (\stmt[b], \stmt[o], \stmt[a])$ is such that $\stmt[b] \ncomp \stmt[a]$ and $\stmt[o] \equiv \NOT \stmt[b] \AND \NOT \stmt[a]$. For a strict reference we then have $\stmt[b] \narrower \NOT \stmt[a]$. This is automatically achieved for discrete quantities, since object do not have an extent over them. For those that have an extent, for example when measuring the position of an object, this assumes that the extent of the object to be measured is very small compared to the extent of the reference so that the object can always be considered wholly before/on/after the reference.

We say two references $\refStmt_1 = (\stmt[b]_1, \stmt[o]_1, \stmt[a]_1)$ and $\refStmt_2 = (\stmt[b]_2, \stmt[o]_2, \stmt[a]_2)$ are \textbf{aligned} if for any $\stmt_1 \in \{ \stmt[b]_1, \NOT\stmt[a]_1\}$ and $\stmt_2 \in \{ \stmt[b]_2, \NOT\stmt[a]_2\}$ we have 
$\stmt_1 \narrower \stmt_2$ or $\stmt_2 \narrower \stmt_1$. A set $R$ of references is aligned if any pair of references is aligned. If two references are aligned and do not overlap (i.e. $\stmt[o]_1 \ncomp \stmt[o]_2$) then one reference must be before the other. Formally, one reference is before the other, noted $\refStmt_1 \less \refStmt_2$, if $\stmt[b]_1 \OR \stmt[o]_1 \ncomp \stmt[o]_2 \OR \stmt[a]_2$. If they do not overlap, they at least are such that we can imagine they have boundaries that come one after the other. Moreover, alignment implicitly requires that we can always tell references apart such that their relationship are always expected to be the same. If they jiggle around there can be no fixed, well-defined, alignment.

Another insight is that $(-\infty, b) \subset (-\infty, b]$ and no other set of the form $(-\infty, x)$ or $(-\infty, x]$ can be placed in between. In terms of statement, this means that the totally ordered set $( \basis_b \cup \NOT(\basis_a), \narrower)$ is formed by pairs of consecutive elements, one for each possible value.

We say a set of references $R$ is \textbf{refinable} if given two strict references $\refStmt_1 = ( \stmt[b]_1, \stmt[o]_1, \stmt[a]_1)$ and $\refStmt_2 = ( \stmt[b]_2, \stmt[o]_2, \stmt[a]_2)$ we can always:
\begin{itemize}
	\item find an intermediate one if they are not consecutive; that is, if $\refStmt[r]_1 < \refStmt[r]_2$ but $\refStmt[r]_2$ is not the immediate successor of $\refStmt[r]_1$ (i.e. $\NOT \stmt[a]_1 \snarrower \stmt[b]_2$), then we can find a strict reference $\refStmt_3$ aligned with $\edomain$ such that $\refStmt[r]_1 < \refStmt[r]_3 < \refStmt[r]_2$.
	\item refine overlapping references if one is finer than the other; that is, if $\stmt[o]_2 \snarrower \stmt[o]_1$, we can find a strict reference $\refStmt_3$ aligned with $\edomain$ such that $\stmt[o]_3 \narrower \stmt[o]_1$ and either $\stmt[b]_3 \equiv \stmt[b]_1$ and $\refStmt_3 < \refStmt_2$ or $\stmt[a]_3 \equiv \stmt[a]_1$ and $\refStmt_2 < \refStmt_3$.
\end{itemize}
This conditions means that we are able to cover the whole space with references fine enough to resolve all possible overlaps. This is what allows us to pick out individual values as we can ultimately find a before statement that is broadest narrower statement of each negated after statement.

With the given definitions, we are able to state the following three theorems, the proofs of which are available at \cite{Carc3}.
\begin{thrm}[Reference ordering theorem]
	An experimental domain is naturally ordered if and only if it can be generated by a set of refinable aligned strict references.
\end{thrm}
\begin{thrm}[Discrete ordering theorem]
	An experimental domain is naturally ordered with a discrete quantity if and only if it is generated by a set of refinable aligned strict references with a sparse order (i.e. only finitely many references between two)
\end{thrm}
\begin{thrm}[Continuous ordering theorem]
	An experimental domain is naturally ordered by a continuous quantity if and only if it is generated by a set of refinable aligned strict references with a dense order (i.e. infinitely many references between two)
\end{thrm}

Note that the only extra condition to recover the continuous and the discrete orderings is the cardinality of references found between two. This may be unexpected for the continuous case, since the real numbers not only require the ordering be dense, but also complete and to have a countable dense subset. What happens is that the experimental domain automatically provides the other two conditions automatically. The closure of the domain under countable disjunction requires the ordering to be complete. The countable basis provides the countable dense subset. Therefore the dense ordering is the only extra condition.

The other interesting aspect is that in the discrete order all the before and after statements are not only verifiable, but also falsifiable. In fact, this is the only ordering with that characteristic. On the other hand, in the continuous order none of the before and after statements are falsifiable. In fact, this is the only ordering with that characteristic. This stresses that, experimentally, discrete and continuous quantities are qualitatively different.

\subsection*{At finer scale}

Now that we have understood what are the requirements to experimentally define a continuous quantity, we can ask the following question: as we increase spatial and temporal resolution and we approach Plank scale, can we still satisfy those conditions? Or can they only be satisfied as an approximation at large enough scale?

At this point, we do not aim lay out a convincing argument for or against. Rather, we want to show what are the main points, both conceptually and technically, that one may raise so that one can understand how to construct his own argument. We believe this to be more interesting because, once one decides how and why those assumptions fail, he is already on the path to understand what alternative he wants to explore. We are going to reason in terms of space, but similar arguments can be made in terms of time.

One of the requirements is that references are strict, that is the before/on/after cases are mutually exclusive. When measuring position in space, where finite objects have a finite extent, those cases are not in general mutually exclusive because of overlaps. We can ignore the problem by assuming that the object whose position we want to measure is much smaller than the reference, in which case we can assume that the object is wholly before/on/after the reference. But in order to derive continuous quantities, we also assume that we can take finer and finer references. If the objects we use as references of position are the same objects of which we want to measure the position we logically come at an impasse. This is going to be a problem for particles (i.e. fields excitation) as well since the overlap can be in terms of their wave-packet. In these cases, it is not clear one can make the claim that a particle will always be wholly before/on/after the other.

Another requirement is that references are aligned, that is we can establish clear before/after relationship between the edges of the references. One issue here is that we always need to be able to distinguish between two references such that fixed ordering relationship can be established. If the finest references are individual particles, and these are indistinguishable from each other, it is not clear how this is going to work. Note that we cannot use position itself to distinguish them because we run into circular arguments: we want to use the reference to distinguish position not the other way around. Another problem is that we cannot talk about a substructure for individual particles, therefore it is not clear whether the edges (i.e. where the particle ``starts") can be well defined if particles are used as references.

Another requirement is that references are refinable, that is we can always find finer references that resolve the overlap or be placed in gaps. While it is not necessary to have them all in the same setup as we can, in principle, repeat the experiment with different references in place to get different information, we still need to be able to construct them. While it is generally accept that there is a limit to how small a wave-packet can be made, meaning how small the extent of an object (or a reference) can be, there is no such limit between the distance between two objects. Therefore we can imagine creating situations in which two references are consecutive and yet no other reference can fit in between; or two references overlap yet no other reference can refine the overlap.

The punchline here is that if a single argument along these lines is accepted, the result is that we lose not just the real numbers, we lose ordering itself. What would happen is that, at short scales, ordering becomes fuzzy. Before and after, in both space and time, is not a sharp distinction. At least, we would be unable to define it in a way that is experimentally verifiable. With a loss of ordering, there is not a clear way to keep a sharp notion of distance and all other geometrical ideas. What we would have in its place would depend on how the structure breaks down and what new assumptions can be taken.



\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}