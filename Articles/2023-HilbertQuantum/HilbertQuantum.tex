\documentclass[10pt,twocolumn, nofootinbib]{revtex4-2}
%\documentclass[aps,pra,10pt,twocolumn,floatfix,nofootinbib]{revtex4-1}
%\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{assumptionsofphysics}

%\usepackage{amsmath}
%\usepackage{mathrsfs}
%\usepackage{amsfonts}
%
%\usepackage{graphicx}
%\usepackage{hyperref}
%\hypersetup{
%	colorlinks=true,
%	citecolor=blue,
%	urlcolor=blue,
%	linkcolor=blue
%}
%\urlstyle{same}
%\frenchspacing
%
\def\>{\rangle}
\def\<{\langle}
\DeclareMathOperator{\erf}{erf}

\begin{document}

\title{The unphysicality of Hilbert spaces}
\author{TBD}
\affiliation{Physics Department, University of Michigan, Ann Arbor, MI 48109}

\date{\today}


\begin{abstract}
TBD
\end{abstract}

\maketitle

\section{Introduction}

Hilbert spaces have been the cornerstone of quantum mechanics since von Neumann (\cite{von_neumann_mathematische_1996}). Their use made available a vast number of theorems (Gleason, Riesz, Wigner, Stone, etc.) that made up the mathematical backbone of the theory and also represented a role model of mathematical rigor that people working on quantum field theory would try to achieve decades later \cite{haag_discussion_2010}. Wightman even took von Neumann's book to be the fulfillment of a project Hilbert himself kicked off with his problems on the foundations of mathematics (\cite[p. 157]{browder_hilberts_1976}): to axiomatize the physical sciences. But, despite the undeniable importance of wanting to set physics on a firm mathematical footing, we must remember that by ``axioms,'' they meant ``physically motivated constraints'' more than statements that can be immune to question, rethink, and, if necessary, revise.\footnote{For a more extended discussion of von Neumann's axiomatics and their physical inputs, see \cite{redei_soft_2006, landsman_axiomatization_2022}.}

Now, there are well-known shortcomings of Hilbert spaces, but they are deemed unproblematic: states are rays, not vectors; the Dirac delta is a distribution, not a function; and some elements from $L^2(\mathbb{R})$ don't seem apt candidates to be wave functions. Given the importance Hilbert spaces have had and the issues we have let slide, it's not a surprise that they have become fossilized as parts of axiomatic systems\footnote{Even axiomatic formulations of quantum field theory \cite{haag_local_1996, horuzhy_introduction_1990} that don't need to use Hilbert spaces to make meaningful claims about quantum-mechanical observables and states can reassure physicists unfamiliar with this approach by recovering the Hilbert spaces they know and love through the GNS construction.} without even considering whether we can do quantum mechanics with weaker assumptions. So, despite all their success, perhaps it's time to ask if using Hilbert spaces to describe quantum states, an assumption whose physical motivation was meant to be revised as time passed, has become a dogma.

\section{On the physicality of Hilbert spaces}

Let us first clarify the standard we believe should be used to judge the physicality of a formal definition. Suppose we have a physical system under study in a given condition. A mathematical definition is \textbf{physical} if it properly characterizes a physical system. That is, if it can be shown that the mathematical definition is needed to capture and only capture a particular aspect of the physical system. On the other hand, a mathematical definition is \textbf{unphysical} if it can be shown to require physical properties or operations that cannot be implemented physically.

For example, suppose we have a set of physically distinguishable objects, meaning that we can tell them apart through an experimental test. Experimentally, the best we can do is collect finite information in finite time. If given an arbitrarily long time, we can collect an arbitrary amount of finite information. An element of the set%TODO: Set of what? The example is clear, but this sentence is a bit unclear.
, then, must be identified by, at most, a countably infinite sequence of ones and zeros so that, at some point, we can tell the difference between the two sequences and, therefore, the objects. The set of countable sequences of zeros and one can be understood as the binary expansion of real numbers between zero and one, which has the cardinality of the continuum. Therefore, any definition requiring a set of physical objects to have cardinality greater than the continuum is \textbf{unphysical}. For example, non-separable Hilbert spaces have cardinality greater than the continuum and, therefore, would be considered unphysical under this definition.

Naturally, this does not mean all sets with a cardinality of the continuum or lower are physical. In general, testing physicality is harder as we need to check that all the mathematical features map to physical features and that no physical feature is left behind. Clearly, postulating that ``the state space of quantum states has cardinality no greater than that of the continuum'' is certainly \textbf{physical}, but this tells us little. Let us then see what elements of Hilbert spaces we should consider physical in the context of quantum mechanics. %TODO: I worry that this discussion on cardinality might be confusing since the "elements of Hilbert spaces" we'll discuss are parts of the definition of a Hilbert space, not the members of a set of physical objects.

\subsection{Inner vector space}

Recall that a Hilbert space is a complete inner product space. That is, it is a vector space with an inner product, and its Cauchy sequences converge under the norm defined by the inner product. We will look at the first two structures briefly, leaving all detail in the appendix, as their physical significance is unsurprising.

Roughly speaking, a vector space is a set whose elements can be combined linearly: they can be multiplied by constants and summed. If one regards superpositions as physical requirements of quantum theory, one may think this structure is physical. However, the ability to interpret linear combinations as superpositions requires keeping track of orthonormal vectors. If we can only know whether two vectors are in the same ray, we cannot recover the idea of a probability amplitude, as those are the coefficients of a linear combination between normalized and orthogonal states that return another normalized state. Therefore, the vector space structure, by itself, is not physical.

If we add the inner product, we can define norm and orthogonality, and therefore we can indeed express superpositions. Additionally, the inner product structure also defines the Born rule, the transition probability during measurement. If one is comfortable considering superpositions and the Born rule to be physical requirements of quantum mechanics, then the inner product structure is \textbf{physical}. However, some may not consider superpositions as representing actual physical objects but more as mathematical constructs; others may object that the Born rule, in its standard interpretation, defines the probability of transitions while a state space should be defined at equal times; others can argue that the rays define the states, and therefore the requirements should only be in terms of those objects. For those and other reasons, we offer an alternative justification of the physicality of inner product vector spaces. Here is a summary, but the details are in the appendix.

Given that, experimentally, no preparation or measurement is perfect, a physical theory must define the space of statistical ensembles. Mathematically, these form a convex set that physically represents a set that allows statistical mixtures. The geometry of the space of statistical ensembles is uniquely defined by the inner product and vector space structures, which means properties of the inner product space can be reexpressed as properties of the space of mixtures.\footnote{There is a rich literature on Generalized Probability Theory in which people reconstruct Quantum Theory by imposing requirements on convex spaces. TODO: cite.} For example, we can characterize a superposition in the following way: a pure state $\psi$ is expressible as a superposition of other pure states $\{\phi_i\}$ if and only if there is a mixed state $\rho$ that can be equivalently expressed as a mixture of $\{\phi_i\}$ or as a mixture of $\psi$ and other pure states. That is, the ability to create a superposition is conceptually equivalent to the ability to prepare the same mixture in different ways, another feature particular to quantum mechanics. Additionally, the inner product can be shown to be equivalent to determining the entropy of all equal mixtures of pairs of states. Since we must be able to prepare statistical mixtures and characterize their entropy for any physical theory and the complex inner product space structure is exactly what is required to model the correct relationships of quantum mixtures, therefore \textbf{the inner product space structure is physical}.

\subsection{Completeness}

We now turn to the last property of Hilbert spaces: completeness. Mathematically, this means that the space includes the limit of every Cauchy sequence; physically, this property is more difficult to characterize. We can look at an equivalent characterization \cite[Theorem 13.8, p. 330]{roman_2008}. %\footnote{Roman 2008, p. 330 Theorem 13.8	Roman, Stephen (2008), Advanced Linear Algebra, Graduate Texts in Mathematics (Third ed.), Springer, ISBN 978-0-387-72828-5}
An inner product vector space is complete if, given a series of vectors
$$ \sum _{k=0}^{\infty }u_{k}$$
such that
$$ \sum _{k=0}^{\infty }\|u_{k}\|<\infty,$$
the series converges in the space. This characterization of completeness is in terms of linear combinations. It tells us that we can prepare states that are superpositions of infinitely many elements or, equivalently, as we have seen, mixed states comprised of infinitely many pure states. Is this a physical requirement or just mathematical convenience?

Experimentally, we can create a superposition by splitting a beam along multiple paths, which is typical in quantum optics.\footnote{TODO: cite} The mathematical expression above means splitting the original state into infinitely many progressively small components and being able to place them where we please. However, that would assume that our experimental set-up spans an infinite region of space. This does not sound physical.

Again, given the difficulties of understanding superposition, let us reframe the result in terms of statistical quantities. Suppose we can prepare pure states with arbitrarily finite expectation values for position. Then, completeness means we can also prepare pure states that fall off at infinity as $\frac{1}{x^2}$. The expectation value of $x$ would be proportional to the integral of a function that falls off as $\frac{1}{x}$, which diverges. Clearly, this does not make physical sense. When we posit that a quantity, like position, has an infinite range of possible values, we simply mean that the observed value can be arbitrarily large, not that we can literally spread values over an infinite range.\footnote{This is the difference between potential infinity and actual infinity. Now, ``multiplying by $x$'' is not a well-defined operator in $L^2(\mathbb{R})$ unless we restrict the configuration space of our free particle to a compact interval of the real line. The fact that position operators must be bounded should recover some physicality, but that wouldn't be a property of the states themselves, which is what we're interested in studying.}

The argument can be summed up as follows. On physical grounds, we assume the existence of quantities, like position, that can take arbitrarily large values. This requires that, for each possible value, there must exist some state whose expectation matches that value. Requiring completeness mathematically forces us to posit states with an infinite expectation value, but that cannot be implemented physically.\footnote{Philosophers interested in perturbative quantum field theory have formulated interpretive strategies to make sense of some of the divergent series that arise, but surveying them would take us too far afield. For an example, see \cite{miller_mathematical_2023}.} The mathematical definition implicitly assumes objects that cannot be physically realized, so \textbf{the use of completeness for the space of quantum systems in unphysical.}

\subsection{Impact of unphysicality}

It should not be surprising that closure over infinite sequences is problematic, as properly handling infinity is one of the key problems in mathematics.\footnote{Weyl stated, ``Mathematics is the science of the infinite, its goal the symbolic comprehension of the infinite with human, that is finite, means.'' Hermann Weyl, "The Open World: Three Lectures on the Metaphysical Implications of Science," (1932) as quoted in Mind and Nature: Selected Writings on Philosophy, Mathematics, and Physics (2009) ed. Peter Pesic. Several branches of mathematics were developed to handle large and small infinities. } We should understand the impact on the physics of using completeness for that goal. %TODO: This sentence was a bit difficult to parse.

If an inner product space is finite-dimensional, it is automatically complete.\footnote{This is exactly why completeness is mathematically desirable: infinite-dimensional spaces behave like finite-dimensional ones.} If the space is not complete, we can always complete it by enlarging it. The prevalent attitude among physicists is that this does not pose a problem: we simply have a bigger set of objects than we strictly need, and we simply discard what we do not need. However, having a bigger space with redundant elements often creates bigger problems.

For example, take the problem of defining volumes in three-dimensional Euclidean space $\mathbb{R}^3$. Formally, we want to find a measure $\mu(U)$ that returns the size of the region $U$. Naively, we may want to define it on the set of all possible subsets. In this case, the Banach–Tarski paradox tells us that we can take a unit ball, cut it into five pieces, and reassemble those pieces into two balls of the same size. Clearly, this does not make physical sense. However, we get a consistent definition if we restrict ourselves to a measure on the Borel sets instead of all sets. Therefore, bigger is not always better in mathematics:\footnote{In another work TODO: cite, we show that the Borel sets are exactly those sets that can be associated with experimental procedures. We have often found that physical requirements naturally map to well-behaved spaces.%TODO: Is this related to the spectral theorem somehow?
} we need to look more closely at what the math dragged in.

Unitary transformations play an important role in the theory of Hilbert spaces for at least two reasons. The first is that two Hilbert spaces that differ by a unitary transformation are mathematically equivalent. Like a change of basis, a change of representation is a unitary transformation. The second reason is that time evolution for an isolated system is represented by a unitary transformation. Let us see, then, the interplay between unitary transformations and our previous findings.\footnote{More precisely, the first reason only holds if the assumptions of the Stone-von Neumann theorem hold. For the conditions and physical systems under which those assumptions are unwarranted and the interpretive problems of trying to understand physical equivalence for systems that are not unitarily equivalent, see \cite{ruetsche_interpreting_2011}. The second reason is a consequence of the Stone theorem mentioned in the introduction. Notice that the definition of unitary transformations requires the inner product. Yet another reason for its physicality!}

In a Hilbert space, we can always find a unitary transformation that maps one vector to any other. Therefore, there will be unitary transformations that map states with finite expectation values to infinite ones. This means that whether something has a finite expectation value will depend on the choice of representation. As a concrete example, consider the following two wave functions
\begin{align}
\psi(x) &= \sqrt{\frac{e^{-x^2}}{\sqrt{\pi}}} \\
\phi(x) &= \frac{1}{\sqrt{\pi(x^2 + 1)}}.
\end{align}
Both states are symmetric and, therefore, will have zero expectation value for $x$. The first distribution is a Gaussian; therefore, all moments of the distribution, the expectation for $x^n$, are finite. The second goes to infinity like $\frac{1}{x^2}$, so the expectation will diverge for all moments above the first. We can now find a change of variable $y(x)$ that transforms one distribution into the other. We need to set
\begin{equation}
\begin{aligned}
\int_{0}^{x} \psi^\dagger(x) \psi(x) dx &= \int_{0}^{y(x)} \phi^\dagger(x) \phi(x) dx \\
\int_{0}^{x} \frac{e^{-x^2}}{\sqrt{\pi}} dx &= \int_{0}^{y(x)} \frac{1}{\pi(y^2 + 1)} dx \\
\frac{\erf(x)}{2} &= \frac{\tan^{-1}(y)}{\pi} \\
y &= \tan \left(\frac{\pi}{2}\erf(x)\right). \\
\end{aligned}
\end{equation}
Therefore, through a variable change, we can change a state with a finite expectation value for all moments greater than the first into a state with an infinite expectation value for the same moments. Variable changes are unitary transformations on the Hilbert space. %TODO: I worry that I'm not sure if this change of variables is not implementable by unitary operators...writing down the explicit unitary transformation would be great.
Therefore, the theory of Hilbert spaces, as applied to quantum mechanics, would tell us that the two representations are equivalent.

On physical grounds, these are clearly not equivalent. Reconstructing a state from its expectation values is a common technique, quantum tomography. If a unitary transformation can change finite expectations to infinite ones, we effectively change what can be distinguished experimentally. Not only can we not measure infinite values, but different finite values would get lumped into the same infinite value. %TODO: The comment on tomography made me think that tomographic procedures also have an uncertainty associated with them (some collaborators and I have a paper on this), so this would mean that we have a device with infinitely good resolution, which is nonsense! If this argument seems right, we can include it.
In the example above, if we increased the variance, one observer would see all the even moments change, but the other would see them all equally infinite. The math, as it stands, takes physically inequivalent states as equivalent, making it impossible later to separate physical problems from unphysical ones.

Moreover, we can create the following family of transformations
\begin{equation}
y(t) = \cos(\omega t) x + \sin(\omega t) \tan \left(\frac{\pi}{2}\erf(x)\right).
\end{equation}
This is clearly continuous in $t$ and, for $t=0$, we have the identity transformation, and therefore, mathematically, there is no reason why this wouldn't be a valid time evolution. %TODO: This would be more convincing by showing the unitary transformation reflecting the change of variables.
What this does is stretch back and forth the wavefunction, such that the state keeps oscillating between the two functions above, making the expectation value oscillate from finite to infinite in finite time. This, again, is physically untenable.

Again, these issues often do not arise when performing actual calculations because physics makes us work in the corner of the structure where things are reasonable. The issue is that when one tries to prove theorems or general results on quantum theory, one is currently forced to consider the entire Hilbert space. It is unreasonable to expect all theorems valid in all physical cases to have valid generalizations for unphysical ones. We are likely missing out on useful results by not considering what is provable within the subset of physical cases. We, therefore, wonder whether many of the technical issues we have in quantum theory (e. g., the non-existence of a valid measure for path integrals, inequivalent representations for interacting theories, the non-existence of the categorical tensor product for Hilbert spaces, etc.)\footnote{See \cite[\S A.4]{glimm_quantum_1987} for the non-existence of infinite products of Lebesgue measures. Glimm and Jaffe also mention a theorem by Minlos (3.4.2) suggesting that path integral measures \textit{can} be defined in Schwartz spaces that, as far as we know, has not been paid attention to in the literature. The locus classicus for Haag's theorem and the interaction picture in quantum field theory is still \cite{earman_haags_2006}. For categorical tensor products, see TODO.} having to deal with infinities and infinite correlations are simply a consequence of using unphysical objects at a fundamental level.

\section{On the physicality of Schwartz spaces}

While we do need infinite-dimensional spaces to handle unbound quantities, such as the number of particles, or continuous quantities, such as position, it seems that Cauchy-completeness is not the proper characterization. While finding the proper one goes beyond the scope of this work, we want to show that alternatives are possible.

A reasonable alternative would require the expectation of all polynomials of position and momentum to be finite. In quantum mechanics, this means requiring all expectations of $\frac{1}{2}(X^nP^m - P^mX^n)$ to be finite. This restricts our space to those functions that are infinitely smooth (i. e., all derivatives exist) and decrease very rapidly as $x$ goes to infinity: these are the Schwartz functions.

The Schwartz space has several other interesting properties, explored in more detail in the appendix. For example:

\begin{itemize}
\item the expectations fully identify it - two Schwartz are the same if and only if all expectations are the same; quantum tomography on all polynomials fully reconstructs the state
\item it is inner product space with the same norm of $L^2$
\item it is a dense subset of $L^2$ Hilbert space - any element of the Hilbert space can be approximated by a Schwartz function with an arbitrary level of precision\footnote{Even the problematic position operators can be defined starting from Schwartz spaces \cite[Threorem 5.23]{moretti_spectral_2017}.}
\item it is complete with respect to the expectation values - a sequence of functions for which all expectation values of all polynomials of position and momentum converge will converge in the Schwartz space
\item its closure over all Cauchy sequences recovers the Hilbert space - the only thing missing are the Cauchy sequences for which the limit of at least one expectation is not well defined
\item it is the only space closed under Fourier transform - the Fourier transform of a Schwartz function is a Schwartz function
\item it plays a fundamental role in the theory of distributions - objects like the $\delta$-function are mathematically defined on top of the Schwartz space
\end{itemize}
These properties make the Schwartz space a much more reasonable candidate to capture the physics. The convergence of expectation values of actual observables replaces convergence over vectors in an abstract space.\footnote{Compare this statement with the ``weak convergence'' of von Neumann algebras.} The point is that alternatives exist and should be fully explored.

\section{Conclusion}

We have made the case that Hilbert spaces in quantum mechanics are \textbf{unphysical} as they necessarily bring in states with infinite expectation values, coordinate transformations that turn finite expectations into infinite ones, and unitary transformations that do the same in finite time. Theorems that are valid on Hilbert spaces range over these unphysical cases, meaning that we are possibly missing results and techniques that would be physically interesting.

The more general problem is that the physics community has become complacent in simply accepting mathematical definitions without properly understanding their limit of applicability to physical theories. We believe that meaningful progress on the foundations of physics cannot happen without understanding the implicit assumptions embedded in the most basic mathematical tools.

\bibliography{bibliography}

\newcommand{\pj}[1] {\underbar{$#1$}}

\section*{Appendix}

This appendix provides the same arguments in the article's main body, but expanded with full mathematical detail.

\subsection{Physicality of inner product space structure}

The first task is to show that the vector space structure is not, by itself, physical. Since rays of a Hilbert space represent quantum states, and rays can be defined simply on top of the vector space structure alone, one may think that the vector space structure, by itself, is physical. The issue is that, without an inner product, one cannot make physical sense of the coefficients one uses for linear combinations, and, therefore, superpositions become ill-defined.

To show the problem, we prove the following proposition that tells us that there are infinitely many ways to decompose a vector representing a state in terms of vectors representing two other states, meaning that the coefficients of the linear combination are arbitrary.
\begin{prop}\label{vector_insufficient}[The vector space structure is not enough to uniquely identify superpositions.] Let $\mathcal{H}$ be a complex vector space and let $\textbf{P}(\mathcal{H})$ be its projective space. Let $\psi, \phi_1, \phi_2 \in \mathcal{H}$ such that $\psi = c_1 \phi_1 + c_2 \phi_2$ for some $c_1, c_2 \in \mathbb{C}$. Let $\pj{\psi}, \pj{\phi_1}, \pj{\phi_2} \in \textbf{P}(\mathcal{H})$ be the corresponding rays in the projective space. Then for any $\hat{c}_1, \hat{c}_2 \in \mathbb{C}$ we can find $\hat{\phi}_1 \in \pj{\phi_1}$ and $\hat{\phi}_2 \in \pj{\phi_2}$ such that
$$\psi = \hat{c}_1 \hat{\phi}_1 + \hat{c}_2 \hat{\phi}_2.$$
\end{prop}

\begin{proof}
Let $\hat{\phi}_1 = \frac{c_1}{\hat{c}_1} \phi_1$. Since they differ only by a constant, they are elements of the same ray. That is, $\hat{\phi}_1 \in \pj{\phi_1}$. Similarly, we let $\hat{\phi}_2 = \frac{c_2}{\hat{c}_2} \phi_2$ and we have $\hat{\phi}_2 \in \pj{\phi_2}$. We have
\begin{equation}
\begin{aligned}
\hat{c}_1 \hat{\phi}_1 + \hat{c}_2 \hat{\phi}_2 &= \frac{c_1}{\hat{c}_1} \phi_1 + \frac{c_2}{\hat{c}_2} \phi_2 \\
&= c_1 \phi_1 + c_2 \phi_2 \\
&= \psi.
\end{aligned}
\end{equation}
\end{proof}

The intuition that a state has a single linear decomposition in terms of other vectors requires, first of all, that the vectors are normalized. To identify the coefficient as probability amplitudes, that is that $\sum_i |c_i|^2 = 1$, further requires decomposition on orthogonal vectors.\footnote{Mathematically, this means turning the vectors $\{\phi_i\}$ into an orthonormal set using Gram-Schmidt orthonormalization, which requires the inner product.} That is, linear combinations require the inner product to be understood physically as superpositions. Therefore, the vector space structure is insufficient to provide a clear connection to physics.

We could now use the above reasoning to argue that the inner product space structure, as a whole, is physical because it indeed characterizes both superpositions and the Born rule. These are features required by quantum mechanics and, therefore, representationally necessary and physically motivated. Many will find this argument convincing enough, but there are several problems.

First of all, it is not clear whether superpositions are actual physical entities or whether they are just mathematical constructs. This is an area where different interpretations may differ \cite{albert_quantum_1994, wallace_everett_2013, howard_complementarity_2021}, and the physicality of a mathematical representation should not be interpretation-dependent. Second, in its standard characterization, the Born rule brings in one of the most controversial aspects of the theory, measurements, which suffers from an interconnected interpretation problem. Lastly, the inner product is critical for both the Born rule, which is a transition probability of transition before and after the measurement, and linear decomposition into superposition, which is done at equal times. The goal, then, is to find a characterization of our physical requirement that is interpretation-independent, more cohesive, and perhaps more physically necessary %TODO: Not sure what ``necessary'' means here.

The idea is to reformulate the requirements that lead to superposition and the Born rules in terms of equivalent requirements of statistical mixtures. Mathematically, these will be in terms of the space of density operators instead of the vector space itself.\footnote{Similar techniques can be found in the literature of Quantum Logic and of Generalized Probability Theories. TODO: add citations}

The idea is to link superposition to another feature of quantum mechanics: the non-unique decomposition of mixed states into pure states. For example, if we take the maximally mixed state for a spin 1/2 system, this can be implemented with an equal mixture of spin up and spin down or with an equal mixture of spin left and spin right. The idea is that a pure state $\psi$ is expressible as a superposition of other pure states $\{\phi_i\}$ exactly because there is a mixed state $\rho$ that can be equivalently expressed as a mixture of $\{\phi_i\}$ or as a mixture of $\psi$ and other pure states. Hilbert space subspaces are grouping together pure states that can provide the same statistical mixtures. To keep the reasoning as general as possible, we will not require $\{\phi_i\}$ to be orthogonal to each other.

\begin{prop}\label{prop_densitySpan}
Let $\mathcal{H}$ be a complex inner product space. Let $\{\psi_i\}, \{\phi_j\} \in \mathcal{H}$ be two finite sets of normalized vectors. Suppose there exists a density operator that can be expressed as a strict convex combination of either set. That is, we can find two sequences $\{a_i\}, \{b_j\} \in \mathbb{R}_{>0}$ such that
\begin{enumerate}
\item $\sum_i a_i = 1$
\item $\sum_j b_j = 1$
\item $\sum_i a_i |\psi_i\>\<\psi_i| = \sum_j b_j |\phi_j\>\<\phi_j|$,
\end{enumerate}
then the span of the two sets is the same.
\end{prop}

\begin{proof}
Consider $\rho = \sum_i a_i |\psi_i\>\<\psi_i|$. For a unitary vector $\varphi \in \mathcal{H}$ we have
$$p(\varphi|\rho)=tr(\rho |\varphi\>\<\varphi|) = \sum_i a_i |\<\psi_i|\varphi\>|^2$$
Since all $a_i$ are positive, $p(\varphi|\rho) = 0$ if and only if $\varphi$ is orthogonal to all $\psi_i$.

Now suppose $\rho = \sum_i a_i |\psi_i\>\<\psi_i| = \sum_j b_j |\phi_j\>\<\phi_j|$. Then a vector $\varphi$ is orthogonal to all $\psi_i$ if and only if it is also orthogonal to all $\phi_i$, which means $span(\{\psi_i\}) = span(\{\phi_j\})$) as they have the same orthogonal complement.
\end{proof}

\begin{prop}\label{prop_decomposition}
Let $\mathcal{H}$ be a complex inner product space. Let $\psi \in \mathcal{H}$ be a normalized state and $\rho : \mathcal{H} \to \mathcal{H}$ a density operator of finite rank such that $\<\psi|\rho|\psi\>\neq 0$. Then we can express $\rho$ as a mixture of $\psi$. That is, there exists a finite set of normalized states $\{\psi_i\} \in \mathcal{H}$ such that $\psi_1 = \psi$ and $\rho = \sum_i p_i |\psi_i\>\<\psi_i|$.
\end{prop}

\begin{proof}
The set of all possible density operators is a convex set, which can be characterized as a subset of a vector space $V$. Let $\rho$ be a density operator such that $\<\psi|\rho|\psi\>\neq 0$. This will be a point in the convex set. If $\rho = |\psi\>\<\psi|$, we are done. If not, the two elements will identify a line, which must intersect the boundary of the convex set in two places. One must be $\psi$ since $\psi$ is a pure state and, therefore, an extreme point. Let $\rho_1$ be the other point. If it is an extreme point, we are done as $\rho$ is an affine combination of $\psi$ and $\rho_1$. If not, $\rho_1$ is on a part of the boundary that is not strictly convex. That region will be a convex set constrained on a subspace $V_1$ of $V$. Note that $V_1$ does not include $\psi$, and it does not span the direction identified by $\rho_1$ and $\psi$. This means that we can't have $\rho_1 = \rho$ as $\<\psi|\rho|\psi\>\neq 0$. Therefore we have that $\rho$ is an affine combination of $\psi$ and $\rho_1$, which must be a density operator of finite rank lower than $\rho$. We can express $\rho_1$ as a convex combination of finitely many extreme points $\psi_2, \psi_3, ..., \psi_n$, each of them corresponding to a pure state. We have that $\rho$ is an affine combination of pure states that include $\psi$.
\end{proof}

\begin{prop}\label{prop_superpositionIsDecomposition}[Superposition is multiple decomposition of mixed states.]
Let $\mathcal{H}$ be a complex vector space. Let $\psi \in \mathcal{H}$ be a normalized vector and $\{\phi_j\} \in \mathcal{H}$ a finite set of normalized vectors that does not contain $\psi$. Then $\psi$ is a superposition of $\{\phi_j\}$ if and only if there exists a density operator $\rho$ that can be expressed both as a strict convex combination of $\{\phi_i\}$ and of another set of normalized vectors that contain $\psi$. That is, we can find a finite set of normalized vectors $\{\psi_i\} \in \mathcal{H}$ and two sequences $\{a_i\}, \{b_j\} \in \mathbb{R}_{>0}$ such that
\begin{enumerate}
\item $\psi_1 = \psi$
\item $\sum_i a_i = 1$
\item $\sum_j b_j = 1$
\item $\sum_i a_i |\psi_i\>\<\psi_i| = \sum_j b_j |\phi_j\>\<\phi_j|$,
\end{enumerate}
\end{prop}

\begin{proof}
Suppose $\psi$ is a normalized state that can be written as $\psi = \sum_{i=1}^n c_i \phi_i$ where $\{\phi_i\} \in \mathcal{H}$ is a finite set of normalized vectors that does not contain $\psi$. Since $\{\phi_j\}$ are not necessarily orthogonal, it is not necessarily true that $|\<\psi|\phi_i\>| = |c_i|^2$ or that $|\<\psi|\phi_i\>| \neq 0$ for all $i$. However, since $\psi$ is normalized and $\psi \neq \phi_i$ for all $i$, there must be at least two vectors in $\{\phi_i\}$ such that $|\<\psi|\phi_i\>| \neq 0$. We can then find $\{p_i\} \in \mathbb{R}+$ for which $\sum_i p_i =1$, such that $\rho = \sum_i p_i |\phi_j\>\<\phi_j|$ and $\<\psi|\rho|\psi\> \neq 0$. By Proposition \ref{prop_decomposition}, $\rho$ can be expressed as a convex combination of a set of normalized states that include $\psi$.

Conversely, suppose we have a density operator $\rho$ that can be expressed as a strict convex combination of $\{\phi_i\}$ and another set of normalized vectors containing $\psi$. By Proposition \ref{prop_densitySpan} the span of $\{\phi_i\}$ will include $\psi$ and therefore $\psi$ is a superposition of $\{\phi_i\}$.
\end{proof}

As for the inner product, we show that the Born rule can be understood as characterizing the entropy of equal mixtures over state pairs. This gives us a geometric understanding of the inner product at equal times instead of a probability of transition, which brings it more in line with the use during superposition. It should also be noted that the von Neumann entropy of a mixture can be understood as the minimum Shannon entropy over all possible decompositions,\footnote{TODO: cite} which again shows the connection between the geometry of the convex space of statistical ensembles and the inner product.

\begin{prop}\label{prop_innerProductIsEntropy}[Inner product is an entropic structure]
Let $\mathcal{H}$ be a complex Hilbert space. Let $I : \mathcal{H} \times \mathcal{H} \to \mathbb{R}$ be the von Neumann entropy of the equal mixture of two pure states. That is
\begin{equation}
I(\psi_1, \psi_2) = S\left(\frac{1}{2}|\psi_1\>\<\psi_1| + \frac{1}{2}|\psi_2\>\<\psi_2|\right).
\end{equation}
Let $p : \mathcal{H} \times \mathcal{H} \to \mathbb{R}$ be the square of the inner product. That is
\begin{equation}
p(\psi_1, \psi_2) = |\<\psi_1| \psi_2\>|^2.
\end{equation}
Then $p$ and $I$ can be reconstructed from each other. That is, there exists an invertible function $f$ such that
\begin{equation}
I(\psi_1, \psi_2) = f(p(\psi_1, \psi_2)).
\end{equation}
\end{prop}

\begin{proof}
TODO: Copy proof from other paper.
\end{proof}

Having shown the connection between superposition and non-unique decompositions of mixed states and between the Born rule and the entropy of mixtures, we can now use these to justify the physicality of the complex inner product space structure for quantum states.
\begin{prop}
Complex inner product spaces are physical when used to represent the state space of quantum systems.
\end{prop}
\begin{justification}
Since physical preparations and measurements are often not perfect, a physical theory must define statistical ensembles. Part of that definition includes keeping track of statistical ensembles under statistical mixtures, that is, which particular mixture is obtained by mixing particular states in particular proportions. A particular feature of quantum mixed states is that, unlike classical states, they do not generally provide a unique decomposition in terms of pure states. This non-unique decomposition, as shown by proposition \ref{prop_superpositionIsDecomposition}, is equivalent to the ability to create superpositions of pure state. Therefore, the inner product structure is the exact structure needed to characterize quantum ensembles and their properties, which is required by the physics.

Additionally, a physical theory must be able to define each ensemble's entropy, as thermodynamics requires. In quantum mechanics, the thermodynamic entropy is recovered by the von Neumann entropy, which Proposition \ref{prop_innerProductIsEntropy} shows is exactly captured by the inner product. This again shows that the inner product structure is required to capture a necessary physical requirement.
\end{justification}

\section{The unphysicality of completeness}

To show that the completeness requirement on complex inner product spaces that represent quantum states is unphysical, we need to show that this definition forces the state space to include elements that cannot have physical correspondents.

The Hellinger–Toeplitz theorem states that a symmetric operator $O$ defined on the whole Hilbert space $\mathcal{H}$ is necessarily bound. Therefore, an unbound operator $X$ cannot be defined on the whole space, meaning that the operator must diverge or be ill-defined on a subset of $\mathcal{H}$. To see that the problem is the completeness requirement of the Hilbert space, we prove the following:
\begin{prop}
Let $\mathcal{H}$ be a Hilbert space and $X : D(X) \to Y$ an unbounded operator where $D(X)$ is the domain of $X$, and $Y$ is another Hilbert space. Then $D(X)$ is an inner product space that is not complete.
\end{prop}
\begin{proof}
The domain $D(X)$ of the operator is a subspace of $\mathcal{H}$. In fact, if $||X(v_1)||_Y$ and $||X(v_2)||_Y$ are finite, so will $||X(a_1 v_1+a_2v_2)||_Y$. Therefore $D(X)$ is an inner product space. It cannot be completed by the converse of the Hellinger–Toeplitz theorem.
\end{proof}

To understand the physical significance, consider the position operator $X : D(X) \to \mathcal{H}$. If we take a normalized vector $\psi \in \mathcal{H}$, the norm $||X\psi|| = \<X\psi|X\psi\> = E[X^2|\psi]$ is equal to the expectation of the position squared. The operator is unbounded because the position can be arbitrarily large. We can therefore construct a Cauchy sequence $\{\psi_i\}$ such that $\lim\limits_{i \to \infty}||X\psi|| = +\infty$, that takes a sequence of vectors for which the expectation of position is larger and larger. Because of completeness, the limit of the Cauchy sequence will be in the Hilbert space. However, because the expectation diverges, the limit cannot be in the domain of $X$. Cauchy completeness forces us to include ``states'' for which the position is ill-defined.

The matter would still be manageable if we had a way to keep these degenerate cases isolated, but this is not the case. Generally, a unitary operator can move vectors in and out of the domain.
\begin{prop}
Let $\mathcal{H}$ be a Hilbert space, $X : D(X) \to Y$ an unbounded operator, and $U : \mathcal{H} \to \mathcal{H}$ a unitary operator. Then, in general, $U(D(X)) \notin D(X)$.
\end{prop}
\begin{proof}
Let $\psi, \phi \in \mathcal{H}$ be two normalized vectors. Then we can construct a unitary operator $U$ such that $\phi = U(\psi)$. For example, we can take the operator that performs a rotation in the subspace identified by $\psi$ and $\phi$, leaving the orthogonal subspace unchanged. We can now take $\psi$ to be in $D(X)$ while $\phi$ to not be in $D(X)$. Therefore, in general, a unitary operator can move vectors in and out of the domain of an unbounded operator.
\end{proof}

To understand the physical significance, note that unitary operators are isomorphisms between Hilbert spaces. That is, mathematically, two Hilbert spaces are considered indistinguishable if there exists a unitary transformation between them. As we saw, unitary operations can change the domain in which unbound operators are well defined: they can map states for which position is well defined onto states for which it is not. While the mathematical structure remains unchanged, the physical significance hasn't.

More concretely, a change of variable $X$ to $Y$ would be a unitary operator as it is just a change of representation. However, we can construct changes of variables such that the domain of $X$ is not exactly mapped to the domain of $Y$. Let $y=y(x)$ be our change of variable such that $y(0) = 0$. If $\psi(x)$ is a wavefunction expressed over $x$, and $\phi(y)$ represents the same state as a wavefunction over $y$, we have the following relationship:
\begin{equation}
\int_{0}^{y(x)} \phi^\dagger(y) \phi(y) dy = \int_{0}^{x} \psi^\dagger(x) \psi(x) dx
\end{equation}
To find a coordinate transformation that takes finite expectations to infinite expectation, we set the initial and final wavefunctions as follow:
\begin{align}
\psi(x) &= \sqrt{\frac{e^{-x^2}}{\sqrt{\pi}}} \\
\phi(y) &= \frac{1}{\sqrt{\pi(y^2 + 1)}}.
\end{align}
The first distribution is a Gaussian; therefore, all moments of the distribution, the expectation for $x^n$, are finite. The second goes to infinity like $\frac{1}{x^2}$, so the expectation will diverge for all moments above the first. We find
\begin{equation}
\begin{aligned}
\int_{0}^{y(x)} \frac{1}{\pi(y^2 + 1)} dy &= \int_{0}^{x} \frac{e^{-x^2}}{\sqrt{\pi}} dx \\
\frac{\tan^{-1}(y(x))}{\pi} &= \frac{\erf(x)}{2} \\
y(x) &= \tan \left(\frac{\pi}{2}\erf(x)\right). \\
\end{aligned}
\end{equation}
The graph of the above function increase so fast that, when plotted, it looks like it has a vertical asymptote. Nonetheless, it is an invertible function over the whole domain and will induce a unitary transformation on the Hilbert space.\footnote{Note that we could implement a similar coordinate transformation in classical mechanics, which would also change finite moments of a distribution into infinite ones. It may be that, like differentiable manifolds are constrained to only differentiable coordinate transformation, we need ``statistical manifolds'' that are constrained to coordinate transformations that preserve the finiteness of moments of distributions. This is a topic that requires further analysis.}

Unitary operators are also used in quantum theory to represent time evolution. Typically, we have a family of unitary operators $\{U_t\}_{t \in \mathbb{R}}$ that is strongly continuous (i.e. $\lim_{t \to t_0} U_t = U_{t_0}$) and respect composition in time (i.e. $U_t U_s = U_t+s$). We can turn the above transformation into an evolution by setting
\begin{equation}
y(x, t) = \cos(\omega t) x + \sin(\omega t) \tan \left(\frac{\pi}{2}\erf(x)\right).
\end{equation}
The idea is that the evolution will simply stretch and shrink the wavefunction intermittently, potentially oscillating expectation values from finite to infinite and vice versa in finite time. Clearly, this is not a meaningful time evolution, yet it will correspond to a strongly continuous one-parameter unitary group and, by Stone's theorem, will even admit a Hamiltonian.

The mathematician that points out that this is all known and there is nothing new is missing the point. The physicists that note that ``yes, those elements are clearly unphysical, but I don't use them, so I do not care,'' are also missing the point. The point is that, physically, we will want to make general statements such as ``for all observers, X is valid'' or ``under all evolution, Y is valid.'' Given that Hilbert spaces mix physically clearly meaningful objects with clearly unphysical ones, we have no way to make those statements precisely.

We can conclude the discussion with the following
\begin{prop}
Infinite-dimensional complex Hilbert spaces are unphysical when used to represent the state space of quantum systems due to completeness.
\end{prop}
\begin{justification}
If a finite-dimensional space models a quantum system, and since every finite-dimensional space is complete, finite-dimensional complex Hilbert spaces are physical.

Some physical systems are described by unbounded discrete quantities (e. g., number of particles) or continuous quantities (e. g., position), which require infinite-dimensional spaces. Infinite-dimensional complex inner product spaces, then, are needed to represent quantum systems.

An unbounded operator cannot be defined on all the elements of a Hilbert space by the converse of the Hellinger-Toeplitz theorem. This means that if one represents states as rays on a Hilbert space and observables as operators, the unbounded observable will not be well defined, not even as a statistical quantity, on all states. In particular, whether the statistical properties of an observable are well defined, whether it is possible to identify a state through tomography experimentally would be observer-dependent. Moreover, whether the expectation of an observer is finite or not would be something that can change in finite time.

On physical ground, we must have that an observable has well-defined statistical properties over all states, that this property is covariant, and that it is preserved by time evolution. Hilbert spaces do not satisfy this requirement and are, therefore, unphysical.
\end{justification}

\section{The possible physicality of Schwartz spaces}

We have found that:
\begin{enumerate}
\item complex inner product spaces are needed
\item infinite-dimensional spaces are needed
\item completeness is unphysical.
\end{enumerate}
In other words, we need a stricter way to characterize convergence within the state space so that we can manage the infinite dimensionality. Conceptually, we need to treat the infinities coming from unbound quantities as potential infinities, not actual infinities: we never actually have infinitely many particles or a system positioned at infinity; we have an infinite range of possible values.

A naive idea would be to require that the expectation value for all possible variables converge. Unfortunately, this doesn't work. Suppose we have a distribution $\rho(x)$ over position $x$. We would require the expectation of any function to be finite, which would include $e^x$, $e^{e^x}$, $e^{e^{e^x}}$, and so on. The only way this can work is if the function has compact support. Physically, this seems too restrictive as it excludes functions like normal distributions. At a closer investigation, the Paley-Wiener theorem\footnote{TODO: find citation--Maybe Prop. 3.115 in \cite{moretti_spectral_2017}?} tells us that the Fourier transform of a function with compact support is an entire function, and an entire function does not have compact support.\footnote{TODO: find citation} Therefore, we cannot have compact support in both position and momentum. \footnote{This is not true in classical mechanics, as position and momentum are different variables, not linked by the Fourier transform. Therefore the space of functions with compact support on phase space gives us finite expectation value for all functions of positions and momentum.}

The only way out, then, is to require only a certain class of observables to have finite expectation. Physically, it would make sense to require exactly those observables needed to reconstruct the state through quantum tomography fully. A good set in that respect seems to be the set of polynomials of conjugate quantities, like position and momentum. In quantum mechanics, this means requiring all expectations of $X^nP^m = -\imath \hbar x^n\partial_x ^m$ to be finite. This restricts our space to those functions that are infinitely smooth (i. e., all derivatives exist) and decrease very rapidly as $x$ goes to infinity: the Schwartz functions. Requiring finite expectation for all polynomials of position and momentum, then, does not give us the usual $L^2$ Hilbert space; it gives us the Schwartz space.

Not only do the expectations of all polynomials exist, but they are enough to identify the elements and define limits. The Schwartz space is, in fact, a Fréchet space \cite[Theorem V.9]{reed_methods_1980}, meaning that it is a Hausdorff space, with the topology induced by the seminorms given by the expectations, and it is complete with respect to those seminorms. Physically, this means that measurements on the polynomials (i. e., the topology of the seminorms) are enough to identify the states (i. e., the singletons, which are closed sets as per Hausdorff).\footnote{This is not true in classical mechanics. Even in the single variable case, distinct distributions have the same moments. However, if we assume compact support, distinct distributions have distinct moments even in the multi-variable case.\cite{moment_problem_2017} It is curious that the moment problem in quantum mechanics works differently.} Moreover, if we have a sequence for which all expectations converge, we are guaranteed to converge to another state (i. e., completeness with respect to the seminorms). If any expectation diverges, the limit is not in the space. This criterion of convergence seems a lot more physically sound.

To compare Schwartz and Hilbert spaces, the Schwartz space is a subspace of the $L^2$ Hilbert space taken as an inner product space. That is, all Schwartz functions are elements of the Hilbert space; they are closed under linear combinations and have the same inner product. It is not complete, and it is a dense subspace, meaning that any element of the Hilbert space can always be approximated by a Schwartz function with an arbitrary level of precision. Or, equivalently, once a map is defined over the Schwartz space, the map is uniquely extended over the Hilbert space. It would then seem that all we are losing is the behavior at actual infinity.

The Schwartz space also has a very important property: it is the only space that is closed under the Fourier transform. That is, the Fourier transform of a Schwartz function is a Schwartz function, and it is the only set of functions with this property. Given the importance of the Fourier transform in quantum theory, this feels like an important property to have. Mathematically, the theory of tempered distribution, which allows us to define objects like the Dirac $\delta$-function, is built on top of the Schwartz space. Therefore, this space already plays a fundamental role in the definitions of the tools we already use.

If we restrict ourselves to the Schwartz space, then the only unitary transformations we are interested in are those that map Schwartz function to Schwartz functions. These are special cases of unitary transformation over Hilbert spaces and inherit all their properties, such as the existence of the inverse. The change of coordinate we defined in the previous section, then, is automatically ruled out. It is interesting to note that two Hilbert spaces connected by such unitary transformations have essentially two separate theories of distributions as they start from two different sets of objects. In our mind, this shows exactly how two inequivalent physical representations can be mathematically equivalent. We suspect that the problem of inequivalent mathematical representations in QFT is a consequence of adding another non-physical infinity. %TODO: This last sentence is a bit controversial, and in the main text, it was looser, so I was more comfortable with conjecturing it. In the end, I leave it up to you two!

Though we believe the arguments to be thoroughly convincing, we are stopping short of declaring Schwartz spaces physical. First, this is not the paper's goal, which is to show the unphysicality of Hilbert spaces. Second, we would need to show the importance of expectation values of polynomials from experimental considerations.\footnote{The fact that the moment problems work differently in classical and quantum mechanics may make that argument difficult to construct.} It is not clear to us that that's the case, so it may be that the justification would have to proceed in a different, but ultimately equivalent, way.\footnote{One of the issues is the fact that uniqueness works TODO}

Now, one may be concerned that if we abandon Hilbert spaces, we would also have to abandon many convenient tools built on top. This is not the case. When solving an integral, we sometimes extend the domain for real to complex values, which are unphysical, because complex analysis has nicer mathematical features. The result so found, however, is still a valid result in the real domain. Similarly, we can pose the problem on the Schwartz space, extend to the Hilbert space or the space of distributions for calculation, and then bring the result back to the Schwartz space. Instead, the construction of state space, especially under infinite operations, needs to be rethought. If we want to construct the state space for a composite system of potentially infinitely many subsystems, understanding exactly what infinities are physical and which aren't is exactly the issue. Therefore taking the Hilbert space, which we saw doesn't deal with physical infinities correctly, and making infinitely many copies of it is bound to create problems.

\section{A final remark on the mathematical foundations of physical theories}

When mathematicians and philosophers noticed that mathematical theories at the time allowed to express inconsistencies (e. g., Russell's paradox, Berry paradox, etc.), an effort was put into strengthening the foundations of mathematics so that such paradoxes were either resolved or couldn't be expressed. Concerning the mathematical foundations of physical theories, we have a similar problem: we can write statements that, though mathematically consistent, are physically inconsistent. Looking for and addressing these problems will ultimately lead to a solid foundation, which, we believe, is the prerequisite to solving other outstanding issues in fundamental physics. %TODO: We should discuss the best way to frame this!

\end{document}
