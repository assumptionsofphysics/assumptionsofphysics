\documentclass[10pt,twocolumn, nofootinbib]{revtex4-2}
%\documentclass[aps,pra,10pt,twocolumn,floatfix,nofootinbib]{revtex4-1}
%\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{assumptionsofphysics}

%\usepackage{amsmath}
%\usepackage{mathrsfs}
%\usepackage{amsfonts}
%
%\usepackage{graphicx}
%\usepackage{hyperref}
%\hypersetup{
%	colorlinks=true,
%	citecolor=blue,
%	urlcolor=blue,
%	linkcolor=blue
%}
%\urlstyle{same}
%\frenchspacing
%
\def\>{\rangle}
\def\<{\langle}
\DeclareMathOperator{\erf}{erf}

\begin{document}

\title{The unphysicality of Hilbert spaces}
\author{TBD}
\affiliation{Physics Department, University of Michigan, Ann Arbor, MI 48109}

\date{\today}


\begin{abstract}
TBD
\end{abstract}

\maketitle

\section{Introduction}

Hilbert spaces have been the cornerstone of quantum mechanics since von Neumann (\cite{von_neumann_mathematische_1996}). Their use made available a vast number of theorems (Gleason, Riesz, Wigner, Stone, etc.) that made up the mathematical backbone of the theory and also represented a role model of mathematical rigor that people working on quantum field theory would try to achieve decades later \cite{haag_discussion_2010}. Wightman even took von Neumann's book to be the fulfillment of a project Hilbert himself kicked off with his problems on the foundations of mathematics (\cite[p. 157]{browder_hilberts_1976}): to axiomatize the physical sciences. But, despite the undeniable importance of wanting to set physics on a firm mathematical footing, we must remember that by ``axioms,'' they meant ``physically motivated constraints'' more than statements that can be immune to question, rethink, and, if necessary, revise.\footnote{For a more extended discussion of von Neumann's axiomatics and their physical inputs, see \cite{redei_soft_2006}.}

Now, there are well-known shortcomings of Hilbert spaces, but they are deemed unproblematic: states are rays, not vectors; the Dirac delta is a distribution, not a function; and some elements from $L^2(\mathbb{R})$ don't seem apt candidates to be wave functions. Given the importance Hilbert spaces have had and the issues we have let slide, it's not a surprise that they have become fossilized as parts of axiomatic systems\footnote{Even axiomatic formulations of quantum field theory (see e. g. \cite{haag_local_1996}) that don't need to use Hilbert spaces to make meaningful claims about quantum-mechanical observables and states can reassure physicists unfamiliar with this approach by recovering the Hilbert spaces they know and love through the GNS construction.} without even considering whether we can do quantum mechanics with weaker assumptions. So, despite all their success, perhaps it's time to ask if using Hilbert spaces to describe quantum states, an assumption whose physical motivation was meant to be revised as time passed, has become a dogma.

\section{On the physicality of Hilbert spaces}

Let us first clarify the standard we believe should be usde to judge the physicality of a formal definition. Suppose we have a physical system under study in a given condition. We say a mathematical definition is \textbf{physical} if it is the proper mathematical characterization of the physical system. That is, if it can be shown that the mathematical definition is needed to capture and only capture a particular aspect of the physical system. On the other hand, a mathematical definition is \textbf{unphysical} if it can be shown to require physical properties or operations that cannot be implemented physically.

For example, suppose we have a set of physically distinguishable objects, meaning that we can tell any two apart through an experimental test. Experimentally, the best we can do is collect finite information in finite time. If we are given an arbitrarily long time, we can collect an arbitrary amount of finite information. An element of the set, then, must be identified by at most a countably infinite sequence of ones and zeros, so that, at some point, we would be able to tell the difference between the two sequences and therefore the objects. The set of countable sequences of zeros and one can be understood as the binary expansion of real numbers between zero and one, which has cardinality of the continuum. Therefore, any definition that would require a set of physical objects to have cardinality greater than the continuum, then, is \textbf{unphysical}. For example, non separable Hilbert spaces have cardinality greater than the continuum, and therefore should be considered unphysical.

Naturally, this does not mean that all sets with cardinality of the continuum or lower are physical. In general, testing physicality is harder as we need to check that all the mathematical features map to physical feature and no physical feature is left behind. Clearly, postulating that ``the state space of a quantum states has cardinality no grater than that of the continuum'' is certainly \textbf{physical} but, however, this tells us little. Let us then see what elements of Hilbert spaces should we consider physical in the context of quantum mechanics.

\subsection{Inner vector space}

Recall that a Hilbert space is a complete inner product space. That is, it is a vector product, with an inner product, closed under Cauchy sequences. We will look at the first two structures briefly, leaving all detail to the appendix, as their physical significance is not surprising.

Roughly speaking, a vector space is a set whose elements can be combined linearly: can be multiplied by constants and summed. If one regards superpositions as physical requirements of quantum theory, one may think that this structure is physical. However, the ability to interpret linear combination as superpositions requires the ability to keep track of orthonormal vectors. If we can only know whether two vectors are in the same ray, we are not able to recover the idea of a probability amplitude, as those are the coefficients of a linear combination between normalized and orthogonal states that return another normalized state. Therefore the vector space structure, by itself, is not physical.

If we add the inner product, we can define norm and orthogonality and therefore we can indeed express superpositions. Additionally, the inner product structure also defines the Born rule, the transition probability during measurement. If one is comfortable in considering superpositions and the Born rule to be physical requirements of quantum mechanics, then the inner product structure is \textbf{physical}. However, some may not consider superpositions as actual physical objects, but more as mathematical constructs; others may object that the Born rule, in its standard interpretation, defines probability of transitions while a state space should be defined at equal time; others can argue that the states are defined by the rays, and therefore the requirements should only be in terms of those objects. For those and other reasons, we have an alternative, more necessary justification, which we include in the appendix, and can be summarized as follows.

Given that, experimentally, no preparation or measurement is perfect, a physical theory must define the space of statistical ensembles. Mathematically, these form a convex set, that physically represents a set that allows statistical mixtures. The geometry of the space of statistical ensembles is uniquely defined by the inner product and vector space structures, which means properties of the inner product space can be reexpressed as properties of the space of mixtues.\footnote{There is a rich literature on Generalized Probability Theory in which people reconstruct Quantum Theory by imposing requirements on convex spaces.} For example, we can characterize superposition in the following way: a pure state $\psi$ is expressible as a superposition of other pure states $\{\phi_i\}$ if and only if there is a mixed state $\rho$ that can be equivalently expressed as a mixture of $\{\phi_i\}$ or as a mixture of $\psi$ and other pure states. That is, the ability to create superposition is conceptually equivalent to the ability to prepare the same mixture in different ways, another feature particular to quantum mechanics. Additionally, the inner product can be shown to be equivalent to determining the entropy of all equal mixtures of state pairs. These requirements are necessary in the sense that both classical and quantum mechanics need to keep track how ensemble combine under mixing and what entropy each ensemble have.

The argument can be summed up as follows. On physical grounds, for any physical theory, we must be able to prepare statistical mixtures and characterize their entropy. The complex inner product space structure is exactly required to model the correct relationships of quantum mixtures, therefore the mathematical definition is necessitated by physical requirements. \textbf{The inner product space structure is physical}.

\subsection{Completeness}

We now turn to the last property of Hilbert spaces: completeness. Mathematically, this means that the space includes the limit of every Cauchy sequence; physically, this property is more difficult to characterize. We can look at an equivalent characterization:\cite{roman_2008}\footnote{Roman 2008, p. 330 Theorem 13.8
	
	Roman, Stephen (2008), Advanced Linear Algebra, Graduate Texts in Mathematics (Third ed.), Springer, ISBN 978-0-387-72828-5} the space is complete if, given a series of vectors
$$ \sum _{k=0}^{\infty }u_{k}$$
such that
$$ \sum _{k=0}^{\infty }\|u_{k}\|<\infty \,$$
the series converges in the space. This is now in terms of linear combinations, and therefore it is essentially telling us that we can prepare states that are superposition of infinitely many elements or, equivalently as we have seen, mixed states comprised of infinitely many pure states. Is this a physical requirement of just mathematical convenience?

Experimentally, we can imagining creating a superposition by splitting a beam along multiple paths, which is something typical, for example, in quantum optics.\footnote{TODO: cite} The above mathematical expression means splitting the original state into infinitely many progressively small components, and be able to place them where we please. However, it also assumes that we can place them over an infinite spatial range: we are literally saying that we can prepare states that are spread over infinite regions. This does not sound physical.

Again, given the difficulties of understanding superposition, let us reframe the result in terms of statistical quantities. Suppose that we are able to prepare pure states with arbitrary finite expectation value for position. Then completeness means we are also able to prepare pure states that falls off at infinity as $\frac{1}{x^2}$. The expectation value of $x$ would the integral of a function that falls off as $\frac{1}{x}$ which diverges. Clearly, this does not make physical sense. When we posit that a quantity, like position, has an infinite range of possible values, we simply mean that observed value can be arbitrarily large, not that we can literally spread values over an infinite range.\footnote{This is the difference between potential infinity and actual infinity.}

The argument can be summed up as follows. On physical grounds, we assume the existence of quantities, like position, that can take arbitrarily large values. This requires that for each possible value there must exist some state whose expectation matches that value. Requiring completeness mathematically forces us to posit states with an infinite expectation value, which cannot be implemented physically. The mathematical definition implicitly assumes objects that cannot be physically realized. \textbf{The use of completeness for the space of quantum systems in unphysical.}

\subsection{Impact of unphysicality}

It should not be surprising that closure over infinite sequences is problematic, as properly handling infinity is one of the key problems in mathematics.\footnote{Weyl stated ``Mathematics is the science of the infinite, its goal the symbolic comprehension of the infinite with human, that is finite, means.'' Hermann Weyl, "The Open World: Three Lectures on the Metaphysical Implications of Science," (1932) as quoted in Mind and Nature: Selected Writings on Philosophy, Mathematics, and Physics (2009) ed. Peter Pesic. Several branches of mathematics were developed to handle infinities, both large and small. } We should understand the impact on the physics of using completeness for that goal.

If an inner product space is finite dimensional, it is automatically complete.\footnote{This is exactly why, mathematically, completeness is nice as it makes infinite dimensional space behave like finite dimensional ones.} If the space is not complete, we can always complete it by enlarging the space. The prevalent attitude among physicists is that this pose no problem: we simply have a bigger set of objects than what we strictly need, and we simply discard what we do not need. Unfortunately, having a bigger space often creates bigger problems.

For example, take the problem of defining volumes in three dimensional euclidean space $\mathbb{R}^3$. Formally, we want to find a measure $\mu(U)$ that returns the size of the region $U$. Naively, we may want to define it on the set of all possible subsets. In this case, the Banach–Tarski paradox tells us that we can take a unit ball, cut it into five pieces, and reassemble those pieces into two balls of the same size. Clearly, this does not make physical sense. However, if we restrict ourselves with a measure on the Borel sets instead of all sets, we get a consistent definition. Therefore, in mathematics, bigger is not always better:\footnote{In another work, we show that the Borel sets are exactly those sets that can be associated with experimental procedures. In many cases, we have found that physical requirements naturally map to well behaved spaces.} we need to look more closely at what the math dragged in.

Unitary transformation play an important role in the theory of Hilbert spaces for at least two reasons. The first is that two Hilbert spaces that differ by a unitary transformation are mathematically equivalent. A change of representation, like a change of basis, is a unitary transformation. The second reason is that time evolution for an isolated system is represented by a unitary transformation. Let us see, then, the interplay between unitary transformations and our previous findings.

In a Hilbert space, we can always find a unitary transformation that maps one vector to any other. Therefore, there will be unitary transformations that map states with finite expectation values to infinite ones. This means that whether something has a finite expectation value or not will depend on the choice of representation. As a concrete example, consider the following two wave functions
\begin{align}
	\psi(x) &= \sqrt{\frac{e^{-x^2}}{\sqrt{\pi}}} \\
	\phi(x) &= \frac{1}{\sqrt{\pi(x^2 + 1)}}.
\end{align}
Both states are symmetric, and therefore will have zero expectation value for $x$. The first distribution is a Gaussian, and therefore all moments of the distribution, the expectation for $x^n$, are finite. The second goes to infinity like $\frac{1}{x^2}$, so the expectation will diverge for all moments above the first. We can now find a change of variable $y(x)$ that transforms one distribution into the other. We need to set
\begin{equation}
	\begin{aligned}
	\int_{0}^{x} \psi^\dagger(x) \psi(x) dx &= \int_{0}^{y(x)} \phi^\dagger(x) \phi(x) dx \\
	\int_{0}^{x} \frac{e^{-x^2}}{\sqrt{\pi}} dx &= \int_{0}^{y(x)} \frac{1}{\pi(y^2 + 1)} dx \\
	\frac{\erf(x)}{2} &= \frac{\tan^{-1}(y)}{\pi} \\
	y &= \tan \left(\frac{\pi}{2}\erf(x)\right). \\
	\end{aligned}
\end{equation}
Therefore, through a variable change, we can change a state that has finite expectation value for all moments greater than the first into a state that has infinite expectation value for the same moments. Variable changes, in terms of the Hilbert space, are unitary transformation. Therefore the theory of Hilbert spaces, as applied to quantum mechanics, would tell us that the two representations are equivalent.

On physical grounds, these are clearly not equivalent. Identifying a state through expectation value is a common technique (i.e quantum tomography). If a unitary transformation can change finite expectations to infinite ones, we are effectively changing what can be distinguished experimentally. Not only we cannot measure infinite values, but different finite values would get lumped into the same infinite value. In the above example, if we increased the variance, one observer will see all the even moments change, yet the other would see them all equally infinite. The math, as it stands, lumps together physically inequivalent representations into the same equivalence class, making it impossible later to separate physical problem from unphysical ones. 

Moreover, we can create the following family of transformations
\begin{equation}
	y(t) = \cos(\omega t) x + \sin(\omega t) \tan \left(\frac{\pi}{2}\erf(x)\right).
\end{equation}
This is clearly continuous in $t$ and, for $t=0$, we have the identity transformation and therefore, mathematically, there is no reason why this wouldn't be a valid time evolution. What this does is stretching back and forth the wavefunction, such that the state keeps oscillating between the above two functions, making the expectation value oscillate from finite to infinite in finite time. This, again, is physically untenable.

Again, most of the time these issues do not arise when performing actual calculations because the physics makes us work in a corner of the structure where things are reasonable. The issue is that when one tries to prove theorems or general results on quantum theory, one currently is forced to consider the entire Hilbert space. It is unreasonable to expect that all theorems valid on all physical cases would have valid generalizations on unphysical ones, and therefore we are likely missing useful results. We therefore wonder whether many of the technical issues we have in quantum theory (e.g. non existence of a valid measure for path integrals, inequivalent representation of interacting theories, non existence of the categorial tensor product for Hilbert spaces, having to deal with infinities and infinite correlations)\footnote{TODO: cite} are simply a consequence of the use, at a fundamental level, of unphysical objects.

\section{On the physicality of Schwartz spaces}

Suppose the reader agrees with our finding, the subsequent question is: what is the alternative? We do need infinite dimensional spaces to handle unbound quantities, such as number of particles, or continuous quantities, such as position. If we can't use Cauchy completeness, how do we characterize the converge of infinite sequences?

A solution could be simply focusing on the expectation values of observables, and requiring a sufficient number of them to be finite. For example, we could require the expectation of all polynomial of position and momentum to be finite. In quantum mechanics, this means requiring all expectations of $\frac{1}{2}(X^nP^m - P^mX^n)$ to be finite. This restricts our space to those functions that are infinitely smooth (i.e. all derivative exist) and decrease very rapidly as $x$ goes to infinity: these are the Schwartz functions. Is the Schwartz space a better candidate?

First of all, the Schwartz space is a subspace of the $L^2$ Hilbert space taken as an inner product space. That is, all Schwartz functions are elements of the Hilbert space, they are closed under linear combinations and have the same inner product. It is not, however, complete, which is what we want. Moreover, it is a dense subspace, meaning that any element of the Hilbert space can always be approximated by a Schwartz function with an arbitrary level of precision. This is a good hint that we have thrown away only unphysical elements.

If we restrict ourselves to the Schwartz space, then, the only unitary transformations we are interested in are those that map Schwartz function to Schwartz functions. The change of coordinate we defined in the previous section, then, is ruled out. Limits in terms of Cauchy sequences are not guaranteed, but limits in terms of expectation values are guaranteed: if we have a sequence of states such that the limit of the expectation converge, then we are guaranteed that the limit is also a Schwartz function. Schwartz functions, in fact, are uniquely identified by the expectation of all polynomial of position and momentum, effectively guaranteed that they can be distinguished by quantum tomography.

The Schwartz space has also a very important property: it is the only space that is closed under the Fourier transform. That is, the Fourier transform of a Schwartz function is a Schwartz function, and it is the only set of functions with this property. The theory of tempered distribution, which allows us to define the Dirac $\delta$-function, is mathematically based, at its core, over the Schwartz space. Therefore, this space already plays a fundamental role in the definitions of the tools we already use.

While determining whether Schwartz spaces are the correct space to capture quantum states goes beyond the scope of this article, we do want to show that alternatives exist. Exploring these alternatives fully, to see exactly what theorems still hold which do not, and whether others are possible, is a significant effort that is extremely important and long overdue.

\section{Conclusion}

We have made the case that Hilbert spaces in quantum mechanics are \textbf{unphysical} as they necessarily bring in states with infinite expectation values, coordinate transformations that turn finite expectations in infinite ones, and unitary transformations that do the same in finite time. Theorems that are valid on Hilbert spaces must be valid over these unphysical cases, meaning that we are possibly missing results and techniques that would be physically interesting.

The more general problem is that the physics community has become complacent in simply accepting mathematical definitions, without properly understanding their limit of applicability for physical theories. We believe that meaningful progress on the foundations of physics cannot happen without understanding the implicit assumptions embedded in the most basic mathematical tools.

\bibliography{bibliography}

\newcommand{\pj}[1] {\underbar{$#1$}}

\section*{Appendix}

In this appendix we provide the same arguments presented in the main body of the article expanded with the full mathematical detail.

\subsection{Physicality of inner product space structure}

The first task is to show that the vector space structure is not, by itself, physical. Since quantum states are represented by rays of a Hilbert space, and since rays can be defined simply on top of the vector space structure alone, one may think that the vector space structure, by itself, is physical. The issue is that, without an inner product, one cannot make physical sense of the coefficients one uses for linear combinations, therefore superpositions becomes ill-defined.

To show the problem, we prove the following proposition that tells us that there are infinitely many ways to decompose a vector representing a state in terms of vectors that represent two other states, meaning that the coefficients of the linear combination are arbitrary.
\begin{prop}\label{vector_insufficient}[The vector space structure is not enough to uniquely identify superpositions.] Let $\mathcal{H}$ be a complex vector space and let $\textbf{P}(\mathcal{H})$ be its projective space. Let $\psi, \phi_1, \phi_2 \in \mathcal{H}$ such that $\psi = c_1 \phi_1 + c_2 \phi_2$ for some $c_1, c_2 \in \mathbb{C}$. Let $\pj{\psi}, \pj{\phi_1}, \pj{\phi_2} \in \textbf{P}(\mathcal{H})$ be the corresponding rays in the projective space. Then for any $\hat{c}_1, \hat{c}_2 \in \mathbb{C}$ we can find $\hat{\phi}_1 \in \pj{\phi_1}$ and $\hat{\phi}_2 \in \pj{\phi_2}$ such that
$$\psi = \hat{c}_1 \hat{\phi}_1 + \hat{c}_2 \hat{\phi}_2.$$
\end{prop}

\begin{proof}
Let $\hat{\phi}_1 = \frac{c_1}{\hat{c}_1} \phi_1$. Since they differ only by a constant, they are elements of the same ray. That is, $\hat{\phi}_1 \in \pj{\phi_1}$. Similarly, we let $\hat{\phi}_2 = \frac{c_2}{\hat{c}_2} \phi_2$ and we have $\hat{\phi}_2 \in \pj{\phi_2}$. We have
\begin{equation}
\begin{aligned}
	\hat{c}_1 \hat{\phi}_1 + \hat{c}_2 \hat{\phi}_2 &= \frac{c_1}{\hat{c}_1} \phi_1 + \frac{c_2}{\hat{c}_2} \phi_2 \\
	&= c_1 \phi_1 + c_2 \phi_2 \\ 
	&= \psi.
	\end{aligned}
\end{equation}
This concludes the proof.
\end{proof}

The intuition that a state has a single linear decomposition in terms of other vectors requires, first of all, that the vectors are normalized. To identify the coefficient as probability amplitudes, that is that $\sum_i |c_i|^2 = 1$, further requires the decomposition to be done on orthogonal vectors.\footnote{Mathematically, this means turning the vectors $\{\phi_i\}$ into an orthonormal set using Gram-Schmidt orthonormalization, which requires the inner product.} That is, linear combinations require the inner product to be understood physically as superpositions. The vector space structure by itself is therefore insufficient to provide a clear connection to physics.

We could now use the above reasoning to argue that the inner product space structure, as a whole, is physical, because it indeed characterizes both superpositions and the Born rule. These are features required by quantum mechanics, and therefore necessary and physically motivated. Many will find this argument convincing enough, however there a couple of objective problems.

First of all, it is not clear whether superpositions are actual physical entities or whether they are just mathematical constructs. This is an area where different interpretations may differ,\footnote{TODO: add citations} and the physicality of a mathematical representation should not be interpretation dependent. Second, the Born rule, in its standard characterization, brings in one of the most controversial aspects of the theory, measurements, which suffers from an interpretation problem as well. Lastly, the inner product is critical for both the Born rule, which is a transition probability of transition before and after the measurement, and linear decomposition into superposition, which is done at equal time. The goal, then, is to find a characterization of our physical requirement that is interpretation independent, more cohesive and perhaps more physically necessary.

The idea is to reformulate the requirements that lead to superposition and the Born rules in terms of equivalent requirements of statistical mixtures. Mathematically, these will be in terms of the space of density operators instead of the vector space itself.\footnote{Similar techniques can be found in the literature of Quantum Logic and of Generalized Probability Theories. TODO: add citations}

The idea is to link superposition to another feature of quantum mechanics: the non-unique decomposition of mixed state into pure states. For example, if we take the maximally mixed state for a spin 1/2 system, this can be implemented with an equal mixture of spin up and spin down, or with an equal mixture of spin left and spin right. The idea is that a pure state $\psi$ is expressible as a superposition of other pure states $\{\phi_i\}$ exactly because there is a mixed state $\rho$ that can be equivalently expressed as a mixture of $\{\phi_i\}$ or as a mixture of $\psi$ and other pure states. Hilbert space subspaces are grouping together pure states that can provide the same statistical mixtures. To keep the reasoning as general as possible, we will not require $\{\phi_i\}$ to be orthogonal to each other.

\begin{prop}\label{prop_densitySpan}
	Let $\mathcal{H}$ be a complex inner product space. Let $\{\psi_i\}, \{\phi_j\} \in \mathcal{H}$ be two finite sets of normalized vectors. Suppose there exists a density operator that can be expressed as a strict convex combination of either set, that is we can find two sequences $\{a_i\}, \{b_j\} \in \mathbb{R}_{>0}$ such that
	\begin{enumerate}
		\item $\sum_i a_i = 1$
		\item $\sum_j b_j = 1$
		\item $\sum_i a_i |\psi_i\>\<\psi_i| = \sum_j b_j |\phi_j\>\<\phi_j|$,
	\end{enumerate}
	then the span of the two sets is the same.
\end{prop}

\begin{proof}
	Consider $\rho = \sum_i a_i |\psi_i\>\<\psi_i|$. For a unitary vector $\varphi \in \mathcal{H}$ we have
	$$p(\varphi|\rho)=tr(\rho |\varphi\>\<\varphi|) =  \sum_i a_i |\<\psi_i|\varphi\>|^2$$
	Since all $a_i$ are positive, $p(\varphi|\rho) = 0$ if and only if $\varphi$ is orthogonal to all $\psi_i$.
	
	Now suppose $\rho = \sum_i a_i |\psi_i\>\<\psi_i| = \sum_j b_j |\phi_j\>\<\phi_j|$. Then a vector $\varphi$ is orthogonal to all $\psi_i$ if and only if it is also orthogonal to all $\phi_i$, which means $span(\{\psi_i\}) = span(\{\phi_j\})$) as they have the same orthogonal complement.
\end{proof}

\begin{prop}\label{prop_decomposition}
	Let $\mathcal{H}$ be a complex inner product space. Let $\psi \in \mathcal{H}$ be a normalized state and $\rho : \mathcal{H} \to \mathcal{H}$ a density operator of finite rank such that $\<\psi|\rho|\psi\>\neq 0$. Then we can express $\rho$ as a mixture of $\psi$. That is, there exists a finite set of normalized states $\{\psi_i\} \in \mathcal{H}$ such that $\psi_1 = \psi$ and $\rho = \sum_i p_i |\psi_i\>\<\psi_i|$.
\end{prop}

\begin{proof}
	The set of all possible density operators is a convex set, which can be characterized as a subset of a vector space $V$. Let $\rho$ be a density operator such that $\<\psi|\rho|\psi\>\neq 0$. This will be a point in the convex set. If $\rho = |\psi\>\<\psi|$, we are done. If not, the two elements will identify a line, which must intersect the boundary of the convex set in two places. One must be $\psi$, since $\psi$ is a pure state and therefore an extreme point. Let $\rho_1$ be the other point. If it is an extreme point, we are done as $\rho$ is an affine combination of $\psi$ and $\rho_1$. If not, $\rho_1$ is on a part of the boundary that is not strictly convex. That region will be a convex set constrained on a subspace $V_1$ of $V$. Note that $V_1$ does not include $\psi$ and it does not span the direction identified by $\rho_1$ and $\psi$. This means that we can't have $\rho_1 = \rho$ as $\<\psi|\rho|\psi\>\neq 0$. Therefore we have that $\rho$ is an affine combination of $\psi$ and $\rho_1$, which must be a density operator of finite rank lower than $\rho$. We can express $\rho_1$ as a convex combination of finitely many extreme points $\psi_2, \psi_3, ..., \psi_n$, each of them corresponding to a pure state. We have that $\rho$ is an affine combination of pure states that include $\psi$.
\end{proof}

\begin{prop}\label{prop_superpositionIsDecomposition}[Superposition is multiple decomposition of mixed states.]
Let $\mathcal{H}$ be a complex vector space. Let $\psi \in \mathcal{H}$ be a normalized vector and $\{\phi_j\} \in \mathcal{H}$ a finte sets of normalized vectors that does not contain $\psi$. Then $\psi$ is a superposition of $\{\phi_j\}$ if and only if there exists a density operator $\rho$ that can be expressed both as a strict convex combination of $\{\phi_i\}$ and of another set of normalized vectors that contain $\psi$. That is, we can find a finite set of normalized vectors $\{\psi_i\} \in \mathcal{H}$ and two sequences $\{a_i\}, \{b_j\} \in \mathbb{R}_{>0}$ such that
\begin{enumerate}
	\item $\psi_1 = \psi$
	\item $\sum_i a_i = 1$
	\item $\sum_j b_j = 1$
	\item $\sum_i a_i |\psi_i\>\<\psi_i| = \sum_j b_j |\phi_j\>\<\phi_j|$,
\end{enumerate}
\end{prop}

\begin{proof}
	Suppose $\psi$ is a normalized state that can be written as $\psi = \sum_{i=1}^n c_i \phi_i$ where $\{\phi_i\} \in \mathcal{H}$ is a finite sets of normalized vectors that do not contain $\psi$. Since $\{\phi_j\}$ are not necessarily orthogonal, it is not necessarily true that $|\<\psi|\phi_i\>| = |c_i|^2$ or that $|\<\psi|\phi_i\>| \neq 0$ for all $i$. However, since $\psi$ is normalized and $\psi \neq \phi_i$ for all $i$, there must be at least two vectors in $\{\phi_i\}$ such that $|\<\psi|\phi_i\>| \neq 0$. We can then find $\{p_i\} \in \mathbb{R}+$ for which $\sum_i p_i =1$, such that $\rho = \sum_i p_i |\phi_j\>\<\phi_j|$ and $\<\psi|\rho|\psi\> \neq 0$. By Proposition \ref{prop_decomposition}, $\rho$ can be expressed as a convex combination of a set of normalized states that include $\psi$.
	
	Conversely, suppose we have a density operator $\rho$ that can be expressed both as a strict convex combination of $\{\phi_i\}$ and of another set of normalized vectors that contain $\psi$. By Proposition \ref{prop_densitySpan} the span of $\{\phi_i\}$ will include $\psi$ and therefore $\psi$ is a superposition of $\{\phi_i\}$.
\end{proof}

As for the inner product, we show that the Born rule can be understood as characterizing the entropy of equal mixtures over state pairs. This gives us a geometric understanding of the inner product at equal time, instead of a probability of transition, which brings it more in line with the use during superposition. It should also be noted that the von Neumann entropy of a mixture can be understood as the minimum Shannon entropy over all possible decompositions,\footnote{TODO: cite} which again shows the connection between the geometry of the convex space of statistical ensembles and the inner product.

\begin{prop}\label{prop_innerProductIsEntropy}[Inner product is an entropic structure]
Let $\mathcal{H}$ be a complex Hilbert space. Let $I : \mathcal{H} \times \mathcal{H} \to \mathbb{R}$ be the von Neumann entropy of the equal mixture of two pure states. That is
\begin{equation}
	I(\psi_1, \psi_2) = S\left(\frac{1}{2}|\psi_1\>\<\psi_1| + \frac{1}{2}|\psi_2\>\<\psi_2|\right).
\end{equation}
Let $p :  \mathcal{H} \times \mathcal{H} \to \mathbb{R}$ be the square of the inner product. That is
\begin{equation}
	p(\psi_1, \psi_2) = |\<\psi_1| \psi_2\>|^2.
\end{equation}
Then $p$ and $I$ can be reconstructed from other. That is, there exists an invertible function $f$ such that
\begin{equation}
	I(\psi_1, \psi_2) = f(p(\psi_1, \psi_2)).
\end{equation}
\end{prop}

\begin{proof}
	Copy proof from other paper.
\end{proof}

Having shown the connection between superposition and non-unique decomposition of mixed state, and between the Born rule and the entropy of mixtures, we can now use these to justify the physicality of the complex inner product space structure for quantum states.
\begin{prop}
	Complex inner product spaces are physical when used to represent the state space of quantum systems.
\end{prop}
\begin{justification}
	Since physical preparations and measurements are most of the time not perfect, a physical theory must define statistical ensembles. Part of that definition includes keeping track of statistical ensembles under statistical mixtures, that is which particular mixture is obtained by mixing particular states in particular proportions. A particular feature of quantum mixed states is that, unlike classical states, they do not in general provide a unique decomposition in terms of pure states. This non-unique decomposition, as shown by proposition \ref{prop_superpositionIsDecomposition}, is equivalent to the ability to create superpositions of pure state. The inner product structure is therefore the exact structure needed to characterize quantum ensembles and their properties, which is required by the physics.
	
	Additionally, a physical theory must be able to define the entropy of each ensemble, as required by thermodynamics. In quantum mechanics, the thermodynamic entropy is recovered by the von Neumann entropy, which Proposition \ref{prop_innerProductIsEntropy} show it is exactly captured by the inner product. This again shows that the inner product structure is required to capture a necessary physical requirement.
\end{justification}

\section{The unphysicality of completeness}

To show that the completeness requirement on complex inner product spaces that represent quantum states is unphysical, we need to show that this definition forces the state space to include elements that cannot have physical correspondents.

The Hellinger–Toeplitz theorem states that a self-adjoint operator $O$ defined on the whole Hilbert space $\mathcal{H}$ is necessarily bound. Therefore, an unbound operator $X$ cannot be defined on the whole space, meaning that the operator must diverge or be ill-defined on a subset of $\mathcal{H}$. To see that the problem is the completeness requirement of the Hilbert space, we prove the following:
\begin{prop}
	Let $\mathcal{H}$ be a Hilbert space and $X : D(X) \to Y$ a unbounded operator where $D(X)$ is the domain of $X$ and $Y$ is another Hilbert space. Then $D(X)$ is an inner product space that is not complete.
\end{prop}
\begin{proof}
	The domain $D(X)$ of the operator is a subspace of $\mathcal{H}$. In fact, if $||X(v_1)||_Y$ and $||X(v_2)||_Y$ are finite, so will $||X(a_1 v_1+a_2v_2)||_Y$. Therefore $D(X)$ is an inner product space. It cannot be complete by the converse of the Hellinger–Toeplitz theorem.
\end{proof}

To understand the physical significance, consider the position operator $X : D(X) \to \mathcal{H}$. If we take a normalized vector $\psi \in \mathcal{H}$, the norm $||X\psi|| = \<X\psi|X\psi\> = E[X^2|\psi]$ is equal to the expectation of the position squared. The operator is unbounded because the position can be arbitrarily large. We can therefore construct a Cauchy sequence $\{\psi_i\}$ such that $\lim\limits_{i \to \infty}||X\psi|| = +\infty$, that is take a sequence of vectors for which the expectation of position is larger and larger. Because of completeness, the limit of the Cauchy sequence will be in the Hilbert space. However, because the expectation diverges, the limit cannot be in the domain of $X$. Cauchy completeness forces us to include ``states'' for which the position is ill-defined.

The matter would still be manageable if we had a way to keep these degenerate cases isolated, but this is not the case. In general, a unitary operator can move vectors in and out of the domain.
\begin{prop}
	Let $\mathcal{H}$ be a Hilbert space, $X : D(X) \to Y$ a unbounded operator and $U : \mathcal{H} \to \mathcal{H}$ a unitary operator. Then, in general, $U(D(X)) \notin D(X)$.
\end{prop}
\begin{proof}
	Let $\psi, \phi \in \mathcal{H}$ be two normalized vectors. Then we can construct a unitary operator $U$ such that $\phi = U(\psi)$. For example, we can take the operator that performs a rotation in the subspace identified by $\psi$ and $\phi$ and leaves the orthogonal subspace unchanged. We can now take $\psi$ to be in $D(X)$ while $\phi$ to not be in $D(X)$. Therefore, in general, a unitary operator can move vectors in and out the domain of an unbounded operator.
\end{proof}

To understand the physical significance, note that unitary operators are isomorphisms between Hilbert spaces. That is, mathematically, two Hilbert spaces are considered indistinguishable if there exists a unitary transformation between them. As we saw, unitary operations can change the domain in which unbound operators are well defined: they can map states for which position is well defined onto states for which it is not. While the mathematical structure remains unchanged, the physical significance hasn't.

More concretely, a change of variable $X$ to $Y$ would be a unitary operator as is just a change of representation. However, we can construct changes of variables such that the domain of $X$ is not exactly mapped to the domain of $Y$. Let $y=y(x)$ be our change of variable such that $y(0) = 0$. If $\psi(x)$ is a wavefunction expressed over $x$, and $\phi(y)$ represents the same state as a wavefunction over $y$, we have the following relationship:
\begin{equation}
		\int_{0}^{y(x)} \phi^\dagger(y) \phi(y) dy = \int_{0}^{x} \psi^\dagger(x) \psi(x) dx
\end{equation}
To find a coordinate transformation that take finite expectations to infinite expectation, we set the initial and final wavefunctions as follow:
\begin{align}
	\psi(x) &= \sqrt{\frac{e^{-x^2}}{\sqrt{\pi}}} \\
	\phi(y) &= \frac{1}{\sqrt{\pi(y^2 + 1)}}.
\end{align}
The first distribution is a Gaussian, and therefore all moments of the distribution, the expectation for $x^n$, are finite. The second goes to infinity like $\frac{1}{x^2}$, so the expectation will diverge for all moments above the first. We find
\begin{equation}
	\begin{aligned}
		\int_{0}^{y(x)} \frac{1}{\pi(y^2 + 1)} dy &= \int_{0}^{x} \frac{e^{-x^2}}{\sqrt{\pi}} dx \\
		\frac{\tan^{-1}(y(x))}{\pi} &= \frac{\erf(x)}{2} \\
		y(x) &= \tan \left(\frac{\pi}{2}\erf(x)\right). \\
	\end{aligned}
\end{equation}
The graph of the above function increase so fast that, when plotted, it looks like it has a vertical asymptote. Nonetheless, it is an invertible function over the whole domain, and will induce a unitary transformation on the Hilbert space.\footnote{Note that we could implement a similar coordinate transformations in classical mechanics, which would also change finite moments of a distribution into infinite ones. It may be that, like differentiable manifolds are constrained to only differentiable coordinate transformation, we need ``statistical manifolds'' that are constrained to coordinate transformations that preserve the finiteness of moments of distributions. This is a topic that requires further analysis.}

Unitary operators are also used in quantum theory to represent time evolution. Typically, we have a family of unitary operators $\{U_t\}_{t \in \mathbb{R}}$ that is strongly continuous (i.e. $\lim_{t \to t_0} U_t = U_{t_0}$) and respect composition in time (i.e. $U_t U_s = U_t+s$). We can turn the above transformation into an evolution by setting
\begin{equation}
	y(x, t) = \cos(\omega t) x + \sin(\omega t) \tan \left(\frac{\pi}{2}\erf(x)\right).
\end{equation}
The idea is that the evolution will simply stretch and shrink the wavefunction intermittently, potentially oscillating expectation values from finite to infinite and viceversa in finite time. Clearly, this is not a meaningful time evolution, yet it will correspond to a strongly continuous one-parameter unitary group and, by Stone's theorem, will even admit a Hamiltonian.

The mathematician that points out that this all known, and there is nothing new, is missing the point. The physicists that notes that, yes, those elements are clearly unphysical, but I don't use them, so I do not care, is also missing the point. The point is that, physically, we will want to make general statements such as ``for all observer X is valid'' or ``under all evolution Y is valid''. Given that Hilbert spaces mix physically clearly meaningful object with clearly unphysical ones, we have no way to make those statements precisely.

We can conclude the discussion with the following
\begin{prop}
	Infinite dimensional complex Hilbert spaces are unphysical when used to represent the state space of quantum systems due to completeness.
\end{prop}
\begin{justification}
	If a quantum system is modeled by a finite dimensional space, and since every finite dimensional space is complete, finite dimensional complex Hilbert spaces are physical.
	
	Some physical system that are described by unbounded discrete quantities (e.g. number of particles) or by continuous quantities (e.g. position) which require infinite dimensional spaces. Infinite dimensional complex inner product spaces, then, are needed to represent quantum system.

	An unbounded operator cannot be defined on all the elements of a Hilbert space by the converse of the Hellinger-Toeplitz theorem. This means that if represents states as rays on a Hilbert space and observables as operators, the unbounded observable will not be well defined, not even as a statistical quantity, on all states. In particular, whether the statistical properties of an observable are well defined, whether it is possible to experimentally identify a state through tomography, would be observer dependent. Moreover, whether the expectation of an observer is finite or not would be something that can change in finite time.
	
	On physical ground, we must have that an observable has well defined statistical properties over all states, that this property is covariant and that is preserved by time evolution. Hilbert spaces do not satisfy this requirement and are therefore unphysical.
\end{justification}

\section{The possible physicality of Schwartz spaces}

Recall that an inner product space $V$ is complete if every Cauchy sequence in $V$ converges in $V$. This definition is difficult to characterize physically, therefore we use an equivalent condition: an inner product space $V$ is complete is complete if and only if all absolutely convergent series converge in $V$ (see theorem 13.8 in \cite{roman_2008}). This reframes the requirement in terms of convergence of linear combinations, and therefore superpositions.

We now show that if we have an unbounded operator, like position, completeness requires the existence of pure states for which 

If we are only interested in observable with finitely many possible outcomes, we can use finite dimensional spaces. But as soon we have discrete quantities with arbitrarily large values, such as the number of particles, or quantities that are continuous, like position and momentum, we need infinite dimensional spaces. If we allow infinite dimensional spaces, we need some way of controlling what infinite linear combinations are allowed or not allowed. Cauchy completeness is one such way, but if that is not physical, what should we use?

We saw that the main problem is having expectation values that diverge, therefore the naive idea would be to require that the expectation value for all possible variables converge. This would require the expectation for $e^x$, $e^{e^x}$, $e^{e^{e^x}}$ and so on to be finite as well, which seems rather extreme. But what is a reasonable point to stop? If the idea is that we need to be able to reconstruct the state from expectation values, we should note that bounded distributions can be recovered from all the moments of the distribution, from the expectation of $x^n$ for every finite $n$. It seems reasonable, then, to require the expectation of all polynomial of position and momentum to be finite.

In quantum mechanics, this means requiring all expectations of $X^nP^m = -\imath \hbar x^n\partial_x ^m$ to be finite. This restricts our space to those functions that are infinitely smooth (i.e. all derivative exist) and decrease very rapidly as $x$ goes to infinity: the Schwartz functions. Requiring finite expectation for all polynomials of position and momentum, then, does not give us the usual $L^2$ Hilbert space, it gives us the Schwartz space. Is this a better candidate?

First of all, the Schwartz space is a subspace of the $L^2$ Hilbert space taken as an inner product space. That is, all Schwartz functions are elements of the Hilbert space, they are closed under linear combinations and have the same inner product. It is not, however, complete, which is what we want. Moreover, it is a dense subspace, meaning that any element of the Hilbert space can always be approximated by a Schwartz function with an arbitrary level of precision. Or, equivalently, that once a map is defined over the Schwartz space, the map is uniquely extended over the Hilbert space. This is a good hint that we have thrown away only unphysical elements.

If we restrict ourselves to the Schwartz space, then, the only unitary transformations we are interested in are those that map Schwartz function to Schwartz functions. The change of coordinate we defined in the previous section, then, is ruled out. Limits in terms of Cauchy sequences are not guaranteed, but limits in terms of expectation values are guaranteed: if we have a sequence of states such that the limit of the expectation converge, then we are guaranteed that the limit is also a Schwartz function.

The Schwartz space has also a very important property: it is the only space that is closed under the Fourier transform. That is, the Fourier transform of a Schwartz function is a Schwartz function, and it is the only set of functions with this property. This is not, in retrospect, a nice property that would be convenient for physicists. The theory of tempered distribution, which allows us to define the Dirac $\delta$-function, is mathematically based, at its core, over the Schwartz space. Therefore, this space already plays a fundamental role in the definitions of the tools we already use.

On the downside, many of the tools we use indeed assume a Hilbert space and many theorems would not hold without Cauchy completeness. There are two responses to this issue. First of all, there is no reason to prohibit that calculation are performed on the larger, unphysical space. When solving an integral, we do sometimes extend the domain for real to complex values, which are unphysical, because complex analysis has nicer mathematical features. The result so found, however, is still the valid result on the real domain. Similarly, we can pose the problem on the Schwartz space, extend to the Hilbert space for calculation, and then bring the result back to the Schwart space. However, there is a second way to look at this issue. Given that the focus has been squarely on Hilbert spaces, we do not know which mathematical results will hold, or even whether other results may be found. This is not something that the authors of this paper can answer and neither the mathematicians that were asked. This requires a serious research effort on the mathematical underpinning of multiple areas, which brings us to our closing point.

This effort is never going to happen if the physics community, as whole, do not generate enough interest on the subject. There may be a better series of mathematical tools and results that stem from a more precise specification of our physical requirements in terms of mathematical definitions. It is unlikely that the mathematical world will give us these tools unprompted. It is the job of us physicists to understand exactly what are ramifications of the definitions in terms of what physical objects would be left out or what unphysical objects would be brought in.

% TODO: hint that the unitary transformations on Schwartz space are a subset of the ones on the Hilbert, and therefore they have unique inverse; operators we are interested in are uniquely extended to the Hilbert space.

\section{A final remark on the mathematical foundations of physical theories}

When mathematicians and philosophers noticed that mathematical theories at the time allowed to express inconsistencies (e.g. Russell's paradox, Berry paradox, ...), effort was put into strengthening the foundations of mathematics so that such paradoxes were either resolved or couldn't be expressed. With regard to the mathematical foundations of physical theories, we have a similar problem: we can write statements that, though mathematically consistent, are physically inconsistent. Looking for these problems and addressing them is ultimately what will lead to a solid foundation, which, we believe, is the prerequisite to solve other outstanding issues in fundamental physics.

\end{document}
