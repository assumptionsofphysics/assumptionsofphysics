\documentclass[letterpaper]{article}

\input{../../../include/basicstyle}
\input{../../../include/theorems}
\input{../../../include/logic}

\begin{document}

\title{TBD}
\author{Gabriele Carcassi, Christine A. Aidala \\ University of Michigan}

\date{\today}

\maketitle

\begin{abstract}
	TBD
\end{abstract}


\section{Introduction}

------------------
Cite other axiomatic works.

Single state space to capture:
* descriptions at all levels
* descriptions at different times
* correlations between descriptions at equal time (equations of state)
* correlations between descriptions at different times (evolution laws)
* different correlations at different description
* granularity/precision of such descriptions

We can't have:
* probability as a native concept
------------------

In the intro, describe only the discrete case as it simpler to understand and already contains all the physics. The continuous case adds the complication of 

Evolution is a temporal sequence of states. Process is a set of possible evolutions. What we want to study is how a statement about a state at a particular time selects a particular set of possible evolutions and therefore selects a set of possible states at a previous or past time.

Define determinism and reversibility in terms of what evolutions exist. Note that a dynamical system is a deterministic system.

Note how the number of states does not always match the number evolutions it is compatible with. Note that under deterministic evolution the number of compatible evolutions can only increase. For dynamical systems, then, the number of evolutions associated to a state can only increase in time and it is stationary for equilibria.

If we compose independent systems, the number of possible states and trajectories is the product. If we take the logarithm, then those numbers are additive. Conceptually the entropy is the logarithm of the number of evolutions compatible with a given state. This article shows how this simpler and more general concept leads, in special cases, to the Boltzman entropy and the Shannon entropy. We will also see how this same concepts is applicable more in general, including the case of non-Hamiltonian systems.

\section{Different level of precision}



We regard states as points in a space. Conceptually, this presents problems. Mathematically, what we care about is the sigma algebra.

Introduce theoretical domains as point-less spaces, descriptions, that follow a countable boolean algebra. A size is given by a measure, additive map from the theoretical domain to the reals.

To define a unit system, we take one statement to be the unit, the size of a set can be defined as the ratio of the measure of the set and the measure of the set of the unit.

Two statements are independent if all minterms are possible, are not contradictions.

TODO: Combine with

\section{Experimental domains}

First introduce tabular versions of contexts. Introduce equivalence, narrowness, independence and incompatibility on tables.

Introduce verifiable statements and domains. States as possibilities.

Precision over statements.


\section{Process entropy}

The general idea is that we need to describe a system as it evolves in time. To that end, we need to define what we mean by states, processes and evolutions in the most general setting such that it can be applied to thermodyamic, dynamical, classical, quantum systems alike. A formal and more rigorous introduction of the framework, both mathematically and conceptually, is given in the appendix. Here we limit ourselves to a quick overview of the main point. We will we first attempt to use measure theory, which hopefully the reader is already familiar with, show its shortcomings and then present our framework as an amendment.

To define a measure space we start with a set of objects that fully define all variables.\footnote{In probability theory this is called the sample space.} In our case, it will be the set $E$ of \textbf{possible evolutions} which represent full descriptions of the system at all times. For example, if our process describes the vertical motion of a point-particle, an evolution would be something like \statement{the trajectory of the particle is $y=10 \, m - t \cdot 9.80665 \, m/s^2 $}. Through this set, the process implicitly characterizes what is physically allowed. For example, in a relativistic setting evolutions with velocity greater than the speed of light would not be allowed and therefore no be part of $E$.

Next we need a $\sigma$-algebra on $E$ which can be thought as a set of incomplete descriptions about the system.\footnote{In probability theory this is called the set of events.} For a point-particle, the description \statement{at time 0 s the position is 1 m} would correspond to all evolutions such that the particle is at the given position at the given time. We call \textbf{process domain} $\tdomain[P]$ the set of all these descriptions as it captures all those descriptions pertinent to the process at hand.

Finally we a measure $\mu : \tdomain[P] \to \mathbb{R}$ that allows us to give a size to each description. This allows us to characterize which description is more or less precise: \statement{at time 0 s the particle is between 0 m and 1 m} is doubly more specific than \statement{at time 0 s the particle is between 0 m and 2 m} precisely because it correspond to half the evolutions of the second.

This measure theoretic view gives a sense of what we would like to do, except it doesn't work and needs to be amended. Its biggest strength is its generality. Even though we typically use properties and quantities for the system to label the statements, they do not appear in the basic structure. Therefore, depending on the system, we will have statements like \statement{the average volume between 1 and 2 seconds is between 3 and 4 liters}, \statement{the half-life of the material is between 4.46 and 4.48 billion years} or \statement{at time 2.5 s the position of the ball is [3.1, 4.2, -1.2] meters} which will correspond to the appropriate set of evolutions. The problem is that it fails to handle different level of descriptions in two ways.

First of all, the description given by the evolutions are mathematically different objects from all others: the first are points and the other are sets. This is awkward because evolutions of a coarse grain process will be simple descriptions on a fine grain one. So we can't properly see one as a mathematical structure contained in the other.

Second, the measure does not have enough resolution: it can only compare objects of the same dimensionality. If we imagine all evolutions to be points on an $n$ dimensional manifold, if the measure gives finite values for $k$-dimensional regions it will necessarily give measure zero for all regions with lesser dimensionality and infinite measure for those with greater dimensionality. Therefore we will not be able to relate the measure at different level of scale. This, again, is a problem since states will have different dimensionality when studying coarse and fine grained descriptions.

To solve the first problem, we note both the evolutions in $E$ and the elements of $\tdomain[P]$ are, in the end, descriptions of the system. Therefore we treat as what they are: statements in a well-posed logical system. Our process domain $\tdomain[P]$, then, is simply a set of statements that is closed under negation (NOT), countable disjunction (OR) and countable conjunction (AND), a $\sigma$-complete Boolean algebra. The evolutions $E$ are also descriptions about the system, so we simply have $E \subset \tdomain[P]$. All descriptions of subsystems or of the system at lower scale will simply be sub-algebras of $\tdomain[P]$. 

All the set operations one would have can be translated in terms of logical operations. In the same way that on sets we have an inclusion operator $\subseteq$, given two statements $\stmt_1, \stmt_2 \in \tdomain[P]$ we say one is \textbf{narrower} than the other, noted $\stmt_1 \narrower \stmt_2$, if the second is true whenever the first is. This can describe relationships at different scale (e.g. \statement{the horizontal position is between 2.5 and 3 meters} $\narrower$ \statement{the horizontal position is between 2 and 3.5 meters}), on different quantities (e.g. \statement{the horizontal position is between 2.5 and 3 meters and the vertical position is between 1 and 1.5 meters} $\narrower$ \statement{the horizontal position is between 2.5 and 3 meters}), constraints between variables at the same time (e.g. \statement{the temperature of the water in the glass is 3.98 C} $\narrower$ \statement{the density of the water in the glass is 1 $g/cm^3$}) or at different times (e.g. \statement{at time 0 s the position is 1 m and the velocity is 1 m/s} $\narrower$ \statement{at time 1 s the position is 2 m}). Evolutions, then, can be seen as the narrowest statements in the domain that can still be true.

Similarly, we say that two statements are \textbf{compatible}, noted $\stmt_1 \comp \stmt_2$, if they can both be true or incompatible if the cannot, which in terms of set would correspond to the non-empty intersection. For each $\stmt \in \tdomain[P]$ we can define $E(\stmt)$ as the set of evolutions that are compatible with it. These are exactly the sets we had in the $\sigma$-algebra before, which now corresponds to $E(\tdomain[P])$. There are operations, all with straight-forward physical meaning, that can be introduced though we will stop here since these are the only two we strictly require.

This small change has significant advantages. The practical one is that we can now mix and match descriptions at different scale and of different parts of the system within a single framework. The conceptual advantage is that it is clear that all we are talking about is descriptions about a system within a model and their logical relationships, which makes it straight-forward to understand our conclusions. Lastly, the structure is still very similar to the standard tools of measure theory, therefore, once a scale or subsystem is chose, measure structures can be recovered.

The second problem is solved by replacing the measure with a suitable partial order $\finer$ on $\tdomain[P]$ which, given two statements, it tells us whether the description of one is \textbf{finer}, more refined, than the other. Suitable means, for example, that it needs to be compatible with narrowness: if $\stmt_1 \narrower\stmt_2$ we must also have $\stmt_1 \finer \stmt_2$. Two statements are \textbf{equigranualar}, noted $\stmt_1 \eqgran \stmt_2$, if they provide the same level of description. By analogy with geometrical objects, we can see that these relationships can now span different dimensionality: isolated points are always going to be smaller than lines which are always smaller than surfaces and so on, while we can still have lines and surfaces of the same size. For example, we can say that \statement{the trajectory of the particle is $y=t \cdot 1 \, m/s$} $\eqgran$ \statement{the trajectory of the particle is $y=t \cdot 2 \, m/s$} and that \statement{the position at time 0 sec is between 0 and 1 m} $\eqgran$ \statement{the position at time 0 sec is between 1 and 2 m}.

To recover measures, the idea is that, given a statement $\stmt[u] \in \tdomain[P]$ we can construct a measure $\mu_{\stmt[u]}$ such that $\mu_{\stmt[u]}(\stmt[u]) = 1$ and $\stmt_1 \finer \stmt_2$ will mean $\mu_{\stmt[u]}(\stmt_1) \leq \mu_{\stmt[u]}(\stmt_2)$. That is, we can quantity how more or less precise a statement is compared to a fixed statement taken as a unit.

This does not work in general, though, because statements along different dimensions cannot be compared. For example, consider the pressure/volume state space for an ideal gas. Comparing \statement{the pressure is 1 kPa and the volume is between 1 and 2 liters} and \statement{the pressure is between 1 and 2 kPa and the volume is 1 liter} would mean saying where one unit liter is bigger or smaller than 1 kPa. There are two types of statements in $\tdomain[P]$, though, that can always be compared.

For the first type, note that all evolutions in $E$ must give a complete description, so they must be all equigranular. Therefore any statement that corresponds to finitely many evolutions (e.g. \statement{the full trajectories is either $y=t \cdot 1 m/s$ or $y=-t \cdot 1 m/s$}) will be comparable to all other statements.

For the second group, note that in our ideal gas example one of the quantities was determined with infinite precision. If we gave a range for all quantities, we would compare areas in that space, which we can always do. Note that statements with finite precision measurements are the only ones we can experimentally verify. So, we will require that all experimentally verifiable statements are comparable. We call \textbf{experimental domain} for the process the subset $\edomain[P] \subseteq \tdomain[P]$ of statements that can be, at least in line of principle, experimentally verified.

We leave the full mathematical characterization in the mathematical section. We limit ourselves to make a few important comments. Verifiable statements will correspond, in terms of sets of $E$, to finite and infinite volumes. Requiring those to be comparable means the $E$ is a measurable space. In the familiar spaces, such as phase space or physical space, the measure we have will be the familiar one. As the process domain corresponds to a $\sigma$-algebra on $E$, the experimental domain corresponds to a topology on $E$. Therefore notions of continuity can be recovered as well. The process domain is the closure of the experimental domain under standard Boolean operations. This means that all the process domain is fully specify by, at least in principle, experimentally verifiable statements. The space does not contain any assertion that cannot ultimately be defined in terms of experiments. Lastly, requiring that, given enough time, each statement will be verified means the experimental domain must be generated by countably many statements. This means the topology is second countable and one is limited to work with ``nice'' spaces (e.g. spaces of continuous functions, separable Hilbert spaces, ...) not because they are ``nice'', but because they are the only physically meaningful ones.

To sum up, we have two foundational object. The first object is the process domain $\tdomain[P]$ which is a Boolean algebra that contain all the possible description of our process. A subset $\edomain[P]$ contains those that are experimentally verifiable, which contain all the information in the full domain. The narrowest statements in $\tdomain[P]$ correspond to the evolutions $E$, that provide the full description at all times. The second object is the operator $\finer$ which gives us a way to compare two statements and decide which one gives a more refined description. Though two statements will not in general be comparable, all verifiable statements are comparable and all evolutions provide an equally refined description.

This framework imposes very few requirements which are of very general applicability. It does not matter what specific quantities are used, or whether the process is from physics, chemistry, control systems, ecology, economics, sociology, or some other realm we have yet to discover. In the end, if we have a process we need to model, our theory will need at least to provide those objects. This means that the results we find will have broad applicability as well.

\section{States}

\section{States}

As the process extends over time, it is natural to want to organize the statements in our process domain into partial domains, one for each moment in time. Given our time parameter $t \in T \subseteq \mathbb{R}$, we can imagine to carve a domain $\tdomain_t$ that would correspond to all the statements about the system one can make at the given time.


At each moment, we have a set of possible statements about the system corresponding to physically measurable properties. We call state the maximal description that can be given at a particular time. Given the state, we know all that can be said about the system in that moment. We define an evolution of the system as the maximal description of the system at all times. If we knew the exact evolution, we know all possible descriptions of the system at all times. Therefore picking an evolution is equivalent to picking a state at each time. A particular process will constrain how the system can evolve, it will constrain the possible evolutions. Therefore we formally define a process as a set of possible evolutions, the ones that are allowed by the process.

As each evolution gives the total description of the system at all times, we assume that all evolutions give the same level of description. We also assume we have a way to compare sets of possible evolutions and determine which is bigger and which is smaller. Mathematically, we have a measure defined on the set of possible evolutions. Each description, if verified experimentally, will narrow the set of possible evolutions to the ones that are compatible with said description. Therefore each description, and in particular each state, can be assigned a value that corresponds to the number of evolutions compatible with it. We call the logarithm of the number of evolution the entropy associated to the description.

We define a process to be deterministic if knowing the state at one time means we can predict with absolute certainty the state at a future time. If this is the case, all evolutions compatible with one state cannot split and must all pass through the same states at all times. During a deterministic process, then, the number of evolutions per state can only increase over time. The entropy associated to each state is a monotonically increasing function.

Conversely, we define a process to be reversible if knowing the state at one time means we can reconstruct with absolute certainty the state a previous time.\footnote{Note that this notion of reversibility is not identical to the one usually found in thermodynamics, which corresponds to the ``ability to undo the change''. We will later find that the notion of thermodynamic reversibility corresponds to the case where system and environment together undergo a deterministic and reversible process.} Reasoning along the same lines, during a reversible process the entropy associated to each state can only decrease over time, as evolutions cannot merge. A deterministic and reversible process will necessarily see the number of states, and therefore the entropy, remain the same.

In a deterministic process, a state will be an equilibrium if, roughly speaking, the evolutions have fully merged and they will all give the same future state. In other words, after the equilibria the evolution is effectively reversible. This means that, at equilibria, the entropy will have reached a maximum. Each equilibria will be associated with a bundle of evolutions which will define, at times before the equilibrium, the set of states that will merge. For each equilibria one can construct a constraint, an assertion that remains true for each equilibria. Therefore each equilibria can be seen as the maximizing the entropy under the constraints imposed by the process.

Finally, a process over a system can be broken into two processes over two systems if and only if they are independent. That is, if the evolution over one subsystem tells us nothing about the evolution of the other or, equivalently, the measure on the evolutions on the whole is the product of the measure on the subsystems. In those cases, the entropy of the system is equal to the sum of the entropy of the subsystems. However, note that if the systems are independent throughout the whole evolution, no coupling can be defined between the subsystem.

A useful scenario is when the systems can be considered independent at the beginning of the evolution, couple, and then return to be independent at equilibrium. The entropy can then be considered additive at the beginning and at the end of the evolution, but not in between. Equilibria on the whole will necessarily correspond to equilibria on each subsystem. Note how this conceptually corresponds to the scenarios studied in thermodynamics.





\section{Math section}

Let $\tdomain$ be the set of all statements about the evolution of the system. This is a $\sigma$-complete Boolean algebra. Let $E \subset \tdomain$ the set of all evolutions, these are the narrowest statements. To each statement $\stmt \in \tdomain$ corresponds a set of evolutions $A(s)$ that are compatible with the statement.

Given two statements $s_1, s_2 \in \mathcal{D}$ we can say whether one is finer than the other $s_1 \finer s_2$. Given any statement $\stmt[u] \in \mathcal{D}$, we have a function $\mu_u : \mathcal{D} \to \mathbb{R}^+\cup \{+\infty \}$ such that:
\begin{enumerate}
	\item $\mu_u$ is a measure
	\item $\mu_u(u) = 1$
	\item $\mu_u(s_1) \leq \mu_u(s_2)$ if $s_1 \finer s_2$
\end{enumerate}
The value $\mu_u(\stmt)$ tells us how many trajectories are compatible with $\stmt$ in terms of how many trajectories are compatible with the unit statement $\stmt[u]$.

The conditional probability $P(\cdot | \cdot) : \tdomain \times \tdomain \to [0,1]$ is defined as $P(\stmt_1 | \stmt_2) = \mu_{\stmt_2}(\stmt_1 \AND \stmt_2)$ and represents the fraction of trajectories that are compatible with $\stmt_2$ that are also with $\stmt_1$.

We define $T \subseteq \mathbb{R}$ to be the range of the time parameter. We define $\tdomain_{t} \subseteq \tdomain$ as the set of statements defined at the time t. Note this does not mean they are statement of only what happens at an instant in time. They can be averages around. It's how we decompose the problem at the desired time resolution. The states at time $t$ are the possibilities of $\tdomain_t$. The process is deterministic over the chosen states if for each $x_0 \in \tdomain_{t_0}$ we can find an $x_1 \in \tdomain_{t_1}$ such that $x_0 \narrower x_1$.  The process is reversible over the chosen states if for each $x_1 \in \tdomain_{t_1}$ we can find an $x_0 \in \tdomain_{t_0}$ such that $x_1 \narrower x_0$.

\bibliography{bibliography}


\end{document}