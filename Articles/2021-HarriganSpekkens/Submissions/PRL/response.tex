\documentclass[11pt]{article}

\usepackage[margin=1.25in]{geometry}

\usepackage{amssymb}
\usepackage{color}
\usepackage{graphicx}
\usepackage{epsfig,amssymb,amsmath,amsthm}
%\usepackage[active]{srcltx}
%\usepackage[hypertex,linkcolor=red]{hyperref}

\usepackage{color}
\usepackage{cancel}
\usepackage{tikz-cd}

\DeclareMathOperator{\spn}{span}

\newcommand{\pj}[1] {\underbar{$#1$}}
%\newcommand{\pj}[1] {\overline{#1}}


\def\>{\rangle}
\def\<{\langle}
\def\ca{_{\cal A}}
\def\cb{_{\cal B}}
\def\cc{_{\cal C}}
\def\comment#1{}
%\def\comment#1{ [{\bf Comment Lor:} {\sf #1}]}
\def\commentg#1{ [{\bf Comment Gabriele:} {\sf #1}]}
\def\labell#1{\label{#1}}
%\def\labell#1{\label{#1}{\mbox{{\tiny #1}}}}
%\def\section#1{{\par\em #1:--- }}
\def\togli#1{}
\def\sh{\mbox{sh}}
\def\iden{\openone}


\begin{document}
	
	
\title{\textbf{Reply to Professor Barrett's Comments}}

\author{The Authors}

\maketitle

	
We would like to thank the Editor for the opportunity to respond to Professor Barrett's engaging comments about our manuscript, these remarks not only allow us to explain in more detail our main result, but also to say a few words on its theoretical foundations. We hope to have properly addressed his doubts with the following text; similarly, we hope that these answers will be sufficient in order to send the paper to the next step of the review process.

We apologize in advance if we mention facts that may sound obvious to some readers; however, since knowledge of the the foundations of probability among our physics colleagues varies greatly, we would rather err on the side of caution.
\vspace{2mm}

There seems to be some sort of misunderstanding or disconnect between our intent and Barrett's perspective on the manuscript. In particular, he seems to think that we are aiming to contradict the PBR theorem. But, in the closing remark, he adds that:
\begin{quote}
We know from the PBR theorem that	 any such model must either be $\psi$-ontic or violate preparation independence. Possibly there is a result to be proven along the lines suggested above, that classical entropies in such a model cannot match quantum entropies.
\end{quote}

Ironically, this is literally what we aim to show in our paper; in fact, in the introduction we say:
\begin{quote}		
In this paper we are not going to rebut the theorem itself.
			
			...
		
Combining these results with PBR, our conclusion is that the HS classification itself is fundamentally problematic.
\end{quote}

This statement clearly affirms that in our argument we are using the PBR theorem, not contradicting it. As Barrett correctly says, the PBR result rules out a sub-category of ontological models: $\psi$-epistemic models for which preparations are assumed independent. We are \emph{not} refuting that claim. However, many scholars think that the PBR theorem proves that $\psi$-ontic states are the correct interpretation of quantum states. We point out that such a view is not correct by showing that the whole HS classification is problematic. Indeed, what we show is that another sub-category, the $\psi$-ontic models, are to be ruled out as well, since they do not agree with quantum information theory. It is the combination of our result and the PBR theorem that makes us conclude that the HS categorization is essentially ``empty''.

The above mentioned closing remark suggests that our intent is aligned with his; therefore, it is not clear to us where the disagreement is. The result that rules out $\psi$-ontic models is stated in the abstract:
\begin{quote}
In this paper we show that the HS framework has a fundamental problem: the epistemic structure it implicitly assumes does not follow the one dictated by quantum mechanics. Namely, \textbf{the map between the epistemic states of the model and quantum density matrices preserves neither the value nor ordering of the information entropy.}
\end{quote}
\noindent This point is not acknowledged, refuted or commented on in Barrett's response; this fact left us very confused.

Before going into the merit of some of the technical details, let us take a step back. In an ontological model the epistemic state is represented by the probability $p(\lambda | P)$ of obtaining an ontological state $\lambda$ given a preparation $P$. Classical mixture is treated like classical probability conditioning (i.e. $\sum_i  w_i p(\lambda| P_{\psi_i})$, cf.\ eq.~3 in our paper). This is a classical (Kolmogorov) probability density (given that the space $\Lambda$ must have cardinality of the continuum at least), meaning that the probability space has to satisfy the standard probability axioms (e.g.\ countable additivity). Hence, the crucial question is: can a classical (Kolmogorov, countably additive) probability space replicate all the results of a quantum probability space?
	
	Since Bell, this question has been answered by finding specific inequalities/constraints on the probability, to show that this or that model does not work. We are employing a different strategy. The foundations of both classical probability and classical information theory lie within (classical) measure theory. The results on one side are linked to the results on the other side: if we have a uniform distribution $\rho$ with support $U$, we have $S(\rho) = \log \mu(U)$. Since the function is invertible, constraints on information theory are necessarily constraints on probability theory and vice-versa. Therefore violations of the former coincide with violations of the latter. Moreover, on physical grounds, violations of information theory by themselves are enough to break statistical mechanics and thermodynamics predictions, and therefore would correspond to physical violations.
	
	On the other hand, the foundations of quantum probability are not based on classical measures, rather on the inner product of Hilbert spaces, which also constitutes the foundations for quantum information theory. As in the classical case, the two are linked. Suppose we have two pure states $\rho_\psi$ and $\rho_\phi$ expressed as density matrices. The entropy $S(\frac{1}{2} \rho_\psi + \frac{1}{2} \rho_\phi)$ is given by the Shannon entropy $S(\frac{1+p}{2}, \frac{1-p}{2})$ where $p=\<\psi | \phi \>\<\phi | \psi\>$. Again, this is an invertible function, so violations of probability are violation of information theory.
	
	Therefore, we can rephrase the question above as follows: can classical information theory replicate all the results of quantum information theory? We already know that the latter violates bounds given by the former. For example, a quantum composite state can have information entropy lower than the individual systems, something that classical information theory cannot replicate. Classical information theory is understood to be a ``strict subset'' of quantum information theory, and therefore, intuitively, we already expect that classical information theory cannot replicate all the results of quantum information theory. Using this strategy has also a technical advantage in that the spaces of classical and quantum mixtures are easy to compare: they are both linear spaces, where the linearity has the same physical meaning (i.e. statistical mixture). Classical and quantum probability spaces, on the other hand, are rather different as we lay out in the discussion section of the paper. The difference is so profound that von Neumann and others thought (erroneously in our view) that the rules of classical propositional logic had to be modified. Thus, going the information theory route bypasses all those problems.
	\vspace{2mm}
	
	Now, given this premise, as we say in the paper:
	\begin{quote}
		... we will concentrate on a single aspect of the map: how information entropy transforms under $\iota$. While there are other problems, we do not need to explore them: given the crucial role of entropy in information theory, its breakdown is
		sufficient to show that the epistemic structures of $E_{HS}$
		and $E_{QM}$ are different
	\end{quote}
	That is, since we have to show that classical information theory cannot replicate quantum information theory, we only need to find one particular feature that is irremediably broken. We settled on showing that mixing breaks the ordering of the information entropy since ordering is the most fundamental property of any quantitative system: the notion of greater and lesser information gets lost. This is a deadly blow which, again, should not be surprising as we already know that quantum information theory allows us to do things that classical information theory does not (it would not be such an interesting field of research otherwise). The breakdown of ordering is shown in Fig.~2, where one sees, for example, the third case and the second case switching places.
	
	Now, whether this different way to frame our result helps or not, we leave it to the reviewers. If it does, we can, of course, significantly alter the text of the paper. It will help, though, to address Barrett's comments.

	Barrett focuses on two details. The first is that the map $\iota : E_{HS} \to E_{QS}$ from epistemic states in the HS model to quantum mixed states is not invertible. 
	\begin{quote}
The paper points out that in this model, the different mixtures correspond to different distributions over $\lambda$, even though they yield the same quantum mixed state I/2.

Although the paper does not do this, one can in fact ask: must *any* ontological model for a qubit (not just the $\psi$-complete model considered) have the feature that different mixtures corresponding to the same quantum mixed state correspond to different distributions over $\lambda$? In fact, the answer is known to be yes, and this property of quantum systems is known as `preparation contextualityâ€™. This was shown in R.W.\ Spekkens, Phys. Rev. A 71, 052108 (2005), the first paper to introduce preparation contextuality, as well as in many other papers since.
	\end{quote}

	The fact that the map is not invertible is not a problem per se. As we say in the paper, the question is:
	\begin{quote}
The key question, then, is the following: is the
map $\iota$ sufficiently well behaved that we can understand
the epistemic content of $E_{QM}$ based on the epistemic
content of $E_{HS}$?
	\end{quote}
We contend that it is not, given that the ordering is broken as Fig.~2 shows, and this claim does not seem to us to be either acknowledged or challenged.

As for `preparation contextuality', the question is: can we still use classical conditioning of the form $\sum_i  w_i p(\lambda| P_i)$? To our understanding, that is the case. Therefore, we are still in a classical (Kolmogorov) space. The rules of how distributions and information entropy combine are the same. The argument stands.

The second comment focuses on the infinite versus finite value for entropy. The only objection to the claimed failure is:
\begin{quote}
Again, though, the conclusions here are only reached via consideration of the $\psi$-complete model.
\end{quote}
Let us address that objection. Suppose we have a $\psi$-incomplete model. In this case, an epistemic state will be a weighted sum $\sum_i  w_i p(\lambda| P_{\psi_i})$ of \textbf{nonoverlapping} functions $p(\lambda| P_{\psi_i})$. This means that the information entropy of the mixture reduces to $S(w_i) + \sum_i S(p(\lambda| P_{\psi_i}))$. Now, since the information entropy for each pure state must be zero to agree with quantum information, $S(p(\lambda| P_{\psi_i}))=0$ for all $i$, the entropy of the mixture further reduces to the Shannon entropy $S(w_i)$, which coincides with that of the $\psi$-complete case. This means that all we say for the $\psi$-complete models equally applies to all $\psi$-incomplete models, and therefore to all $\psi$-ontic cases.

While our result is directed toward $\psi$-ontic models, we can construct another argument for the remaining $\psi$-epistemic ones. We already know from PBR that the models that assume preparation independence violate quantum probability, therefore (by the arguments before) will also violate quantum information. Now consider a quantum state for which you have independence at the quantum probability level, that is the density matrix factorizes. In this case, the quantum information over the composite is the sum of the information over the individual systems. In classical probability, the information of the joint distribution is the sum of the information over the marginals if and only if the joint distribution is the product of the marginals. Therefore, on one side, if we want quantum information to agree with classical information, the probabilities must factorize, but on the other side PBR tells us that if the probabilities factorize then we have a violation of quantum probabilities. This is a contradiction, so we can't replicate both quantum probabilities and quantum information at the same time. To our understanding, this means that all $\psi$-epistemic models must be ruled out.

We concede that we haven't explored these points in the manuscript. We would be happy to add them if the reviewers think they are valuable.

Barrett then asks:
\begin{quote}
A better question would be whether there even exists a
(necessarily preparation-contextual) ontological model for a qubit, in which the
Shannon (or differential) entropy of the $\lambda$-distribution is always equal to
the von Neumann entropy of a corresponding mixed state, at least up to an
additive constant. 
\end{quote}
We are puzzled by this comment as we are literally proving that no such model exists. The order is broken: a greater von Neumann entropy may or may not correspond to a greater Shannon entropy. A real number is a type of order (one that is complete, dense, with no end-points and contains a countable dense subset). If ordering is broken, real numbers are broken.

Barrett comments:
\begin{quote}
This way, the quantum entropy actually would reflect the
classical ignorance about $\lambda$.
\end{quote}
Whether we can interpret the difference in entropy as a classical ignorance is debated in the paper:
\begin{quote}
Ideally, one would like to say that $E_{HS}$ represents all possible epistemic states that include the knowledge about preparation, while $E_{QM}$ represents only those distinguishable through measurement.
\end{quote}
And we argue that the breaking of the ordering is exactly why we cannot do that. Nonetheless, no comment is given on that argument.

Along the same lines---and quite surprisingly to us---no further comments are given on the rest of the paper, where the full conclusion is taken, the root of the problem is found in the different nature of quantum probability spaces, a technical definition of quantum contextuality is given, and it is shown how it cannot be expressed with a single classical (Kolmogorov) measure.

Barrett also mentions a technical remark concerning Shannon entropy:
\begin{quote}
in a sense it is infinite, but it would be better to say undefined. A proper treatment of entropies for distributions over continuous variables requires differential entropies.
\end{quote}

This gives us a chance to go more into the technical details of our work. In a measure theoretic sense, the measure is literally infinite, not undefined. The image of a measure is the extended real line, which means $\mathbb{R} \cup \{-\infty, +\infty\}$. The question of whether one uses the Shannon entropy or the differential entropy is exactly whether one uses a counting measure or the standard measure on $\mathbb{R}^n$. Very often, mathematical details are not important for physics, but in the present case this detail is crucial, and in fact it is the very mathematical detail which makes quantum mechanics, quantum probability and quantum information theory different with respect to their classical counterparts.

In classical measure theory, we need to choose a measure which defines how we ``count'' states in physics. We can choose the counting measure, so that the measure of a set, its size, is $\mu(U) = \#(U)$, where we basically just count the number of points. So, for each point $x$ we have $\mu(\{x\}) = 1$. Each point is associated with finite information, each point identifies one case. This measure is suitable for finite (or countable) cases (e.g. the number of faces on a die, the number of boxes a ball can be placed in). Naturally, any set with infinite points will have infinite measure (again, literally infinite) and therefore infinite entropy.

On a real line we can alternatively choose the Lebesgue measure. The measure is the size of the interval: $\mu([a, b]) = b-a$. In this case, finite intervals are associated with finite measure, but points will necessarily have zero measure. Finite intervals are associated with finite information, while points are associated with $-\infty$ information.

The point is: in classical measure theory you have to make a choice. If one chooses the Lebesgue measure, one has to use probability densities and the differential entropy. If one chooses the counting measure, one has to use ``proper'' probabilities and Shannon entropy. By using the theory of distributions, we can blur the lines by using things like the delta function to properly talk about finite probability on a point over a continuum, but the differential entropy of a delta Dirac is $-\infty$, consistent with the fact that a point has measure zero.

We ``hint'' at this technical imprecision in our footnote:
\begin{quote}
	We will follow the convention of not distinguishing between probability and probability density.
\end{quote}
We do believe this is bad, because it is hiding the actual problem. But such is the practice in our field, and so we adapt.

Now, quantum measure theory breaks all of this because both points and open regions have an entropy that would correspond to finite measure. That is, each pure state has zero entropy, which would correspond to measure one. A uniform distribution over the whole Bloch sphere has entropy of 1 which would correspond to measure $2^1 = 2$. Hence, a single point has only half the measure of a finite area, which has infinitely many points.

If we were to recover a measure corresponding to the sets over which we defined uniform distributions, the measure would not be additive. %Quite literally: $1+1\neq 2$. 
Quantum mechanics breaks measure theory, and it is easy to see that it must. Consider the following requirements:
\begin{enumerate}
	\item each state (point) has measure one
	\item each finite region has finite measure
	\item the measure is additive
\end{enumerate}
They are clearly incompatible since a finite region will have uncountably many points. The counting measure gets rid of requirement 2. The Lebesgue measure gets rid of requirement 1. Quantum mechanics gets rid of requirement 3. Classical probability can only be recovered in quantum mechanics over special subsets where the measure happens to be additive (i.e. orthogonal basis), though even in those cases, it is only finitely additive in general.

This also addresses the closing question:
\begin{quote}
But the problem then becomes,
how do we describe nature in a way that does not fit the schema of ontological
models?	
\end{quote}
We need to go back and redo the foundations of measure theory such that we can construct a generalized non-additive version of it, which allows both classical and quantum mechanics as special cases. This is, naturally, well outside the scope of the present article, which just wants to show that ontological models are not the way to do it.

We hope that our discussion addresses at least some of the most important technical questions raised by Barrett's comments. It is not clear to us exactly how to address them in the paper, as we feel the main criticism contained in his report did not touch the actual point of the paper (the breakdown of ordering between classical and quantum information entropy), and some of his questions are already addressed in the paper. We will look to the referee reports for guidance.
\vspace{5mm}

Sincerely,

The Authors

\end{document}