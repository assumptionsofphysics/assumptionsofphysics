\documentclass[11pt]{article}

\usepackage[margin=1.25in]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{dutchcal}
\usepackage{braket}
\usepackage{enumitem}

\usepackage{tikz}
\usepackage{forest}
\usetikzlibrary{trees}
\usetikzlibrary{calc}
\usepackage{calculator}
\usepackage{standalone}

\usepackage{braket}

\begin{document}

\title{Unitary evolution as a quasistatic process of infinitesimal collapses}

\maketitle

\begin{abstract}
Any state, to be properly defined, has to be an equilibrium of all processes happening at a faster timescale. As processes with equilibria are idempotent, they can be expressed as projections in a probability space. Assuming a quasistatic evolution, then, means the equilibria of the faster scale processes will evolve slowly, giving rise to continuous and unitary evolution. In this paper we show that these ideas are sufficient to get the general form of the projection postulate and the time evolution of quantum mechanics, while also creating a model that applies to other physical theories, such as classical mechanics and thermodynamics. In this light, the different theories are specializations of a broader model. As unitary evolution corresponds to quasistatic evolution, violations of the Schr\"{o}dinger equation, then, should be expected only for processes that cannot be considered quasistatic.
\end{abstract}

%\tableofcontents
%\newpage

\section{Introduction}

In an effort to better understand why the frameworks of classical and quantum mechanics are what they are, we have worked on identifying a minimal set of physical assumptions from which both can be derived.\cite{Carc1} This gave us a new perspective that is somewhat unusual among people who work on fundamental questions in physics. The typical view is that the theories are so different that they require a radically different set of starting points, and that classical mechanics in particular should only be viewed as an approximation of quantum mechanics. In this view, the similarities between the theories stem from one being an approximation of the other.

We believe a more encompassing view is to consider both classical and quantum mechanics as specializations of a simpler, more fundamental theory. This more fundamental theory would deal with states and laws of evolution as abstract objects, formalizing the \emph{necessary} conditions for them to be operationally defined such that they can be experimentally studied. The other physical theories (classical and quantum mechanics, thermodynamics and so on) would specialize those concepts to better define what states we are studying and under what conditions. In this view, the similarities between the theories are due to the general concepts of the more fundamental theory. This alternative approach can help us pinpoint the elements specific to each theory, clarify their realm of applicability and, hopefully, provide insights into where new physics may lie.

In this paper we outline the fundamental elements of a general model for a physical system, their relationships and, in particular, how they work in the context of quantum mechanics. The basic idea is that for a state to be experimentally prepared, manipulated and measured, it needs to be ``stable'' for what may be a very short but certainly finite amount of time. That is, it must be a, possibly metastable, equilibrium of faster scale processes. But a process for which all outputs are equilibria is idempotent (i.e. gives the same output no matter how many times it is applied) and is therefore mathematically modeled by a projection operation on the space of statistical distributions. We identify quantum projections as these processes.Quantum projections, then, should be considered in the same spirit as out-of-equilibrium thermodynamic processes: the dynamics is taken as a black box with no further characterization, there is only a clear initial and final state, and the process can, in general, increase entropy. Quantum states and projections are taken as prime notions in the same way that equilibrium is a prime notion in thermodynamics. If we want a deterministic law, then, it must be a quasistatic evolution in terms of those faster scale processes. As the change must be small, this leads to continuous evolution over the state space and unitary evolution in the space of statistical distributions. We identify unitary evolution as this deterministic law.

The necessity of states to be stable for a certain minimum timescale applies to all physical theories, and a deterministic law, then, can only be valid at \emph{coarser} time resolution within each theory. In other words, faster scale processes define the state space as their equilibria and the minimum scale $dt$ for the law of evolution. It will be instructive, then, to see how these concepts apply to classical mechanics and thermodynamics as well. This will illustrate how looking at the foundations of all physical theories, and not at quantum mechanics in isolation, fosters a better general understanding of fundamental concepts.

It should be noted that while the objective is to put together a general mathematical model that can fit not only quantum mechanics, but other physical theories as well, the model itself cannot be proven mathematically, in the same way that the axioms of set theory, or any other formal system, cannot be proven. Moreover the mathematical structure we want to impose is necessarily ``simple" because simpler structures are the more general ones (i.e. every mathematical object is an element of a set, the simplest structure). Therefore the bulk of the work is, appropriately, to present a physical justification as to why the simple mathematical structure we lay out is necessary.

In section 2 we will first take the basic framework of quantum mechanics and dress it in a slightly different language. The purpose is to make the interplay between pure states, statistical distributions of pure states, projections and unitary evolution clearer. In that context it will be easier to see how unitary evolution can be considered a quasistatic process of infinitesimally close projections. In section 3 we will see how the same mathematical structure can be justified from more general physical considerations and how it necessarily applies to all physical theories, including classical mechanics and thermodynamics. 

\section{From projections to unitary evolution}

In this section we will assume as given the state space of non-relativistic quantum mechanics and the rules for projections. We will then recover unitary evolution (i.e. the Schr\"{o}dinger equation) as the quasistatic deterministic evolution given by continuous projections. To do so, we will introduce a different mathematical notation which will make explicit the difference between pure states, statistical distributions and mixed states, to help dispel potential confusion. This notation will also prepare the stage for the next section, where we will see that the same mathematical framework applies to all scientific theories.

We start by having a set of pure states $\mathcal{S}$, which are typically represented in quantum mechanics as directions in a Hilbert space,\footnote{As long as one is able to define projections, other representations can be equivalently used.} so we will write $\psi \in \mathcal{S}$ meaning $\psi$ is a state for our system. The elements in $\mathcal{S}$ correspond to the possible configurations of a single instance of our system at a given time.

We then define the set of statistical ensembles $\mathcal{D}$, which represent the (classical) statistical distributions of multiple copies of our system independently prepared. Each element $\mathcal{d} \in \mathcal{D}$ can be represented as a normalized distribution $\mathcal{d}: \mathcal{S} \to \mathbb{R}$ where $\mathcal{d}(\psi)$ represents the probability to find an instance of the distribution in the state $\psi$. For example, if $\mathcal{d}(\psi) = \frac{1}{2}$ then $50\%$ of the times a system prepared according to the statistical ensemble $\mathcal{d}$ will be found in the state $\psi$. We can also have statistical ensembles prepared in such a way that all instances are prepared in the same pure state. We therefore define $\iota : \mathcal{S} \to \mathcal{D}$ as the function that returns a statistical ensemble where all instances are prepared in the same way: if $\mathcal{d}=\iota(\psi)$ then $\mathcal{d}(\phi)$ is equal to 1 if $\phi = \psi$ and is equal to 0 otherwise. Mathematically, $\iota$ is an injection of the pure states into the space of statistical distributions. The space $\mathcal{D}$ is a real vector space, as we can combine probability distributions through linear combinations, and the set $\iota(\mathcal{S})$ forms a basis of that space, as any distribution can be constructed from pure states.

Note that $\mathcal{S}$ and $\mathcal{D}$ are two different vector spaces, both mathematically and physically. Suppose we are studying a spin $1/2$ system. Let $z^+, z^- \in \mathcal{S}$ be the two states with spin aligned and anti-aligned with respect to the $z$ direction. We have:
\begin{equation}
\begin{aligned}
\ket{y^+} &= \frac{1}{\sqrt{2}} (\ket{z^+} + i \ket{z^-}) \\
\mathcal{d}&= \frac{1}{2} (\iota(z^+) + \iota(z^-))
\end{aligned}
\end{equation}
The first is a complex linear combination in $\mathcal{S}$ and represents a quantum superposition, which simply returns another pure state. In the example, it returns spin prepared in a different direction. The second is a real linear combination in $\mathcal{D}$ and represents a statistical mixture. In the example, it returns a statistical ensemble that is prepared half the time in one direction and half the time in the opposite direction. The first type of combination is specific to quantum states. The second type of combination applies to all statistical distributions.

In quantum mechanics, not all statistical ensembles are distinguishable from each other. For example, in the spin $1/2$ case, the distribution $\mathcal{d}_1$ defined as $\mathcal{d}_1(z^+)=\mathcal{d}_1(z^-)=\frac{1}{2}$ is physically equivalent to $\mathcal{d}_2$ defined as $\mathcal{d}_2(x^+)=\mathcal{d}_2(x^-)=\frac{1}{2}$. Therefore we define the set of mixed states $\mathcal{M}$ as the set of statistical ensembles that are physically different, which is usually represented by a density matrix. Mathematically, we can also represent physical equivalence between statistical ensembles with an equivalence operator $\mathcal{d}_1 \equiv \mathcal{d}_2$ and the set of mixed states $\mathcal{M} = \mathcal{D}_{/_\equiv}$ will be the quotient space.

We can now introduce the space of projections $\mathcal{P}$ as those processes $\mathcal{p} : \mathcal{D} \to \mathcal{D}$ that take a statistical ensemble and return another statistical ensemble according to the rules of projections in quantum mechanics. That is, given a Hermitian operator $O$ over $\mathcal{S}$, we find the set of eigenstates $\{\phi_i\} \subset \mathcal{S}$ for $O$ and we construct the projection $\mathcal{p}_O$ such that:
\begin{equation}\label{transition_probability}
\mathcal{p}_O(\iota(\psi))(\phi) = 
\begin{cases}
\frac{\braket{\psi | \phi} \braket{\phi|\psi}}{\braket{\psi|\psi}} &\quad\phi \in \{\phi_i\}\\
0 &\quad\phi \notin \{\phi_i\}\\
\end{cases}
\end{equation}
If we prepare a statistical ensemble $\iota(\psi)$, where all instances are in state $\psi$, and we subsequently apply the process $\mathcal{p}_O$, then we will find that we cannot be in a state that is not an eigenstate of $O$, and the probability of being in a particular eigenstate is given by the inner product. Since $\iota(\mathcal{S})$ is a basis for $\mathcal{D}$ and the projections are linear, each $\mathcal{p}_O$ is well defined over the whole $\mathcal{D}$.

All we presented so far are standard concepts in quantum mechanics re-expressed in a new notation which allows us to clarify an important detail: the processes $\mathcal{P}$ are defined on the statistical ensembles $\mathcal{D}$, not on the pure states $\mathcal{S}$. They are, in general, non-deterministic processes and therefore do not take a pure state to a single well-defined pure state. These processes are projections because they are:
\begin{description}
	\item [linear operations] the output for an ensemble is the same as an ensemble of the outputs for the elements, i.e. $\mathcal{p}(a_1\mathcal{d}_1 + a_2\mathcal{d}_2) = a_1\mathcal{p}(\mathcal{d}_1) + a_2\mathcal{p}(\mathcal{d}_2)$
	\item [idempotent] if applied twice return the same result, i.e. $\mathcal{p}(\mathcal{p}(\mathcal{d})) = \mathcal{p}(\mathcal{d})$
\end{description}
The linearity of these operations, then, is the one defined on statistical ensembles: it is the linearity of classical probability, not of superposition. The fact that these processes are idempotent simply means that, if we run the process again on the output, we get the same output. That is, all the outputs are equilibria. Mathematically, if $\psi$ is an eigenstate of $O$, it is an equilibrium for the process since $\mathcal{p}_O(\iota(\psi))=\iota(\psi)$. Every time we start with $\psi$ we always get $\psi$. Therefore, \textbf{we will take the projections to represent non-deterministic processes that always reach equilibria in a very small time $dt$, faster than our description allows}. Similarly to thermodynamics processes, we do not claim that a description in terms of our state space $\mathcal{S}$ is valid during that process, only that it is a valid description for the final equilibrium. 

Conversely, note that for any pure state $\psi \in \mathcal{S}$ we can find an appropriate Hermitian operator $O$ such that $\psi$ is an eigenstate of $O$ and therefore any pure state is an equilibrium of some process $\mathcal{p} \in \mathcal{P}$. That is, not only are the equilibria of every process in $\mathcal{P}$ elements of $\mathcal{S}$, but all elements of $\mathcal{S}$ are equilibria for at least one process in $\mathcal{P}$. \textbf{All states are equilibrium states of the projections}.

If we accept this premise, then the natural thing to do is to write the conditions for a quasistatic deterministic evolution. That is, we assume that at each moment the system is in equilibrium and we change the state just a little so that each pure state is mapped to a single well-defined pure state. That is, if $\psi_{t}$ and $\psi_{t+dt}$ are two states infinitesimally close in time and $\mathcal{p}_{t+dt}$ is the process that between $[t, t+dt]$ transitions one into the other, then every time $\psi_{t}$ is the input of that process $\psi_{t+dt}$ is its output. Mathematically:
\begin{equation}
\begin{aligned}
\mathcal{p}_{t+dt}(\iota(\psi_{t}))&=\iota(\psi_{t+dt}) \\
\end{aligned}
\end{equation}
Applying the definitions we find:
\begin{equation}
\begin{aligned}
\mathcal{p}_{t+dt}(\iota(\psi_{t}))(\psi_{t+dt}) &=
\frac{\braket{\psi_{t} | \psi_{t+dt}} \braket{\psi_{t+dt}|\psi_{t}}}{\braket{\psi_{t}|\psi_{t}}} = 1 \\
\end{aligned}
\end{equation}
This requires the evolution to be unitary and we can use standard techniques from here, which will lead to the Schr\"{o}dinger equation. In other words, \textbf{the Schr\"{o}dinger equation is the quasistatic deterministic evolution of a process of continuous projections}. This approach, therefore, proceeds in the opposite way of others: instead of assuming the Schr\"{o}dinger equation is always valid and deriving projections as a special case, we assume projections are valid approximations of faster scale processes and the Schr\"{o}dinger equation is the special quasistatic deterministic case.

We can briefly see why this approach makes intuitive sense. The closer two states are in the Hilbert space, the greater the chance that one will transition to the other during a projection. Continuous evolution, then, means small deterministic changes. Unitary evolution, in particular, conserves entropy, which is also the hallmark of deterministic and reversible evolution. On the other hand, a projection can increase entropy, which is the hallmark of a transition that went out of equilibrium and is not reversible. Since any two unitary vectors can be connected by a unitary operation (i.e.~a rotation), it makes sense that all states are equilibria since they can all be connected by a deterministic and reversible process and that they all carry the same entropy. We also note that in quantum field theory, to calculate cross-sections and particle decays, one puts the initial states at minus infinity and the final states at plus infinity for processes that, in reality, take a tiny fraction of a second. This is reminiscent of a quasistatic approximation.

Finally, we note that the approach presented here does not solve the so called ``measurement problem''\cite{Genovese,Bassi}, at least not in the way it is typically framed. We still do not have a description of what happens during an arbitrary process (e.g. a projection), yet we have an explanation of why we cannot provide one in terms of a quasistatic evolution (i.e. unitary evolution) since a special case cannot describe the general one.\footnote{We purposely leave unspecified whether the faster scale processes are driven by internal or external dynamics, or by a mixture of the two. As such, this approach does not technically pick an interpretation: it merely states that whatever happens during a measurement in a given interpretation is also happening at every instant in time.}

\section{States and processes}

The next question, then, is whether what we saw in the previous section is an actual model for physical reality. We will, once again, proceed in a different way than usual. Instead of justifying the mathematical structure for quantum mechanics in particular, we will show that a very similar mathematical structure exists when studying other systems. That is, instead of proceeding from what is reasonable in a particular set of circumstances, we proceed from what is necessary in general and find a conceptual and mathematical framework that is similar to the one already discussed.

In any physical theory, first one needs to define what is the object under study. We typically call that object \emph{system} and \emph{environment} everything else. Depending on the case, our system may be the solar system, a rocket, a ball, a region of the atmosphere, a misture of gas within a can, a handful of molecules or an electron. We call \emph{state} a particular configuration of that system at a particular time and define $\mathcal{S}$ as the set of all possible configurations.

It should be fairly clear that the state space will depend upon the choice of system. What may be less clear is that it also depends on context. For example, if we are studying the motion of a balloon, position and momentum may be enough to identify a state. If, instead, we want to study how the balloon expands or contracts we may need temperature and pressure. \textbf{The same system allows different choices for state, which are contingent upon what properties and situations we choose to study.} 

Ultimately, what we want is a set of measurable properties $\xi^a : \mathcal{S} \to \mathbb{R}$ that uniquely identify a state, and a law of evolution $\mathcal{E} : \mathcal{S} \times \mathbb{R} \to \mathcal{S}$ such that given a state at one time and a time increment we can predict the state at the future time. For example, if we are studying the motion of a ball the effect of the air bumping chaotically on the surface can be disregarded and therefore position and velocity of the center of mass will suffice. If we are studying the motion of a speck of dust, the air collisions cannot be disregarded and therefore we use a statistical ensemble as the state and, given the initial probability distribution, we predict the final probability distribution.\footnote{In this case, the measurable properties that identify the state become the probabilities associated to each case.} But if we study the speck of dust in a vacuum, then we can go back to just position and momentum. That is, \textbf{states and deterministic laws are defined interdependently}. Within a given situation we define states in a particular way because we have a law they obey, and we write the law in a particular way because we have states that obey it.

States and deterministic laws, then, are indeed objective concepts but they are not absolute ones. While it is a matter of fact that those particular properties of that particular system under those circumstances are enough to predict their future values, it is up to us to choose the system, the circumstances and the variables that constitute an appropriate combination. Therefore, when discussing state definition, we must be cognizant of that choice or we may unknowingly misconstrue the meaning of our theories. We may believe some results to be features of the system studied while in fact they may be direct consequences of our trying to find states we can manipulate and for which we can write deterministic laws. This is akin to a fisherman noting that there is a minimum size to the fish in the sea, not realizing it is precisely the size of the mesh of his net.

With this is mind, let us explore the following question: could we, in principle, extend the state to exhaust the description of the system? As we saw, that would mean finding a set of circumstances in which the evolution of the entirety of the system is fully determined by the system itself. That is, no part of the system is influenced by the environment in any way. Under those conditions, no interactions with the system are possible. Photons cannot interact with it, nor gravitational waves; no way to synchronize clocks between the system and the environment, no way to tell where the system is with respect to the environment. To us in the environment, within those circumstances, the system has vanished. How, then, are we supposed to study it? How are we supposed to experimentally define the properties in those conditions? How are we supposed to validate the law of evolution?

This tells us that there is a tension. On one side we can only say that something is a property of the system if it is defined independently of the environment. On the other side, we cannot completely turn off system-environment interaction or there would be no way to operationally define the property. This means that we can never have a complete independent description of the system.\footnote{Ultimately, this is why classical mechanics conceptually fails. See \cite{Carc1} for more discussion.} We need to leave out some ``unstated part'' whose future will depend on the environment. In other words, \textbf{the system always has a boundary with the environment and, through it, is in constant interaction}.

This unavoidable interaction with the environment comes into play in the definition of a system and its state. For example, we can talk about the position of a ball because we sit on the surface of the earth at around 273 K. If we were on the surface of the sun at around 5778 K, after a short time, we would not be able to talk about a ball. A state and its properties only exist because the system is in some kind of equilibrium with the environment. Therefore even if the unstated part is not part of the state, its interaction with the environment has to be ``suitable'' for the state to be defined in the first place. In other words, \textbf{a physical property of a system is well defined and measurable if and only if the constant interaction with the environment keeps it that way.}\footnote{A possible misconception is thinking that a process that does not change our state is ``doing nothing''.}

Let us define $\mathcal{P}$ as the set of all system-environment interactions. While we cannot characterize their effect on the unstated part, we should characterize their relationship to the state space $\mathcal{S}$. These processes may act on the states non-deterministically since they depend in general on the configuration of the environment. So we define $\mathcal{D}$ as the set of all statistical ensembles over $\mathcal{S}$ and each process $\mathcal{p} \in \mathcal{P}$ is a map $\mathcal{p} : \mathcal{D} \to \mathcal{D}$ that takes a statistical ensemble to another statistical ensemble. Given a state $\mathcal{s} \in \mathcal{S}$ we must find at least one set of circumstances in which it is in equilibrium with the environment for a finite amount of time. That is, if we prepare an ensemble $\iota(\mathcal{s})$ that is made of identically prepared copies of $\mathcal{s}$, we have a process $\mathcal{p} \in \mathcal{P}$ such that $\mathcal{p}(\iota(\mathcal{s})) = \iota(\mathcal{s})$.

Every process that has equilibria is characterized by a time scale needed to reach equilibrium. That time will set the maximum time resolution we can use with that choice of states and processes. To go to faster time scales we inevitably need to change both states and processes. For example, as we change the volume of a gas, the region against the moving wall will be compressed sooner than the opposite region, but if we wait a short while we will again obtain a uniform pressure. If we want to study that transition, we may conceptually divide the system into small volumes and we replace the pressure by a pressure field. Still, we need to assume each small volume has enough molecules to be in equilibrium. We can go into more detail, and describe the distribution of position and velocity of the molecules. Yet, we need to assume that the molecules themselves are not undergoing chemical changes. We could study the atoms of the molecules, yet we would have to assume that the atoms are stable under nuclear fission. We could study the electrons and nucleons of the atoms, yet we would have to assume they are stable under weak nuclear forces.\footnote{This hierarchy of time scales is indeed used in many areas of science and engineering under the practice of multiscale modeling. \cite{Horstemeyer,Weinan} It allows one to break down a complex problem so that the relevant dynamics is studied efficiently at the right level of scale, gaining more insight and leading to faster calculations. Each scale will use different models and techniques, such as continuum mechanics, Monte-Carlo methods for statistical physics, molecular mechanics, quantum chemistry and so on. \cite{Brandt} During a computation cycle, each level of scale treats the faster and slower dynamics as fixed parameters, which are updated appropriately for the following iteration.} As we move to a finer and finer description, we have faster and faster scale processes that we assume do not change the basic constituents. At each level of the description what is assumed to be in equilibrium changes and what the laws describe changes as well. Yet, the overall structure remains the same: we have a timescale $dt$ such that within each interval $[t-dt, t]$ there is a process $\mathcal{p}_t$ such that the state $\mathcal{s}_t$ is an equilibrium of $\mathcal{p}_t$. The evolution $\mathcal{E}$, then, is quasistatic in terms of the processes in $\mathcal{P}$. That is, \textbf{all deterministic laws are quasistatic evolutions in terms of system-environment interaction processes}.

We have reached, then, the second major point of this article: \textbf{the mathematical structure we used to rearrange quantum mechanics is a general structure that applies to all systems} and as such we call it the \emph{fundamental model of physics}. It is fundamental because it always applies and what changes case by case are the specifics. In all cases we are going to have a set of states that are equilibria of faster scale processes. Each faster scale process will be, in general, non-deterministic in terms of the state and will act on the space of probability distributions. The law of evolution will be a quasistatic process in terms of the faster scale processes.

In classical mechanics, the state of a ball will be given by the position and momentum of the center of mass, which will be defined over a short time scale by integrating the jiggling created by the random collisions of air particles and internal motion of the ball's molecules. That averaging process will be the same regardless of the values of position and momentum; all states are equilibria of the same process and therefore $\mathcal{P}$ contains only one element: the identity map. Therefore, while the overall structure still exists, it is mathematically trivial and can be effectively disregarded as we concentrate on the law of evolution exclusively.

In thermodynamics, instead, processes and equilibria play a critical role. The study of the boundary between system and environment becomes the main focus. In this framework, choosing an isolated fixed wall means we picked the process $\mathcal{p}_{U,V} \in \mathcal{P}$ that guarantees the equilibrium to have a fixed energy and volume. The equilibrium state $\mathcal{s} \in \mathcal{S}$ will be associated to other quantities, like pressure, temperature and entropy, that are only defined on the equilibrium state itself. Work and heat are associated with the process, not the state, and that is why, in general, they are not calculable. State evolution occurs because we change the constraints or work parameters, for example we change volume at equal pressure. That is, at each time step we slowly change either the state or the process and let the system reach a new equilibrium.

In quantum mechanics we have elements of both. Like in classical mechanics we have a state space and a law of evolution, given by the choice of a Hamiltonian, that is deterministic and reversible. Like in thermodynamics, we have states that are equilibria of non-deterministic processes, of which we are not able to give a more fundamental description. Quantities are only well defined at equilibrium and the law of evolution is the quasistatic evolution where we assume the system changes slowly and we are always at equilibrium. What is interesting is that \textbf{in quantum mechanics what drives the deterministic evolution are the same processes that drive the equilibrium}.

In this framework, then, the processes in $\mathcal{P}$ do not represent measurements, they simply represent transitions to a new equilibrium. In thermodynamics they may represent the crystallization of a supersaturated solution or the ignition of a mixture of oxygen and hydrogen to form water. In quantum mechanics they may represent the absorption of an incoming photon by a hydrogen atom or the decay of a muon into an electron and two neutrinos. In all these cases we start from a state of (possibly metastable) equilibrium and we end with a new equilibrium which is not, in general, described in terms of the initial state space. For example, water vapor is not a mixture of hydrogen and oxygen gases and a muon is not a collection of three particles. That is, in general the system passes through configurations that are not suitably described by the initial or final state space. We do not believe the similar conceptual structure to be simply a formal analogy but to represent analogue physical mechanisms. Quantum projections happen for the same reasons supersaturated solutions crystallize: a change in external or internal physical conditions that leads to a new equilibrium.

Why, then, are measurements in quantum mechanics typically associated with projections? Let us think of what a particle detector has to do: it has to take the very small signal of a particle coming through and amplify it to a macroscopic level. In the case the particle itself is absorbed, or destroyed in any way, then we are already in the realm of fast processes. In the other cases, the particle has to initiate a chain reaction that has to transfer energy stored in the detector system to the readout. The detector, then, has to be prepared in a state sufficiently stable to not change if no particle interacts with it but unstable enough that a small perturbation makes it transition to a lower energy. That is, the detector has to be prepared in a metastable state and the particle interaction has to make it transition to a more stable state. But a transition from a metastable state to a more stable state is exactly what our projections are supposed to represent.\footnote{The role of metastability in detectors has already been discussed, for example, by \cite{Daneri} and \cite{Merlin}.}

On the other hand, not all measurements are projections. In a weak measurement\cite{Tamir}, for example, the system interacts with the probe according to unitary evolution (i.e. adiabatically) and the probe itself goes through the projection. So the association of a measurement with a projection will not always work, while a process with equilibria can always be mathematically formalized as a projection.

We can sum up this section in the following points:
\begin{itemize}
	\item the mathematical structure of quantum mechanics (i.e. projections and law of evolution) is the natural structure that all physical theories have
	\item projections represent processes with equilibria that happen at a faster scale 
	\item measurements are simply physical processes
\end{itemize}
The advantage of this perspective is that no ad-hoc concepts are needed. In future works we will further characterize this model providing even more constraints to physical theories, which may clarify which other elements of processes and laws are basic requirements and which are particular to classical or quantum mechanics.

\section{Conclusion}

We have seen that quantum mechanics fits within a more general framework that applies to all physical theories. States are always equilibria of faster scale processes, which in quantum mechanics are modeled with the projection. States are chosen to satisfy a deterministic law of evolution, necessarily describing a quasistatic process, which in quantum mechanics is modeled by the Schr\"{o}dinger equation. This general framework only uses standard physics concepts and puts no special role on the observer except the choice of what processes the system will be subjected to.

Violations of the Schr\"{o}dinger equation should be expected only for processes that cannot be considered quasistatic. If we were to implement a measurement process, then, in a way that the transfer of information between the system and the probe happens in a slow and controlled fashion, this could not provide a violation of the Schr\"{o}dinger equation, nor would it tell us that all projections are quasistatic processes. On the other hand, a better description of the faster scale processes given by the projections cannot be given in terms of unitary evolution, as this represents the quasistatic case. It would inevitably require a new state space as the standard quantum states can only describe equilibria of those processes. Moreover, a description at Planck time scale will ultimately fail to be continuous and quasistatic since a finite change in a finite time will not be divisible into infinitesimal adiabatic changes over infinitely many time steps.

To understand the suitable mathematical framework for those regimes where unitary evolution may not hold, we are proceeding by first identifying the physical requirements for all mathematical structures already used in physics, starting from the most basic ones like topological spaces (upon which is based all of differential geometry) and $\sigma$-algebras (upon which is based all of measure theory and probability theory). This long term effort is centered mainly around the development of an open access book\cite{Carc3} in which these issues can be explored in full detail and with a rigor more typical of mathematical disciplines. This rigor forces us to spell out the often hidden assumptions we have while constructing physical theories. By making explicit, for example, under which physically motivated circumstances time can be modeled by real numbers, or when states can be represented within Hilbert spaces, we believe we will be in a better position to understand what happens when those assumptions fail.

%\section{???}

%If we accept the line of thinking present in the previous two sections, we can try and draw some conclusions. These will be necessary qualitative as much further work would be needed to make any quantitative prediction.

%The first main conclusion is that we should be able to find processes that are neither described by unitary evolution nor by the projection. These would correspond to processes for which the out-of-equilibrium dynamics becomes relevant so the quasistatic evolution is not a good approximation and neither is the instantaneous transition. Even if we do not have a theory for those regimes, we can, at least conceptually, discuss a couple of general strategies.

%For example, we can note that slow changing conditions are unlikely to reveal new dynamics. As long as the system evolves continuously, the quasistatic approximation will hold. It is also conceivable that, in some conditions, a process that may look like a projection end-to-end is actually well described by a slow transition. In those cases the quasistatic approximation evidently holds and no new phenomena would be observed. What is the right time scale, though, is not clear to us since ``slow'' in this setting is still ``very fast''.

%The main issue is that we have to catch the system out of equilibrium. In principle, we can imagine preparing a state $\mathcal{s}_0$, starting a process $\mathcal{p}_1$ and, while in transition, switch to process $\mathcal{p}_2$. At that point, the final state may have characteristics that are different from having run the two process sequentially and that would be evidence of new physics. Hypothetically, this may correspond to having an atom absorb a photon while it was already in the process of emitting one. Or it may correspond to polarizing a particle horizontally while it was in the process of polarizing vertically. Whether anything along these lines is actually practicable is unclear, but it's one general strategy.

%Another one would be to find a process that under some conditions is well described by unitary evolution while in others by a projection. We may find that at the boundary of the transition the process will be described by neither. This may correspond, for example, to those cases where an energy threshold has to be passed to see particle productions or particle absorption. It is not clear what kind of precision would be required to elicit a different response, but it's general strategy. 

%The second main conclusion is that to get a more fundamental theory we have to change the state space. As quantum states only characterize the equilibria for the projections, we need a different state space for the out-of-equilibrium states. This suggests that developing the right physical model for what happens during a projection is not a simple matter of finding a suitable Hamiltonian or a non-linear law of evolution. We may have to substitute complex Hilbert spaces with something else. Given that we don't even have consensus on why those spaces are needed in the first place, and on whether all the objects in those spaces are actually physical, it is unclear what we would substitute them with.

%We may think we can use our intuition to guide us but it is more likely that it will lead us astray. Our ideas of conserved charges, symmetries, quantum numbers and the like may not apply in those out-of-equilibrium states. As we know that, during those processes, particles can transform from one type to another, it would make sense to assume they are all made of the same substance and that particles are more or less stable configurations of that substance. If that is the case, mass, charge and other quantum numbers may simply be the properties of those stable configurations that have no meaning in between, much like pressure or temperature for an out-of-equilibrium volume of gas. Even the symmetries would be qualifying the homogeneity of the equilibrium states.

%Unfortunately, it is probably worse than that. Suppose we want a theory that works at the smallest time resolution, at Planck scale. Then our set of processes $\mathcal{P}$ would correspond to those processes bounded by that time scale. Those will correspond to the basic building blocks with no further refinement possible. If we now want the law of evolution $\mathcal{E}$ as well, the time scale of $\mathcal{E}$ will be the time scale of the processes $\mathcal{P}$: we cannot see time evolution $\mathcal{E}$ as a continuous sequence of processes $\mathcal{p}_t$. As we can no longer pretend that between two fast time scale processes there is always another one, we now must face the fact that these may be running in different regions that may or may not overlap in space and time. That is, the execution of there processes is not strictly sequential and therefore not linearly ordered, in which case time cannot be modeled by a number.

%If Hilbert spaces are not suitable to characterize states, or if real and rational numbers are not suitable to characterize time, it would mean that we may be very very far from even having the correct mathematical tools to be able to characterize those regimes. 




\begin{thebibliography}{999}
	\bibitem[Carcassi(2018)]{Carc1}
	G. Carcassi, C. A. Aidala, D. J. Baker, L. Bieri; From physical assumptions to classical and quantum {Hamiltonian} and {Lagrangian} particle mechanics. {\em J. Phys. Comm.} {\bf 2018}, {\em 2(4)}, 045026.
	
	\bibitem[Genovese(2010)]{Genovese}
	M. Genovese; Interpretations of quantum mechanics and measurement problem. {\em Adv. Sci. Lett.} {\bf 2010}, {\em 3}, 249--258.
	
	\bibitem[Bassi(2013)]{Bassi}
	A. Bassi, K. Lochan, S. Satin, T. P. Singh, and H. Ulbricht; Models of wave-function collapse, underlying theories, and experimental tests. {\em Rev. Mod. Phys.} {\bf 2013}, {\em 85}, 471.
	
	\bibitem[Weinan(2011)]{Weinan}
	E. Weinan; Principles of Multiscale Modeling. {\em Princeton University} {\bf 2011}.
	
	\bibitem[Horstemeyer(2009)]{Horstemeyer}
	M. F. Horstemeyer; Multiscale Modeling: A Review. In Leszczyński, Jerzy; Shukla, Manoj K. (eds.). Practical Aspects of Computational Chemistry: Methods, Concepts and Applications. pp. 87–135. ISBN 978-90-481-2687-3.
	
	\bibitem[Brandt(2002)]{Brandt}
	Brandt A. (2002) Multiscale Scientific Computation: Review 2001. In: Barth T.J., Chan T., Haimes R. (eds) Multiscale and Multiresolution Methods. Lecture Notes in Computational Science and Engineering, vol 20. Springer, Berlin, Heidelberg
	
	\bibitem[Daneri(1966)]{Daneri}
	A. Daneri, A. Loinger and G. M. Prosperi; Further remarks on the relations between statistical mechanics and quantum theory of measurement. {\em Nuovo Cimento B} {\bf 1966}, {\em 44}, 119--128.
	
	\bibitem[Merlin(2015)]{Merlin}
	R. Merlin; A Heuristic Approach to the Quantum Measurement Problem: How to Distinguish Particle Detectors from Ordinary Objects. {\em Int. J. Mod. Phys. B} {\bf 2015}, {\em 29(22)}.
	
	\bibitem[Tamir(2013)]{Tamir}
	B, Tamir, E. Cohen; Introduction to Weak Measurements and Weak Values. {\em Quanta} {\bf 2013}, {\em 2}, 7–17.
	
	\bibitem[Carcassi(2019)]{Carc3}
	G. Carcassi, C. A. Aidala; Assumptions of Physics. {\em In preparation} {\bf 2019}, http://assumptionsofphysics/book.
	
\end{thebibliography}

\end{document}
