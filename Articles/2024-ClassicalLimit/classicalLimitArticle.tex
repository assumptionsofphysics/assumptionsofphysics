\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{assumptionsofphysics}
\usepackage{tikz-cd}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{pgfplots}
\def\>{\rangle}
\def\<{\langle}


\title{Classical mechanics as high entropy limit}
\author{Gabriele Carcassi, Manuele Landini, Christine A. Aidala}

\begin{document}
\maketitle

\begin{abstract}
We show that classical mechanics can be recovered as the high entropy limit of quantum mechanics. The idea is that the high entropy hides quantum effects, and mixed states of high enough entropy can be approximated with classical distributions. The mathematical limit $\hbar \to 0$ can be reinterpreted as setting the zero entropy of pure states to $-\infty$, in the same way that non-relativistic mechanics can be recovered mathematically with $c \to \infty$. Physically, these limits are more appropriately defined as $S \gg 0$ and $v \ll c$. Both limits can then be understood as approximations independently of what mechanism allows those approximations to be valid. Consequently, the limit presented is independent of what interpretation is chosen for both quantum states and entropy. 
\end{abstract}

\section{Introduction}

%TODO: Status. Probably two ways: one mathematical (hbar to zero) and multiple mechanism (what happens that makes things loook classical) like decoherence and other things

%TODO: Our aim is to recover the mathematical limit for general physical ideas, in a way that is independent of mechanism and interpretation.

%TODO: give brief overview

\section{High entropy and classical states}

As mentioned in the introduction, we believe that classical mechanics should be recovered from quantum mechanics in a way that makes intuitive sense to all those that routinely work with quantum systems. Therefore, let us start with a few qualitative considerations that hint at the connection between classical mechanics and high entropy.

\subsection{Producing quantum states}

TODO: qui sarebbe bello mettere un sacco di esempi/citazioni

One of the experimental challenges in quantum mechanics is producing states that are ``quantum enough'' to exhibit quantum properties. What we want to show that all these problems can ultimately be understood as reducing the entropy of the initial state.

Coherence is probably one of the direct and most important properties. It has been shown that coherence can be maintained over long distances and among large number of constituents, meaning that quantum systems are not necessarily small or made of few components. However, it is also established how coherence can be quickly lost through interaction with the environment, trough decoherence. Since decoherence does increase the entropy on the system, it represents one mechanism to reach the high entropy limit. This is in line with our result.

In experimental practice, many quantum effects (e.g.~superconductivity, topological insulators, quantum hall effect, ...) are harder or impossible to achieve at high temperature. The thermal noise can in fact break the coherence of the system. Note that entropy is a monotonic function of temperature, meaning that decreasing temperature does mean decreasing entropy of the system. This is in line with our result.

Some quantum effects can be replicated at higher temperature given a high pressure. This is the case, for example, in some superconductive materials. High pressure corresponds to low entropy, which is in line with our result.

To produce Bose-Einstein condensates, one needs a high density in phase space, which means both low entropy (to decrease the position spread) and low temperature (to decrease the momentum spread). This, again, is in line with our result.
{\color{blue} Something of interest: For a trapped condensate, the PSD at the center and S are related by $PSD=e^{5/2+\gamma-S/N}$, where $\gamma$ is the virial coefficient for the trapping potential (Pinske et al Phys.Rev.Lett. 78, 990 (1997)). This has been used experimentally to condense at constant entropy, by changing the shape of the potential (D. M. Stamper-Kurn, Phys. Rev. Lett. 81, 2194 (1998))}

\subsection{Uncertainty from entropy}

Another hint of the link between high entropy and classical mechanics comes from the relationship between entropy and uncertainty.

In both classical and quantum mechanics, Gaussian states maximize entropy at a fixed uncertainty or, equivalently, minimize uncertainty at fixed entropy. This means that, if we fix the entropy $S$, we will have an uncertainty relationship
\begin{equation}
    \Delta x \Delta p \geq \Sigma(S).
\end{equation}
The specific value of $\Sigma$ will depend on the entropy and on whether we are using classical or quantum mechanics, though the relationship will always be saturated by Gaussian states with no correlation between $x$ and $p$.

In classical mechanics, the relationship between entropy and uncertainty for Gaussian states is\cite{Cover_Thomas_2006,Pathria_Beale_2022}
\begin{equation}
    S_C(\Sigma) = \ln \left(2 \pi e \frac{\Sigma}{h}\right) = \ln \left(\frac{\Sigma}{\hbar}\right) + 1.
\end{equation}
In quantum mechanics it is\cite{weedbrook2012gaussian}
\begin{equation}
S_Q(\Sigma) = \left( \frac{\Sigma}{\hbar} + \frac{1}{2} \right) \ln \left( \frac{\Sigma}{\hbar} + \frac{1}{2} \right) - \left( \frac{\Sigma}{\hbar} - \frac{1}{2} \right) \ln \left( \frac{\Sigma}{\hbar} - \frac{1}{2} \right).
\end{equation}

\begin{figure}
    \centering
\begin{tikzpicture}
\begin{axis}[
height=7cm,
width=\linewidth*0.8,
grid=both,
grid style={line width=.1pt, draw=gray!25},
axis lines=middle,
xlabel = \(\Sigma\),
ylabel = \(S\),
legend style={at={(0.95,0.65)},anchor=east},
]
\addplot[blue,samples=150,domain=0.1:8.5] {ln(x)+1};
\addlegendentry{\(\text{classical}\)}
\addplot[red,samples=150,domain=0.5:8.5] {(x+1/2)*ln(x+1/2)-(x-1/2)*ln(x-1/2)};
\addlegendentry{\(\text{quantum}\)}
\addplot[green,samples=150,domain=0.5:8.5] {(ln(x)+1) -((x+1/2)*ln(x+1/2)-(x-1/2)*ln(x-1/2))};
\addlegendentry{\(\text{difference}\)}
\end{axis}
\end{tikzpicture}
    \caption{Entropy $S$ in nats as a function of uncertainty $\Sigma$ in units of $\hbar$. Uncertainty is measured in units of $\hbar$. In blue, the classical case $\ln(\Sigma) + 1$. In red, the quantum case $\left( \Sigma + \frac{1}{2} \right) \ln \left( \Sigma + \frac{1}{2} \right) - \left( \Sigma - \frac{1}{2} \right) \ln \left( \Sigma - \frac{1}{2} \right)$. In green the difference betwen the two.}
    \label{fig:uncertainty}
\end{figure}

In figure \ref{fig:uncertainty} we can see that the classical and quantum cases are very close when the uncertainty is even just a few units of $\hbar$. Things diverge at about two units of $\hbar$: in quantum mechanics the entropy decreases faster and reaches zero at $\hbar/2$, the bound for the Heisenberg uncertainty principle; classical mechanics reaches zero entropy for $\hbar/e$, and then continues in the negative region.

Note that negative entropy is problematic. It directly contradicts the third law of thermodynamics, but we can see other, less axiomatic, problems. Given that entropy is additive under composition of independent systems, in the negative region the entropy decreases as the number of particles increases. This means that, at low temperature, zero particles give the highest entropy. This is one problem with classical theory that is corrected by quantum mechanics.

Studying the relationship between uncertainty and entropy, then, reinforces the idea that quantum mechanics is required at low entropy much like relativity is required at high speeds.

\subsection{Entropic aliasing}

Note that, in our approach, the mechanism that increases the entropy is irrelevant: any will do. The intrinsic geometry of quantum mixed states makes uncertainty over classical or quantum properties look the same. It is this aliasing of different preparations that drives the classical limit, as we can see even in a standard two slit experiment setup. 

In the simplest case, we can imagine the particle either passing through the left or right slit, which corresponds to the two pure states $|L\>$ and $|R\>$. These identify a two-state system, a qubit. We can now imagine equal superpositions of the two states, $\frac{1}{2}|L\> + \frac{1}{2} e^{-\imath \theta} |R\>$ where $\theta$ is the difference in phase between the two components. If $\theta$ is zero, we have the state $|+\> = \frac{1}{2}|L\> + \frac{1}{2} |R\>$ and the resulting interference pattern will have a peak in the middle of the screen. If $\theta$ is $\pi$, we have the state $|-\> = \frac{1}{2}|L\> + e^{-\imath \pi}\frac{1}{2} |R\>$ and the resulting interference pattern will have a valley in the middle of the screen.

As expected, $|+\>$ cannot be understood as a probability distribution, as a mixture, over $|L\>$ and $|R\>$. The interference pattern, the quantum feature, cannot be understood as a classical distribution over a path, a classical feature. However, an equal mixture of $|+\>$ and $|-\>$ is the maximally mixed state, which is equal to an equal mixture of $|L\>$ and $|R\>$. That is, the case where we randomize the phase is indistinguishable from the case where we randomize the path. In other words, uncertainty over a quantum feature behaves like uncertainty over a classical feature, regardless of the source of the uncertainty.

In the Bloch ball, states at equal entropy form a series of concentric spheres. As we increase the entropy, the points of these spheres become closer and closer, and therefore the error in using a mixture of $|L\>$ and $|R\>$ instead of the actual state becomes smaller. The same happens for the space of mixtures of any quantum system.

Mathematically, the trace distance $T(\rho,\sigma)$ between two mixed states $\rho$ and $\sigma$ will decrease under a completely positive trace-preserving (CPTP) map $M$ that increases the entropy of all states. That is, $T(M(\rho),M(\sigma)) < T(\rho,\sigma)$.\footnote{TODO Man: citation needed} If we call $\mathcal{G}$ the space of all mixtures of Gaussian states, given an arbitrary mixed state $\rho$, we will find a Gaussian state $\sigma_{\rho} \in \mathcal{G}$ that is closest to $\rho$. As the entropy of $\rho$ increases, $\sigma_{\rho}$ will be get closer to $\rho$.

What we described here is just a geometric property of the space of quantum mixed states, and it is independent on the source of entropy.

\section{Reinterpreting traditional approaches}

As mentioned, one of advantages of our approach is that it is compatible with more traditional approaches, including taking the limit $\hbar \to 0$. What one finds is that the math can typically be reinterpreted by taking an equivalent more physically meaningful limit.

For example, following the original paper from Wigner \cite{WignerLimit}, we can consider the Wigner distribution of a system in thermal equilibrium at inverse temperature $\beta$:\footnote{TODO Man: there seem to be some difference from the original paper}
\begin{equation}
    W(x,p)=\int dy e^{i(x+y)p/\hbar}\langle x+y |e^{-\beta\hat{H}}|x-y \rangle e^{-i(x-y)p/\hbar}
\end{equation}
Thermal equilibrium is described by $\hat{\rho}=e^{-\beta \hat{H}}$, which is the mixed state that maximizes entropy at a given average energy. The entropy of this state is directly connected to the value of $\beta$ such that when $S$ tends to $\infty$, $\beta$ tends to 0.
From this, Wigner considers the transformed Hamiltonian
\begin{equation}
    \tilde{H}=e^{i x p/\hbar}\hat{H} e^{-i x p/\hbar}=\frac{(p+i\hbar\partial/\partial x)^2}{2m}+V(x)=\epsilon(x,p)+i\frac{\hbar p}{m}\frac{\partial}{\partial x}-\frac{\hbar^2}{2m}\frac{\partial^2}{\partial x^2}
\end{equation}
where $\epsilon(x,p)$ is the classical Hamiltonian. The extra term contains the quantum corrections; we will refer to it as $Q(\partial/\partial x)$.\footnote{TODO Man: Q vs Q hat} The Wigner function becomes
\begin{equation}
    W(x,p)=\int dy \langle x+y |e^{-\beta\tilde{H}}|x-y \rangle 
\end{equation}
At this point, Wigner expands this expression in powers of $\hbar$, showing that quantum corrections are at second order. What we can do is instead expand in powers of $\beta$. We can show that quantum corrections are also only found at second order in $\beta$, justifying the classical limit. Let's start by considering the first order expansion, $e^{-\beta\tilde{H}}\simeq 1-\beta(\epsilon+\hat{Q})$. So at first order
we get
\begin{equation}
    W(x,p)\simeq 1-\beta \epsilon(x,p)-\beta\int dy\langle x+y |\hat{Q}|x-y \rangle.
\end{equation}
Focusing on the last term, we can insert a completeness (?) in the momentum eigenbase
\begin{equation}
  \int dy\langle x+y |\hat{Q}|x-y \rangle=\int\int dkdy e^{i2ky} \left(-\frac{\hbar p}{m}k+\frac{\hbar^2}{2m}k^2\right)=\int dk \delta(2k) \left(-\frac{\hbar p}{m}k+\frac{\hbar^2}{2m}k^2\right)=0.
\end{equation}
The first order quantum correction vanishes, showing that the classical approximation is correct to first order in $\beta$, which corresponds to the limit of large entropy. We can consider the second order correction
\begin{equation}
     W(x,p)\simeq 1-\beta \epsilon(x,p)-\beta^2\epsilon^2(x,p)-\beta^2\int dy\langle x+y |\hat{Q}V(\hat{x})+V(\hat{x}) \hat{Q}|x-y \rangle,
\end{equation}
giving the first nonzero quantum correction to the Wigner function.

\section{The high entropy limit}

We are now going to develop the limit in its most general formulation. TODO reword. Since the maximum entropy attainable by a quantum system is the logarithm of the dimension of the corresponding Hilbert space, the high entropy limit exists only for infinite-dimensional spaces.\footnote{TODO Man: add reference} This explains why spin, which lives in a finite-dimensional space, is an intrinsically quantum property. Therefore we are going to concentrate on the case of a single degree of freedom identified by position and momentum. The case of multiple degrees of freedom can be recovered by increasing the entropy of all DOFs at the same time. That is, increasing the entropy of each DOF independently, without introducing correlations.

The overall argument can be broken down into the following steps:
\begin{enumerate}
    \item characterize entropy-increasing maps in classical mechanics for a single DOF, noting that they can all be understood as Hamiltonian evolutions followed by a pure stretching map, one that stretches position and momentum by the same factor $\sqrt{\lambda}$
    \item show that a pure stretching map in quantum mechanics cannot be defined over symmetrized operator averages or normal ordering
    \item show that it can be defined over anti-normal ordering; show that if we rescale the zero of entropy, the commutators become $[X, P]= \frac{\imath \hbar}{\lambda}$, which makes the limit $\lambda \to \infty$ mathematically equivalent to $\hbar \to 0$
    \item show how, in the limit, the Wigner $W$ and Husimi $Q$ distributions become closer and closer
\end{enumerate}

\subsection{Stretching classical phase space}

Before looking at the quantum case, let us study the high entropy limit of classical mechanics. We are looking for all those transformations that increase the entropy of all states by the same amount.

We are going to study the one-dimensional case, therefore let us call $\mathcal{M} = (\mathbb{R}^2, \omega)$ the phase space for a single degree of freedom, where $\omega$ is the associated symplectic form.\footnote{The symplectic form allows us to define the count of states in infinitesimal regions, and therefore defines the entropy as well.} Suppose we have a map $R : \mathcal{M} \to \mathcal{M}$ that acts on phase space. This map will also act on probability distributions defined on $\mathcal{M}$ by moving them point to point. We require that $R$ increases the entropy of each distribution $\rho$ by a set value $\Delta S = \log \lambda > 0$. That is
\begin{equation}
S(R(\rho)) = S(\rho) + \log \lambda,
\end{equation}
where $S(\rho) = - \int_{\mathcal{M}} \rho \log \rho dx dp$ and $R(\rho)$ is the distribution as it is transformed through the map.

For a generic transformation, the increase of entropy is given by the expectation of the Jacobian determinant $\Delta S =\int_M \rho \log |\partial_a R^b| dxdp$. Since the increase has to be the same for all distributions, we must have $|\partial_a R^b| = \lambda > 1$.\footnote{The case of a negative Jacobian is a reflection in phase space, which cannot be achieved through a continuous evolution in time and is therefore discarded.} Recall that the Jacobian determinant tells us how an infinitesimal volume scales through the transformation, and therefore a map that increases entropy uniformly is exactly a map that stretches phase space uniformly. We call such a map a \textbf{stretching map}.

Suppose, in fact, that $\rho$ is a uniform distribution over a region of area $W_1$. Then we have $S(\rho)= \log W_1$. Applying the stretching map, $\rho$ will transform into a uniform distribution over a region of area $W_{\lambda} = \lambda W_1$. The final entropy is therefore $S(R(\rho)) = \log \lambda W_1 = \log W_1 + \log \lambda$. The factor $\lambda$, then, can be understood either as the ratio between initial and final areas, or as the exponential of the entropy increase. Therefore studying the high entropy limit means studying what happens under stretching maps in the limit $\lambda \to \infty$.

Note that the transformation is not a canonical transformation. Canonical transformations, those that can be generated by Hamiltonian evolution, preserve areas in phase space and conserve entropy. In fact, for a single degree of freedom, canonical transformations and volume-preserving maps coincide. This allows us to show that all stretching maps can be written as $R = T \circ U$, where $U$ is a canonical transformation and $T$ is a \textbf{pure stretching map} defined as
\begin{equation}
    T(x,p) \mapsto (\sqrt{\lambda} x, \sqrt{\lambda} p)
\end{equation}
where $\lambda = (1,\infty)$. That is, any stretching map can be understood as first performing a canonical transformation that preserves entropy followed by a pure stretch of position and momentum.

To see how this works, note that given a stretching map $R$, we can always write $U = T^{-1} \circ R$. Since $R$ stretches phase space everywhere by a factor $\lambda$ and $T^{-1}$ shrinks it by the same factor, $U$ preserves areas and is a canonical map, since we restricted ourselves to the one-dimensional case.\footnote{To extend to the general case, the stretching map must not only stretch the total volume, but areas in each DOF. Mathematically, this means rescaling the symplectic form $\omega$.} Therefore $R = T \circ U$, which means we only need to study $T$ to characterize all maps that increase entropy uniformly.

We can alternatively characterize stretching maps by how the  Poisson brackets transform. Note that
\begin{equation}
    \{R(x),R(p)\} = \partial_x R(x) \partial_p R(p) - \partial_x R(p) \partial_p R(x) = | \partial_a R^b | = \lambda.
\end{equation}
That is, the Poisson bracket of the transformed position and momentum is the Jacobian determinant of the transformation, which is $\lambda$. Since this is an equality, all maps that satisfy the above transformation of the Poisson brackets are stretching maps.

For a pure stretching map, we can provide a more specific characterization. Note, in fact, that a distribution with compact support is always fully characterized by all its central moments, that is the expectations for all polynomials of position and momentum. Therefore, once we know how the central moments transform through the map, we know how all distributions with compact support transform and therefore we fully characterize the map. This means that $T$ is a pure stretching map if and only if
\begin{equation}
    \langle T(x^np^m) \rangle = (\sqrt{\lambda})^{(n+m)} \langle x^n p^m \rangle.
\end{equation}

\subsection{Operator ordering}

Ideally, we would want to treat the quantum case similarly to the classical case. We would look for those quantum channels (i.e.~CPTP maps) $R$ that increase the entropy of all mixed states by the same amount, we would show that they can be decomposed into a unitary part and a pure stretching part and so on. In practice, the quantum version of the problem is much harder. First of all, a map that increases the entropy of all quantum states cannot be invertible: pure states have the lowest entropy and therefore no state of lower entropy can be mapped to them. Secondly, since our map increases entropy, it does not in general preserve products. In fact, if we had $R(AB) = R(A)R(B)$, then $R([A,B]) = [R(A),R(B)]$, which would mean $R$ is unitary and therefore preserves entropy. Since, in general, $R(AB) \neq R(A)R(B)$, different permutations of polynomials will be transformed differently: the operator ordering matters.
%GC: I think this is a simpler, more general argument. It also puts more in focus why I kept getting confused from the other argument

% Note https://link.springer.com/article/10.1007/BF00419590 says entropy does not decrease if L L* \leq L* L. There also seems to be a bound

In this light, we are looking for a map that rescales the expectations of the polynomials for a particular ordering. There are three commonly used orderings: symmetrized averages, normal ordering and anti-normal ordering. The first takes the product of $n$ operators by averaging all possible permutations; the second is in terms of polynomials of the form $(a^\dagger)^n a^m$, where $a=\sqrt{\frac{m\omega}{2\hbar}}(X+\frac{i}{m\omega}P)$ and $a^\dagger$ are the ladder operators; the last is in terms of $a^n (a^\dagger)^m$. The three orderings are associated, respectively, with a quasi-probability distribution: the Wigner function $W$, the Glauber-Sudarshan $P$ distribution and the Husimi $Q$ distribution. In each case, the expectation under the quasi-probability distribution of polynomials of classical variables returns the expectation of the respective ordering.

Interestingly, not all orderings will allow a pure stretching map $T$ that rescales all expectations and increases the entropy of all states. Let us consider the symmetrized average case. We are looking for a map $T_W$ for which
\begin{equation}
\langle T_W(\Pi(\underbrace{X, ..., X}_{\text{n times}}, \underbrace{P, ..., P}_{\text{m times}})) \rangle = (\sqrt{\lambda})^{(n+m)} \langle \Pi(\underbrace{X, ..., X}_{\text{n times}}, \underbrace{P, ..., P}_{\text{m times}})\rangle.
\end{equation}
where $\Pi(A_1, A_2, \ldots, A_n)  = \frac{1}{n!} \sum_{\pi}  A_{\pi(1)} A_{\pi(2)} \cdots A_{\pi(n)}$ is the average of the products for each permutation $\pi$. These averages correspond to the expectation calculated through the Wigner function $W(x,p)$
\begin{equation}
     \langle \Pi(\underbrace{X, ..., X}_{\text{n times}}, \underbrace{P, ..., P}_{\text{m times}})\rangle = \int_M x^n p^m W(x, p) dx dp.
\end{equation}
The map $T_W$, then, would correspond to a pure stretching map on the Wigner function. However, this cannot work. Wigner functions can have regions with negative values, but the size of these regions cannot exceed a few units of $\hbar$.\cite{kenfack2004negativity} The size of these negative regions would increase under $T_W$, giving functions that do not correspond to a quantum state. Therefore we cannot find a pure stretching map in the symmetrized average operator ordering.

Let us now consider a pure stretching map $T_P$ in normal ordering. This would have:
\begin{equation}
\langle T_P((a^\dagger)^n a^m) \rangle = (\sqrt{\lambda})^{(n+m)} \langle (a^\dagger)^n a^m \rangle.
\end{equation}
For the vacuum state we have $a|0\rangle=0$, which means the mean value of all observables in normal ordering for the vacuum is zero. These would remain unchanged by $T_P$. The vacuum state, then, would not change and therefore the map would not increase entropy for all states. The normal ordering is ruled out as well. {\color{blue} thinking of it this way, you can also use the same argument as before. The P distribution also has negative regions that would stretch.} {\color{red} do we know they must have a maximum size? I haven't seen anything about it.}

We turn our attention to the anti-normal ordering and a map $T_Q$ such that:
\begin{equation}
\langle T_Q(a^n(a^\dagger)^m) \rangle = (\sqrt{\lambda})^{(n+m)} \langle a^n(a^\dagger)^m \rangle.
\end{equation}
This ordering solves the previous problem of the vacuum. The anti-normal ordering is connected to the Husimi $Q$ distribution by
\begin{equation}
    \langle a^n (a^\dagger)^m\rangle=\int \alpha^n(\alpha^*)^m Q_1(\alpha)d^2\alpha.
\end{equation}
The map $T_Q$, then, corresponds to a pure stretching map on the space where $Q$ is defined. That is,
\begin{equation}
T_Q(Q_1(\alpha)) \equiv Q_\lambda(\alpha) = \frac{1}{\lambda}Q_1\left(\frac{\alpha}{\sqrt{\lambda}}\right).
\end{equation}
We indicate $Q_1$ as the initial unstretched distribution and $Q_\lambda$ the final stretched distribution by a factor of $\lambda$. We can in fact verify that 
\begin{equation}
\int \alpha^n(\alpha^*)^m Q_\lambda(\alpha)d^2\alpha=\int \alpha^n(\alpha^*)^m \frac{1}{\lambda}Q_1\left(\frac{\alpha}{\sqrt{\lambda}}\right)d^2\alpha=\int \sqrt{\lambda}^{n+m}\beta^n(\beta^*)^m Q_1(\beta)d^2\beta.
\end{equation}
Since the Husimi distribution is non-negative, this avoids the issue presented by the Wigner function.

The anti-normal ordering, then, is a potential candidate. We now need to show that a pure stretching map $T_Q$ actually exists.

\subsection{Pure quantum stretching map}

If pure quantum stretching maps $T_Q$ exist, they must be CPTP maps as they must transform mixed states into mixed states. Moreover, since they have to increase entropy for all states, they must be describing an open quantum system. We thus show that pure stretching maps can be expressed as the solution of a master equation in Lindblad form and the Heisenberg picture. We start with
\begin{equation}
	\frac{d}{d t} X=\frac{i}{\hbar}[H,X]+\sum_i \gamma_i \left(L_i^\dagger X L_i-\frac{1}{2}\left\{L_i^\dagger L_i,X\right\}\right)
\end{equation}
where X is an operator, $L_i$ are the jump operators and $\gamma_i$ are positive parameters. To define $T_Q$ for a single DOF we set $\gamma_i=\{\gamma\}$ and $L_i=\{a^\dagger\}$. We also set $H=0$ since $T_Q$ should be purely dissipative. The equation of motion of $a$ reduces to
\begin{equation}
	\frac{d}{d t} a=\frac{\gamma}{2} a
\end{equation}
with solution $a(t)=e^{\frac{\gamma}{2} t} a = \sqrt{\lambda} a$, where we make the identification $\lambda=e^{\gamma t}$. 
In general, we find
\begin{equation}
	\frac{d}{d t} a^n (a^{\dagger})^m=\frac{\gamma}{2}(n+m)a^n (a^{\dagger})^m
\end{equation}
meaning that this evolution realizes the stretching map in anti-normal ordering. That is, $(a^n (a^{\dagger})^m)(t)=e^{\frac{\gamma}{2} t (n+m)} a^n (a^{\dagger})^m = (\sqrt{\lambda})^{(n+m)} a^n (a^{\dagger})^m$.\footnote{Note that for the choice of $L_i=\{a\}$, we get the opposite behavior, characterized by
\begin{equation}
	\frac{d}{d t} (a^{\dagger})^n a^m=-\frac{\gamma}{2}(n+m)(a^{\dagger})^n a^m
\end{equation}
leading to shrinking ($\lambda\leq1$) of all observables taken in normal ordering.}

This shows that a map $T_Q$ that stretches the $Q$ distribution can be understood as a purely dissipative process that runs for a time $\Delta t$ with $\gamma_i = \left\{ \frac{\log \lambda} {\Delta t} \right\}$ and $L_i = \{ a^\dagger\}$, and therefore it is a CPTP map. Note that, for the same DOF, $a^\dagger$ is not uniquely fixed as it depends on the parameter $m\omega$. Moreover, ladder operators with different values of the parameter $m\omega$ are not going to commute, therefore will lead to different transformations. That is, while we fixed the ordering of the operators, the non-commutative nature of quantum observables still implies a choice within a one-parameter family of operators.  However, note that a linear transformation that stretches $X$ and shrinks $P$
\begin{equation}
	U(X, P) = \left(\sqrt{\alpha} X, \frac{1}{\sqrt{\alpha}} P\right)
\end{equation}
is a unitary transformation. Under this map, $U(a) = \sqrt{\frac{m\omega\alpha}{2\hbar}}(X+\frac{i}{m\omega\alpha}P)$, which means that $m\omega$ can be changed through a unitary operator. Consistently with the classical definitions, we can define $R_Q = T_Q \circ U$ to be a quantum stretching map. Therefore, even if fixing the operator ordering does not pick a unique map, the behavior when entropy increases is the same.

Lastly, we need to show that $T_Q$ increases entropy for all states. Note that a Lindblad operator increases entropy for all states if\cite{Benatti1988}
\begin{equation}
	\sum_i L_i.L_i^\dagger \leq \sum_i L_i^\dagger L_i.
\end{equation}
In our case, this reduces to 
\begin{equation}
	a^\dagger a \leq a a^\dagger.
\end{equation}
Since $[a, a^\dagger] = a a^\dagger - a^\dagger a = I \geq 0$, our map increases entropy for all states.\footnote{Note that for the choice $L_i=\{a\}$ the inequality is not satisfied.}

We can now look at the effect of the map on $X$, $P$ and their commutator. We have
\begin{align}
    T_Q(a) &= \sqrt{\lambda} a \\ 
    T_Q(a^\dagger) &= \sqrt{\lambda} a^\dagger \\ 
    T_Q(X) &= T_Q\left(\sqrt{\frac{\hbar}{2m\omega}}(a^\dagger + a)\right) = \sqrt{\lambda} X \\
    T_Q(P) &= T_Q(\imath\sqrt{\frac{\hbar m \omega}{2}}(a^\dagger - a)) = \sqrt{\lambda} P \\
    [T_Q(X), T_Q(P)] &= \lambda [X, P].
\end{align}
In other words, the effect of $T_Q$ is to increase the commutator between $X$ and $P$. 

We can study the limit in two ways. The most straightforward would be see how the space changes as the commutators $[T_Q(X), T_Q(P)]= \lambda \imath \hbar$ go to infinity. This corresponds to keeping the entropy of the pure states fixed at zero and studying the space of states at high entropy. Alternatively, we can see how the space itself changes from the perspective of the state that is increasing in entropy. That is, we rescale the entropy of pure states to lower and lower values, while keeping the entropy of the mixed state fixed. To do that, we keep $[T_Q(X), T_Q(P)] = \imath \hbar$ constant and we study the limit as $[X, P]= \frac{\imath \hbar}{\lambda}$ goes to zero. Formally, this is equivalent to taking the limit $\hbar \to 0$, which is the group contraction that morphs the Moyal bracket Lie algebra to the Poisson bracket Lie algebra.\cite{saletan1961contraction, inonu1953contraction} That is, as $\lambda$ increases, the states will see the structure of quantum mechanics becoming closer and closer to the structure of classical mechanics.

%TODO: still missing a group contraction reference for \hbar \to 0

Note that the above argument works for any map $T_Q \circ U$ that combines the pure stretching map with an arbitrary unitary evolution $U$. Also, while we have not shown that anti-normal ordering is the only ordering that allows a stretching map, it will need to have the same effect on $X$ and $P$, leading to the same limit. The question of whether all maps that perform the same group contraction can expressed as $T_Q \circ U$ remains open. However, they will factorize in that fashion in the limit, since the classical limit can always be factorized as pure stretching map following a symplectomorphism. Similarly, the question of whether $T_Q$ increases the entropy of all states by the same amount remains open. However, it will do so in the limit since $T_Q$ will become closer and closer to a pure classical stretching map. Lastly, we have not shown that all transformations that increase entropy must stretch phase space. Note, however, that a finite region of phase space can only hold mixed states with finite entropy. Therefore a map that does not stretch some region of phase space will necessarily lead to states whose entropy will not go to infinity as the map is reapplied over and over. Regardless, our ultimate goal is not to study all possible ways entropy can be increased. Our goal is simply to show that, as entropy increases, the classical description becomes a suitable approximation.

To sum up, we have found a pure quantum stretching map $T_Q$. It is a CPTP map. It rescales operators in anti-normal ordering. It increases entropy for all states. It recovers classical mechanics in the limit. This means that the space of quantum states, as entropy increases, becomes more and more classical. All of this is done under general conditions, and is independent of the mechanism that performs the entropy increase.

%Since the canonical operators x and p are simply linear combinations of $a$ and $a^\dagger$, their mean values will stretch as required, with stretching parameter given by $\lambda=e^{\gamma t}$. It is not so hard to show that the scaling applies to all operator combinations in anti-normal ordering. 
%If one is careful, it's clear that this cannot work forever. We can stretch the first moment of the operators: $a_i^{(\dagger)}(t)=\sqrt{\lambda} a_i^{(\dagger)}(0)$. But already for the second moment this breaks. We find: $(a^\dagger a)(t)=\lambda((a^\dagger a)(0)+1)-1$. The exact stretching is only recovered in the limit of  $\lambda\rightarrow\infty$. On the other hand, if we consider the anti-normal ordering $(a a^\dagger)(t)=\lambda(a a^\dagger)(0)$. This means that the map we have satisfies stretching in anti-normal ordering. 

%The correct distribution function to use under anti-normal ordering is the Husimi Q-distribution. This makes perfect sense. This is the only one that is positive-defined. Therefore it's the only one that can be stretched without issues due to negative regions

%TODO: show that such a map exist and it increases the entropy by a fixed amount (DONE?)

% Possible resource https://link.springer.com/article/10.1007/BF00419590 to show map increase entropy

\subsection{Stretching the Wigner distribution}

To understand what happens physically during the group contraction, let us see how the Wigner W distribution changes under a pure quantum stretching map. To do that, we can use the fact that Q is the Weierstrass transform of $W$. That is:
\begin{equation}
    Q_\lambda(\alpha)=\frac{2}{\pi}\int W_\lambda(\beta)e^{-2|\alpha-\beta|^2}d^2\beta.
\end{equation}
Considering the evolution of $Q$, we get
\begin{equation}
    \int W_\lambda(\beta)e^{-2|\alpha-\beta|^2}d^2\beta=\frac{1}{\lambda}\int W_1(\beta)e^{-2|\alpha/\sqrt{\lambda}-\beta|^2}d^2\beta.
\end{equation}
We notice that these two equations are scaled convolutions between the Wigner distribution and Gaussian functions. Symbolically:
\begin{equation}
    (W_\lambda \ast G)(\alpha)=\frac{1}{\lambda}(W_1\ast G)\left(\frac{\alpha}{\sqrt{\lambda}}\right)
\end{equation}
where $G(\alpha)=(2/\pi) e^{-2|\alpha|^2}$ indicates the Gaussian function. To get rid of the convolution, we now take a Fourier transform of both sides. Keeping in mind that the Fourier transform of a general function $f$ behaves under scaling according to
\begin{equation}
    F\left(\frac{1}{\lambda}f\left(\frac{\alpha}{\sqrt{\lambda}}\right)\right)(k)=F(f(\alpha))(\sqrt{\lambda}k)
\end{equation} and using the convolution theorem, we get (TODO Man: check)
\begin{equation}
  F(W_\lambda)(k)F(G)(k)=F\left(\frac{1}{\lambda}W_1\left(\frac{\beta}{\sqrt{\lambda}}\right)\right)(k)F(G)(\sqrt{\lambda}k).  
\end{equation}
We now notice that (TODO Man: add (k) in the end?)
\begin{equation}
    \frac{F(G)(\sqrt{\lambda}k)}{F(G)(k)}=\frac{e^{-\lambda|k|^2/8}}{e^{-|k|^2/8}}=e^{-(\lambda-1)|k|^2/8}=F(G)(\sqrt{\lambda-1}k)=F\left(\frac{1}{\lambda-1}G\left(\frac{\beta}{\sqrt{\lambda-1}}\right)\right),
\end{equation}
finally giving
\begin{equation}
    W_\lambda(\beta)=F^{-1}\left(F\left(\frac{1}{\lambda}W_1\left(\frac{\beta}{\sqrt{\lambda}}\right)\right)F\left(\frac{1}{\lambda-1}G\left(\frac{\beta}{\sqrt{\lambda-1}}\right)\right)\right)=\frac{1}{\lambda(\lambda-1)}W_1\left(\frac{\beta}{\sqrt{\lambda}}\right) \ast G\left(\frac{\beta}{\sqrt{\lambda-1}}\right)
    \label{Fourier}
\end{equation}
Writing this down explicitly
\begin{equation}
   W_\lambda(\beta)=\frac{2}{\pi\lambda(\lambda-1)}\int W_1\left(\frac{\alpha}{\sqrt{\lambda}}\right)e^{-\frac{2}{\lambda-1}\left|\alpha-\beta\right|^2}d^2\alpha.
\end{equation}
A similar calculation gives the Glauber-Sudarshan $P$ distribution, as this one is also obtained from a Weierstrass transfrom of $Q$.

It is interesting to consider what happens to the negative regions of $W$ under the stretching map. We know that $W$ can have negative regions, but their size is limited by the uncertainty principle. In fact, convolving $W$ with a 2D Gaussian with unitary spread, as in the definition of $Q$, returns a function that is never negative. In the limit $\lambda\gg1$, the formula for $W_\lambda$ reduces to
\begin{equation}
     W_\lambda(\beta)\rightarrow_{\lambda\gg1}\frac{2}{\pi\lambda^2}\int W_1\left(\frac{\alpha}{\sqrt{\lambda}}\right)e^{-\frac{2}{\lambda}\left|\alpha-\beta\right|^2}d^2\alpha=Q_\lambda(\beta).
\end{equation}
Therefore, while negative regions can be in principle found at any finite $\lambda$, $W$ tends to a positive function in the limit. As usual for the $W$ distribution, the phase space size of negative regions is limited to $\hbar$ by the uncertainty principle. The weight of the function in such regions is limited between $\pm 2/\hbar$ for pure states. The effect of the stretching map is to reduce this bound to $\pm 2/(\lambda\hbar)$ for large values of $\lambda$. A clear interpretation can be made by working directly on the Fourier transform of $W$; see Eq.~(\ref{Fourier}). The function $F(W_\lambda)$ is a scaled version of $F(W_1)$, with a Gaussian filter applied to it. Quantum information in $W_1$ is carried by spectral weights with k-vectors larger than 1. The bandwidth of the Gaussian filter is given by $\lambda/(\lambda-1)$. This cutoff approaches 1 in the limit, filtering away the interference terms.

We have thus shown that, in the limit of high entropy, the Wigner distribution can be approximated by a positive function. We now need to show that the evolution can be approximated by classical Hamiltonian evolution. An intuitive way to understand why this works is to look at the evolution of the Wigner function under a Hamiltonian $H = p^2/2m + V$ where the potentials $V$ are analytic. We have~\cite{hillery1984distribution}
\begin{equation}
\begin{aligned}
    \frac{d}{dt} W &= \{\{H, W\}\} \\
    &= \{H, W\} + \sum_n \frac{\hbar^{2n} (-1)^n}{(2n+1)! \, 2^{2n}} \partial_x^{(2n+1)} V \partial_p^{(2n+1)} W
\end{aligned}
\end{equation}
The evolution is in terms of the Moyal bracket $\{\{H,W\}\}$ which can be expanded in orders of $\hbar$ with the Poisson bracket $\{H,W\}$ as the leading term. In our limit, $\hbar$ is constant but as the function stretches all derivatives of $W$ decrease. Therefore the first term becomes dominant.

\section{Conclusion}

We have seen that classical mechanics can be recovered as the high entropy limit of quantum mechanics. That is, states of high entropy are better and better approximated by classical distributions over phase space. This approach to the classical limit is independent of mechanism and interpretation, as it does not matter how the entropy is increased or what one believes quantum states to represent: as long as the description is in terms of mixed states of sufficiently high entropy, classical mechanics applies. The approach fits naturally with experimental considerations and other approaches, such as decoherence, and recovers the established mathematical recipe, which is the group contraction for $\hbar \to 0$. Physically, this can be understood as taking the entropy of pure states to minus infinity, which is equivalent to saying that the relative entropy of mixed states goes to plus infinity. This gives a reasonable and precise account of the classical limit: in the same way that non-relativistic mechanics applies to low speed, classical mechanics applies to high entropy.

The limit also gives us additional insights. As we saw, classical states for which $\Delta x \Delta p < \frac{\hbar}{e}$ are states with negative entropy, which imply a breakdown of thermodynamics. It is no wonder, then, electrons cannot fall on the nucleus or that classical mechanics gives us the wrong spectra for black-body radiation. Classical mechanics fails at low entropy. The use of the correspondence principle as guidance for the development of quantum mechanics, then, can be understood as requiring that the new quantized theory reproduces classical mechanics at high entropy. 

In this light, we wonder whether it can be proven that quantum mechanics is the only way to fix the low entropy range of classical mechanics. That is, is quantum mechanics the only theory that can recover classical mechanics at high entropy? To us, this is a question whose answer would be interesting regardless of the outcome.

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}